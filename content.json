{"pages":[{"title":"关于我","text":"","link":"/about/index.html"},{"title":"分类","text":"","link":"/categories/index.html"},{"title":"留言板","text":"《论语·公冶长第五》：「子路有闻，未之能行，唯恐有（又）闻」 大致的意思是，子路听到了好的道理，还不能转化为行动的时候，就怕自己又听到其他的道理。 上边所引的那句论语，就是子路的方法论：一次一个道理，听完就去施行，没有掌握之前，不再过多摄入。所以现在要做的，不是加法，而是减法，最终能够形成「有闻」→「能行」→「又闻」这样一个良性的循环 So，Come with me……","link":"/guestbook/index.html"},{"title":"标签云","text":"","link":"/tags/index.html"}],"posts":[{"title":"Guava 源码阅读系列——Primitives Ints 类","text":"Ints 类作为 Guava 对 Java 基本数据类型 int 的工具类封装。 常量BYTES12//在 Java 8 中可以被 Integer.BYTES 替代，代表字节数 bytespublic static final int BYTES = Integer.SIZE / Byte.SIZE; MAX_POWER_OF_TWO12// int 最大存储值，使用 1&lt;&lt;(Integer.SIZE-2) 计算得到，2是因为一位代表正负，1同时占一位public static final int MAX_POWER_OF_TWO = 1 &lt;&lt; (Integer.SIZE - 2); 静态方法public static int hasCode(int)计算传入 int 值的 hashcode。与 JDK 8 中 Integer.hashCode(int) 一样，直接返回数值本身。 123public static int hashCode(int value) { return value;} public static int checkedCast(long)将 long 强制类型转换为 int。当传入参数超出 int 的取值范围 [2^31-1, -2^31] 时，抛出 IllegalArgumentException 异常，否则返回参数本身。 12345public static int checkedCast(long value) { int result = (int) value; checkArgument(result == value, &quot;Out of range: %s&quot;, value); return result;} public static int saturatedCast(long)将 long 转换成 int 范围内的值。与 checkedCast 不同的是，当传入参数大于 int 最大值或小于 int 最小值，直接返回最大值或最大值，而不是抛异常。 123456789public static int saturatedCast(long value) { if (value &gt; Integer.MAX_VALUE) { return Integer.MAX_VALUE; } if (value &lt; Integer.MIN_VALUE) { return Integer.MIN_VALUE; } return (int) value;} public static int compare(int, int)`比较两个 int 值的大小，等价于 ((Integer) a).compareTo(b)。返回值分为三种情况: a 小于/等于/大于 b 时分别返回 -1/0/1。注：JDK 7 及以后建议使用 Integer.compar(int, int) 而非此方法。 123public static int compare(int a, int b) { return (a &lt; b) ? -1 : ((a &gt; b) ? 1 : 0);} public static boolean contains(int[], int)`判断给定 12345678public static boolean contains(int[] array, int target) { for (int value : array) { if (value == target) { return true; } } return false;} public static int indexOf(int[], int)`123public static int indexOf(int[] array, int target) { return indexOf(array, target, 0, array.length);} private static int indexOf(int[], int, int, int)12345678private static int indexOf(int[] array, int target, int start, int end) { for (int i = start; i &lt; end; i++) { if (array[i] == target) { return i; } } return -1;} public static int indexOf(int[], int[])123456789101112131415161718public static int indexOf(int[] array, int[] target) { checkNotNull(array, &quot;array&quot;); checkNotNull(target, &quot;target&quot;); if (target.length == 0) { return 0; } outer: for (int i = 0; i &lt; array.length - target.length + 1; i++) { for (int j = 0; j &lt; target.length; j++) { if (array[i + j] != target[j]) { continue outer; } } return i; } return -1;} public int lastIndexOf(int[], int)123public static int lastIndexOf(int[] array, int target) { return lastIndexOf(array, target, 0, array.length);} private int lastIndexOf(int[], int, int, int)12345678private static int lastIndexOf(int[] array, int target, int start, int end) { for (int i = end - 1; i &gt;= start; i--) { if (array[i] == target) { return i; } } return -1;} public static int min(int…)12345678910public static int min(int... array) { checkArgument(array.length &gt; 0); int min = array[0]; for (int i = 1; i &lt; array.length; i++) { if (array[i] &lt; min) { min = array[i]; } } return min;} public static int max(int…)12345678910public static int max(int... array) { checkArgument(array.length &gt; 0); int max = array[0]; for (int i = 1; i &lt; array.length; i++) { if (array[i] &gt; max) { max = array[i]; } } return max;} public static int constrainToRange(int, int, int)1234public static int constrainToRange(int value, int min, int max) { checkArgument(min &lt;= max, &quot;min (%s) must be less than or equal to max (%s)&quot;, min, max); return Math.min(Math.max(value, min), max);} public static int[] concat(int[]…)12345678910111213public static int[] concat(int[]... arrays) { int length = 0; for (int[] array : arrays) { length += array.length; } int[] result = new int[length]; int pos = 0; for (int[] array : arrays) { System.arraycopy(array, 0, result, pos, array.length); pos += array.length; } return result;} public static byte[] toByteArray(int)12345public static byte[] toByteArray(int value) { return new byte[] { (byte) (value &gt;&gt; 24), (byte) (value &gt;&gt; 16), (byte) (value &gt;&gt; 8), (byte) value };} public static int fromByteArray(byte[])1234public static int fromByteArray(byte[] bytes) { checkArgument(bytes.length &gt;= BYTES, &quot;array too small: %s &lt; %s&quot;, bytes.length, BYTES); return fromBytes(bytes[0], bytes[1], bytes[2], bytes[3]);} public static int fromBytes(byte, byte, byte, byte)123public static int fromBytes(byte b1, byte b2, byte b3, byte b4) { return b1 &lt;&lt; 24 | (b2 &amp; 0xFF) &lt;&lt; 16 | (b3 &amp; 0xFF) &lt;&lt; 8 | (b4 &amp; 0xFF);} public static Converter&lt;String, Integer&gt; stringConverter()123public static Converter&lt;String, Integer&gt; stringConverter() { return IntConverter.INSTANCE;} public static int[] ensureCapacity(int[], int, int)12345public static int[] ensureCapacity(int[] array, int minLength, int padding) { checkArgument(minLength &gt;= 0, &quot;Invalid minLength: %s&quot;, minLength); checkArgument(padding &gt;= 0, &quot;Invalid padding: %s&quot;, padding); return (array.length &lt; minLength) ? Arrays.copyOf(array, minLength + padding) : array;} public static String join(String, int…)1234567891011121314public static String join(String separator, int... array) { checkNotNull(separator); if (array.length == 0) { return &quot;&quot;; } // For pre-sizing a builder, just get the right order of magnitude StringBuilder builder = new StringBuilder(array.length * 5); builder.append(array[0]); for (int i = 1; i &lt; array.length; i++) { builder.append(separator).append(array[i]); } return builder.toString();} public static void sortDescending(int[])123456789/** * Sorts the elements of {@code array} in descending order. * * @since 23.1 */public static void sortDescending(int[] array) { checkNotNull(array); sortDescending(array, 0, array.length);} public static void sortDescending(int[], int, int)123456public static void sortDescending(int[] array, int fromIndex, int toIndex) { checkNotNull(array); checkPositionIndexes(fromIndex, toIndex, array.length); Arrays.sort(array, fromIndex, toIndex); reverse(array, fromIndex, toIndex);} public static void reverse(int[])1234public static void reverse(int[] array) { checkNotNull(array); reverse(array, 0, array.length);} public static void reverse(int[], int, int)123456789public static void reverse(int[] array, int fromIndex, int toIndex) { checkNotNull(array); checkPositionIndexes(fromIndex, toIndex, array.length); for (int i = fromIndex, j = toIndex - 1; i &lt; j; i++, j--) { int tmp = array[i]; array[i] = array[j]; array[j] = tmp; }} public static int[] toArray(Collection&lt;? extends Number&gt;)1234567891011121314public static int[] toArray(Collection&lt;? extends Number&gt; collection) { if (collection instanceof IntArrayAsList) { return ((IntArrayAsList) collection).toIntArray(); } Object[] boxedArray = collection.toArray(); int len = boxedArray.length; int[] array = new int[len]; for (int i = 0; i &lt; len; i++) { // checkNotNull for GWT (do not optimize) array[i] = ((Number) checkNotNull(boxedArray[i])).intValue(); } return array;} public static List asList(int…)123456public static List&lt;Integer&gt; asList(int... backingArray) { if (backingArray.length == 0) { return Collections.emptyList(); } return new IntArrayAsList(backingArray);} public static Integer tryParse(String)123public static Integer tryParse(String string) { return tryParse(string, 10);} public static Integer tryParse(String, int)12345678public static Integer tryParse(String string, int radix) { Long result = Longs.tryParse(string, radix); if (result == null || result.longValue() != result.intValue()) { return null; } else { return result.intValue(); }} 静态内部类class IntConverter extends Converter&lt;String, Integer&gt; implements Serializableenum LexicographicalComparator implements Comparator&lt;int[]&gt;class IntArrayAsList extends AbstractListimplements RandomAccess, Serializable","link":"/guava-primitives-Ints.html"},{"title":"Mockito 3.6.0 中文文档","text":"Mockito 库能够 Mock 对象、验证结果以及打桩(stubbing)。本中文文档基于 Mockito 3.6.0 版本的官方文档翻译，如有错误，欢迎在评论区指正👏。 目录 迁移到Mockito 2.0 验证某些行为 如何做一些测试桩 (Stub) 参数匹配器 (matchers) 验证函数的确切、最少、从未调用次数 为返回值为void的函数通过Stub抛出异常 按照顺序验证执行结果 确保交互(interaction)操作不会执行在mock对象上 查找冗余的调用 简化mock对象的创建 为连续的调用做测试桩 (stub) 为回调做测试桩 doReturn()、doThrow()、doAnswer()、doNothing()、doCallRealMethod()系列方法的运用 监控真实对象 修改没有测试桩的调用的默认返回值 ( 1.7版本之后 ) 为下一步的断言捕获参数 (1.8版本之后) 真实的局部mocks (1.8版本之后) 重置mocks对象 (1.8版本之后) 故障排查与验证框架的使用 (1.8版本之后) 行为驱动开发的别名 (1.8版本之后) 序列化mock对象 新的注解 : @Captor,@Spy,@ InjectMocks (1.8.3版本之后) 验证超时 (1.8.5版本之后) 自动初始化被@Spies, @InjectMocks注解的字段以及构造函数注入 (1.9.0版本之后) 单行测试桩 (1.9.0版本之后) 验证被忽略的测试桩 (1.9.0版本之后) mock详情 (1.9.5版本之后) delegate调用真实的实例 (1.9.5版本之后) MockMaker API (1.9.5版本之后) BDD风格的验证 (1.10.0版本之后) 追踪或者Mock抽象类 (1.10.12版本之后) Mockito mock对象通过ClassLoader能被序列化/反序列化 (1.10.0版本之后) deep stubs更好的支持泛型 (1.10.0版本之后) Mockito JUnit 规则 (1.10.17版本之后) 开/关插件 (1.10.15版本之后) 自定义验证失败消息 (2.0.0版本之后) 0. 迁移到 Mockito 2.0为了持续提升 Mockito 以及更进一步的提升单元测试体验，我们希望你升级到 Mockito 2.1.0。Mockito 遵循语意化的版本控制，除非有非常大的改变才会变化主版本号。在一个库的生命周期中，为了引入一系列有用的特性，修改已存在的行为或者 API 等重大变更是在所难免的。有关新版本（包括不兼容的更改）的全面指南，请参阅”Mockito 2” wiki 页面中的 “What’s new in Mockito 2”。我们希望你能够喜欢 Mockito 2.0! 0.1. Mockito Android supportWith Mockito version 2.6.1 we ship “native” Android support. To enable Android support, add the mockito-android library as dependency to your project. This artifact is published to the same Mockito organization and can be imported for Android as follows: You can continue to run the same unit tests on a regular VM by using the mockito-core artifact in your “testCompile” scope as shown above. Be aware that you cannot use the inline mock maker on Android due to limitations in the Android VM. If you encounter issues with mocking on Android, please open an issue on the official issue tracker. Do provide the version of Android you are working on and dependencies of your project. 0.2. Configuration-free inline mock makingStarting with version 2.7.6, we offer the ‘mockito-inline’ artifact that enables inline mock making without configuring the MockMaker extension file. To use this, add the mockito-inline instead of the mockito-core artifact as follows: Be aware that this artifact may be abolished when the inline mock making feature is integrated into the default mock maker. 1. 验证某些行为跟着我们的示例来 mock 一个 List，因为大家对 List 接口很熟悉（例如 add(),get(), clear()）。事实上，不要 mock List 接口本身,而要使用 List 的一个实例来替代。 12345678910111213// 静态导入会使代码更简洁import static org.mockito.Mockito.*;// 创建 mock 对象List mockedList = mock(List.class);// 使用 mock 对象mockedList.add(&quot;one&quot;);mockedList.clear();// 验证verify(mockedList).add(&quot;one&quot;);verify(mockedList).clear(); 一旦 mock 对象被创建了，mock 对象会记住所有的交互。然后你就可能选择性地验证你感兴趣的交互。 2. 如何做一些测试桩 (Stub)123456789101112131415161718192021// 你可以 mock 具体的类型，不仅只是接口LinkedList mockedList = mock(LinkedList.class);// 测试桩when(mockedList.get(0)).thenReturn(&quot;first&quot;);when(mockedList.get(1)).thenThrow(new RuntimeException());// 输出“first”System.out.println(mockedList.get(0));// 抛出异常System.out.println(mockedList.get(1));// 因为 get(999) 没有打桩，因此输出 nullSystem.out.println(mockedList.get(999));// Although it is possible to verify a stubbed invocation, usually it's just redundant//If your code cares what get(0) returns then something else breaks (often before even verify() gets executed).//If your code doesn't care what get(0) returns then it should not be stubbed. Not convinced? See here.// 验证 get(0) 被调用的次数verify(mockedList).get(0); 默认情况下，所有的函数都有返回值。mock 函数默认返回的是 null，一个空的集合或者一个被对象类型包装的内置类型，例如 0、false 对应的对象类型为 Integer、Boolean； 测试桩函数可以被覆写：例如常见的测试桩函数可以用于初始化夹具，但是测试函数能够覆写它。请注意，覆写测试桩函数是一种可能存在潜在问题的做法； 一旦测试桩函数被调用，该函数将会一直返回固定的值； 上一次调用测试桩函数有时候极为重要——当你调用一个函数很多次时，最后一次调用可能是你所感兴趣的。 3. 参数匹配器 (matchers)Mockito 以自然的 java 风格来验证参数值: 使用 equals() 函数。有时当需要额外的灵活性时你可能需要使用参数匹配器 argument matchers : 1234567891011// 使用内置的 anyInt() 参数匹配器when(mockedList.get(anyInt())).thenReturn(&quot;element&quot;);// 使用自定义的参数匹配器( 在isValid() 函数中返回你自己的匹配器实现 )when(mockedList.contains(argThat(isValid()))).thenReturn(&quot;element&quot;);// 输出 elementSystem.out.println(mockedList.get(999));// 你也可以验证参数匹配器verify(mockedList).get(anyInt()); 参数匹配器使验证和测试桩变得更灵活。点击这里查看更多内置的匹配器以及自定义参数匹配器或者 hamcrest 匹配器的示例。 如果仅仅是获取自定义参数匹配器的信息，查看ArgumentMatcher类文档即可。 为了合理的使用复杂的参数匹配，使用 equals() 与 anyX() 的匹配器会使得测试代码更简洁、简单。有时，会迫使你重构代码以使用 equals() 匹配或者实现 equals() 函数来帮助你进行测试。同时建议你阅读第15章节或者ArgumentCaptor类文档。ArgumentCaptor 是一个能够捕获参数值的特殊参数匹配器。 参数匹配器的注意点 : 如果你使用参数匹配器，所有参数都必须由匹配器提供。 示例 : ( 该示例展示了如何多次应用于测试桩函数的验证 ) 12345verify(mock).someMethod(anyInt(), anyString(), eq(&quot;third argument&quot;));// 上述代码是正确的，因为 eq() 也是一个参数匹配器verify(mock).someMethod(anyInt(), anyString(), &quot;third argument&quot;);// 上述代码是错误的，因为所有参数必须由匹配器提供，而参数 &quot;third argument&quot; 并非由参数匹配器提供，因此会抛出异常 像 anyObject(), eq() 这样的匹配器函数不会返回匹配器。它们会在内部将匹配器记录到一个栈当中，并且返回一个假的值，通常为null。这样的实现是由于被Java编译器强加的静态类型安全。结果就是你不能在验证或者测试桩函数之外使用 anyObject(), eq() 函数。 4. 验证函数的确切、最少、从未调用次数1234567891011121314151617181920212223242526mockedList.add(&quot;once&quot;);mockedList.add(&quot;twice&quot;);mockedList.add(&quot;twice&quot;);mockedList.add(&quot;three times&quot;);mockedList.add(&quot;three times&quot;);mockedList.add(&quot;three times&quot;);// 下面的两个验证函数效果一样，因为 verify 默认验证的就是 times(1)verify(mockedList).add(&quot;once&quot;);verify(mockedList, times(1)).add(&quot;once&quot;);// 验证具体的执行次数verify(mockedList, times(2)).add(&quot;twice&quot;);verify(mockedList, times(3)).add(&quot;three times&quot;);// 使用never()进行验证,never相当于times(0)verify(mockedList, never()).add(&quot;never happened&quot;);// 使用atLeast()/atMost()verify(mockedList, atMostOnce()).add(&quot;once&quot;);verify(mockedList, atLeastOnce()).add(&quot;three times&quot;);verify(mockedList, atLeast(2)).add(&quot;five times&quot;);verify(mockedList, atMost(5)).add(&quot;three times&quot;); verify 函数默认验证的是执行了 times(1)，也就是某个测试函数是否执行了 1 次。因此，times(1) 通常被省略了。 5. 为返回值为void的函数通过Stub抛出异常1234doThrow(new RuntimeException()).when(mockedList).clear();// 调用这句代码会抛出异常mockedList.clear(); 关于 doThrow | doAnswer 等函数的信息请阅读第 12 节。 6. 验证执行执行顺序123456789101112131415161718192021222324252627282930// A. 验证 mock 一个对象的函数执行顺序List singleMock = mock(List.class);// 使用 singleMocksingleMock.add(&quot;was added first&quot;);singleMock.add(&quot;was added second&quot;);// 为该 mock 对象创建一个 inOrder 对象InOrder inOrder = inOrder(singleMock);// 确保 add 函数首先执行的是 add(&quot;was added first&quot;)，然后才是 add(&quot;was added second&quot;)inOrder.verify(singleMock).add(&quot;was added first&quot;);inOrder.verify(singleMock).add(&quot;was added second&quot;);// B. 验证多个 mock 对象的函数执行顺序List firstMock = mock(List.class);List secondMock = mock(List.class);// 使用 mockfirstMock.add(&quot;was called first&quot;);secondMock.add(&quot;was called second&quot;);// 为这两个 mock 对象创建 inOrder 对象InOrder inOrder = inOrder(firstMock, secondMock);// 验证它们的执行顺序inOrder.verify(firstMock).add(&quot;was called first&quot;);inOrder.verify(secondMock).add(&quot;was called second&quot;);// A 和 B 可以按照你的意愿组合在一起 验证执行顺序是非常灵活的：你不需要一个一个的验证所有交互，只需要验证你感兴趣的对象即可。另外，你可以仅通过那些需要验证顺序的 mock 对象来创建 InOrder 对象。 7. 确保交互(interaction)操作不会执行在 mock 对象上1234567891011// 使用 Mock 对象mockOne.add(&quot;one&quot;);// 普通验证verify(mockOne).add(&quot;one&quot;);// 验证某个交互是否从未被执行verify(mockOne, never()).add(&quot;two&quot;);// 验证 mock 对象没有交互过verifyZeroInteractions(mockTwo, mockThree); 8. 查找冗余的调用12345678// 使用 mockmockedList.add(&quot;one&quot;);mockedList.add(&quot;two&quot;);verify(mockedList).add(&quot;one&quot;);// 下面的验证将会失败verifyNoMoreInteractions(mockedList); 一些用户可能会在频繁地使用 verifyNoMoreInteractions()，甚至在每个测试函数中都用。但是 verifyNoMoreInteractions() 并不建议在每个测试函数中都使用。verifyNoMoreInteractions() 在交互测试套件中只是一个便利的验证，它的作用是当你需要验证是否存在冗余调用时。滥用它将导致测试代码的可维护性降低。 never() 是一种更为明显且易于理解的形式。 9. 简化 mock 对象的创建 - @Mock 注解 最小化重复的创建代码 使测试类的代码可读性更高 使验证错误更易于阅读，因为字段名可用于标识 mock 对象 1234567public class ArticleManagerTest { @Mock private ArticleCalculator calculator; @Mock private ArticleDatabase database; @Mock private UserProvider userProvider; private ArticleManager manager; 注意！下面这句代码需要在运行测试函数之前被调用，一般放到测试类的基类或者 test runner 中: 1MockitoAnnotations.initMocks(testClass); 你可以使用内置的 runner: [MockitoJUnitRunner] [runner] 或者一个 rule : MockitoRule。对于 JUnit5 测试，在 45 节有描述。关于 mock 注解的更多信息可以阅读 MockitoAnnotations文档。 10. 为连续的调用做测试桩 (stub)有时我们需要为同一个函数调用的不同的返回值或异常做测试桩。典型的运用就是使用 mock 迭代器。原始版本的 Mockito 并没有这个特性，例如，可以使用 Iterable 或者简单的集合来替换迭代器。这些方法提供了更原始的方式。在一些场景中为连续的调用做测试桩会很有用。示例如下 ： 123456789101112when(mock.someMethod(&quot;some arg&quot;)) .thenThrow(new RuntimeException()) .thenReturn(&quot;foo&quot;);// 第一次调用 : 抛出运行时异常mock.someMethod(&quot;some arg&quot;);// 第二次调用 : 输出 &quot;foo&quot;System.out.println(mock.someMethod(&quot;some arg&quot;));// 后续调用 : 也是输出 &quot;foo&quot;System.out.println(mock.someMethod(&quot;some arg&quot;)); 另外，连续调用的另一种更简短的版本 : 123// 第一次调用时返回 &quot;one&quot;，第二次返回 &quot;two&quot;，第三次返回 &quot;three&quot; when(mock.someMethod(&quot;some arg&quot;)) .thenReturn(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;); 11. 为回调做测试桩Allows stubbing with generic Answer interface.运行为泛型接口 Answer 打桩。 在最初的Mockito里也没有这个具有争议性的特性。我们建议使用thenReturn() 或thenThrow()来打桩。这两种方法足够用于测试或者测试驱动开发。 1234567891011when(mock.someMethod(anyString())).thenAnswer(new Answer() { Object answer(InvocationOnMock invocation) { Object[] args = invocation.getArguments(); Object mock = invocation.getMock(); return &quot;called with arguments: &quot; + args; }});//Following prints &quot;called with arguments: foo&quot;// 输出 : &quot;called with arguments: foo&quot;System.out.println(mock.someMethod(&quot;foo&quot;)); 12. doReturn()、doThrow()、doAnswer()、doNothing()、doCallRealMethod()系列方法的运用通过when(Object)为无返回值的函数打桩有不同的方法,因为编译器不喜欢void函数在括号内… 使用doThrow(Throwable) 替换stubVoid(Object)来为void函数打桩是为了与doAnswer()等函数族保持一致性。 当你想为void函数打桩时使用含有一个exception 参数的doAnswer() : 12345doThrow(new RuntimeException()).when(mockedList).clear();//following throws RuntimeException:// 下面的代码会抛出异常mockedList.clear(); 当你调用doThrow(), doAnswer(), doNothing(), doReturn() and doCallRealMethod() 这些函数时可以在适当的位置调用when()函数. 当你需要下面这些功能时这是必须的: 测试void函数 在受监控的对象上测试函数 不知一次的测试为同一个函数，在测试过程中改变mock对象的行为。 但是在调用when()函数时你可以选择是否调用这些上述这些函数。 阅读更多关于这些方法的信息: doReturn(Object)) doThrow(Throwable)) doThrow(Class)) doAnswer(Answer)) doNothing()) doCallRealMethod()) 13. 监控真实对象你可以为真实对象创建一个监控(spy)对象。当你使用这个spy对象时真实的对象也会也调用，除非它的函数被stub了。尽量少使用spy对象，使用时也需要小心形式，例如spy对象可以用来处理遗留代码。 监控一个真实的对象可以与“局部mock对象”概念结合起来。在1.8之前，mockito的监控功能并不是真正的局部mock对象。原因是我们认为局部mock对象的实现方式并不好，在某些时候我发现一些使用局部mock对象的合法用例。（第三方接口、临时重构遗留代码，完整的文章在这里 ） 123456789101112131415161718192021222324List list = new LinkedList();List spy = spy(list);//optionally, you can stub out some methods:// 你可以为某些函数打桩when(spy.size()).thenReturn(100);//using the spy calls *real* methods// 通过spy对象调用真实对象的函数spy.add(&quot;one&quot;);spy.add(&quot;two&quot;);//prints &quot;one&quot; - the first element of a list// 输出第一个元素System.out.println(spy.get(0));//size() method was stubbed - 100 is printed// 因为size()函数被打桩了,因此这里返回的是100System.out.println(spy.size());//optionally, you can verify// 交互验证verify(spy).add(&quot;one&quot;);verify(spy).add(&quot;two&quot;); 理解监控真实对象非常重要！ 有时，在监控对象上使用when(Object)来进行打桩是不可能或者不切实际的。因此，当使用监控对象时请考虑doReturn|Answer|Throw()函数族来进行打桩。例如 : 12345678910List list = new LinkedList();List spy = spy(list);//Impossible: real method is called so spy.get(0) throws IndexOutOfBoundsException (the list is yet empty)// 不可能 : 因为当调用spy.get(0)时会调用真实对象的get(0)函数,此时会发生IndexOutOfBoundsException异常，因为真实List对象是空的 when(spy.get(0)).thenReturn(&quot;foo&quot;);//You have to use doReturn() for stubbing// 你需要使用doReturn()来打桩doReturn(&quot;foo&quot;).when(spy).get(0); Mockito并不会为真实对象代理函数调用，实际上它会拷贝真实对象。因此如果你保留了真实对象并且与之交互，不要期望从监控对象得到正确的结果。当你在监控对象上调用一个没有被stub的函数时并不会调用真实对象的对应函数，你不会在真实对象上看到任何效果。 因此结论就是 : 当你在监控一个真实对象时，你想在stub这个真实对象的函数，那么就是在自找麻烦。或者你根本不应该验证这些函数。 14. 修改没有测试桩的调用的默认返回值 ( 1.7版本之后 ) 你可以指定策略来创建mock对象的返回值。这是一个高级特性，通常来说，你不需要写这样的测试。然后，它对于遗留系统来说是很有用处的。当你不需要为函数调用打桩时你可以指定一个默认的answer。 12Foo mock = mock(Foo.class, Mockito.RETURNS_SMART_NULLS);Foo mockTwo = mock(Foo.class, new YourOwnAnswer()); 关于RETURNS_SMART_NULLS更多的信息请查看 :RETURNS_SMART_NULLS文档 。 15. 为下一步的断言捕获参数 (1.8版本之后)Mockito以java代码风格的形式来验证参数值 : 即通过使用equals()函数。这也是我们推荐用于参数匹配的方式，因为这样会使得测试代码更简单、简洁。在某些情况下，当验证交互之后要检测真实的参数值时这将变得有用。例如 ： 12345ArgumentCaptor&lt;Person&gt; argument = ArgumentCaptor.forClass(Person.class);// 参数捕获verify(mock).doSomething(argument.capture());// 使用equal断言assertEquals(&quot;John&quot;, argument.getValue().getName()); 警告 : 我们建议使用没有测试桩的ArgumentCaptor来验证，因为使用含有测试桩的ArgumentCaptor会降低测试代码的可读性，因为captor是在断言代码块之外创建的。另一个好处是它可以降低本地化的缺点，因为如果测试桩函数没有被调用，那么参数就不会被捕获。总之，ArgumentCaptor与自定义的参数匹配器相关(可以查看ArgumentMatcher类的文档 )。这两种技术都能用于检测外部传递到Mock对象的参数。然而，使用ArgumentCaptor在以下的情况下更合适 : 自定义不能被重用的参数匹配器 你仅需要断言参数值 自定义参数匹配器相关的资料你可以参考ArgumentMatcher文档。 16. 真实的局部mocks (1.8版本之后)在内部通过邮件进行了无数争辩和讨论后，最终 Mockito 决定支持部分测试，早前我们不支持是因为我们认为部分测试会让代码变得糟糕。然而，我们发现了部分测试真正合理的用法。详情点这 在 Mockito 1.8 之前，spy() 方法并不会产生真正的部分测试，而这无疑会让一些开发者困惑。更详细的内容可以看：这里 或 Java 文档) 12345678//you can create partial mock with spy() method:List list = spy(new LinkedList());//you can enable partial mock capabilities selectively on mocks:Foo mock = mock(Foo.class);//Be sure the real implementation is 'safe'.//If real implementation throws exceptions or depends on specific state of the object then you're in trouble.when(mock.someMethod()).thenCallRealMethod(); 一如既往，你会去读部分测试的警告部分：面向对象编程通过将抽象的复杂度拆分为一个个独立，精确的 SRPy 对象中，降低了抽象处理的复杂度。那部分测试是怎么遵循这个规范的呢？事实上部分测试并没有遵循这个规范……部分测试通常意味着抽象的复杂度被移动到同一个对象的不同方法中，在大多数情况下，这不会是你想要的应用架构方式。 然而，在一些罕见的情况下部分测试才会是易用的：处理不能轻易修改的代码（第三方接口，临时重构的遗留代码等等）。然而，为了新的，测试驱动和架构优秀的代码，我是不会使用部分测试的。 17. 重置mocks对象 (1.8版本之后)聪明的 Mockito 使用者很少会用到这个特性，因为他们知道这是出现糟糕测试单元的信号。通常情况下你不会需要重设你的测试单元，只需要为每一个测试方法重新创建一个测试单元就可以了。 如果你真的想通过 reset() 方法满足某些需求的话，请考虑实现简单，小而且专注于测试方法而不是冗长，精确的测试。首先可能出现的代码异味就是测试方法中间那的 reset() 方法。这可能意味着你已经过度测试了。请遵循测试方法的呢喃：请让我们小，而且专注于单一的行为上。在 Mockito 邮件列表中就有好几个讨论是和这个有关的。 添加 reset() 方法的唯一原因就是让它能与容器注入的测试单元协作。详情看 issue 55 或 FAQ。 别自己给自己找麻烦，reset() 方法在测试方法的中间确实是代码异味。 123456List mock = mock(List.class);when(mock.size()).thenReturn(10);mock.add(1);reset(mock);//at this point the mock forgot any interactions &amp; stubbing 18. 故障排查与验证框架的使用 (1.8版本之后)首先，如果出现了任何问题，我建议你先看 Mockito FAQ。 任何你提的问题都会被提交到 Mockito 的邮件列表中。 然后你应该知道 Mockito 会验证你是否始终以正确的方式使用它，对此有疑惑的话不妨看看 validateMockitoUsage()) 的文档说明。 19. 行为驱动开发的别名 (1.8版本之后)行为驱动开发实现测试单元的模式将 //given //when //then comments 视作测试方法的基础，这也是我们实现单元测试时被建议做的！ 你可以在这开始学习有关 BDD 的知识 问题是当信息没有很好地与 //given //when //then comments 交互时，扮演规范角色的测试桩 API 就会出现问题。这是因为测试桩属于给定测试单元的组件，而且不是任何测试的组件。因此 BDDMockito 类介绍了一个别名，使你的测试桩方法调用 BDDMockito.given(Object)) 方法。现在它可以很好地和给定的 BDD 模式的测试单元组件进行交互。 123456789101112131415import static org.mockito.BDDMockito.*;Seller seller = mock(Seller.class);Shop shop = new Shop(seller);public void shouldBuyBread() throws Exception { //given given(seller.askForBread()).willReturn(new Bread()); //when Goods goods = shop.buyBread(); //then assertThat(goods, containBread());} 20. 序列化mock对象模拟对象可以被序列化。有了这个特性你就可以在依赖被序列化的情况下使用模拟对象了。 警告：这个特性很少在单元测试中被使用。 To create serializable mock use MockSettings.serializable()): 这个特性通过 BDD 拥有不可考外部依赖的特性的具体用例实现，来自外部依赖的 Web 环境和对象会被序列化，然后在不同层之间被传递。 1List serializableMock = mock(List.class, withSettings().serializable()); The mock can be serialized assuming all the normal serialization requirements are met by the class. 模拟对象能被序列化假设所有普通的序列化要求都被类满足了。 让一个真实的侦查对象可序列化需要多一些努力，因为 spy(…) 方法没有接收 MockSettings 的重载版本。不过不用担心，你几乎不可能用到这。 12345List&lt;Object&gt; list = new ArrayList&lt;Object&gt;();List&lt;Object&gt; spy = mock(ArrayList.class, withSettings() .spiedInstance(list) .defaultAnswer(CALLS_REAL_METHODS) .serializable()); 21. 新的注解 : @Captor,@Spy,@ InjectMocks (1.8.3版本之后)V1.8.3 带来的新注解在某些场景下可能会很实用 @Captor 简化 ArgumentCaptor 的创建 - 当需要捕获的参数是一个令人讨厌的通用类，而且你想避免编译时警告。 @Spy - 你可以用它代替 spy(Object) 方法) @InjectMocks - 自动将模拟对象或侦查域注入到被测试对象中。需要注意的是 @InjectMocks 也能与 @Spy 一起使用，这就意味着 Mockito 会注入模拟对象到测试的部分测试中。它的复杂度也是你应该使用部分测试原因。 所有新的注解仅仅在 MockitoAnnotations.initMocks(Object)) 方法中被处理，就像你在 built-in runner 中使用的 @Mock 注解：MockitoJUnitRunner 或 规范: MockitoRule. 22. 验证超时 (1.8.5版本之后)允许带有暂停的验证。这使得一个验证去等待一段特定的时间，以获得想要的交互而不是如果还没有发生事件就带来的立即失败。在并发条件下的测试这会很有用。 感觉起来这个特性应该很少被使用 - 指出更好的测试多线程系统的方法。 还没有实现去和 InOrder 验证协作。 例子： 1234567891011121314//passes when someMethod() is called within given time spanverify(mock, timeout(100)).someMethod();//above is an alias to:verify(mock, timeout(100).times(1)).someMethod();//passes when someMethod() is called *exactly* 2 times within given time spanverify(mock, timeout(100).times(2)).someMethod();//passes when someMethod() is called *at least* 2 times within given time spanverify(mock, timeout(100).atLeast(2)).someMethod();//verifies someMethod() within given time span using given verification mode//useful only if you have your own custom verification modes.verify(mock, new Timeout(100, yourOwnVerificationMode)).someMethod(); 23. 自动初始化被@Spies, @InjectMocks注解的字段以及构造函数注入 (1.9.0版本之后)Mockito 现在会通过注入构造方法、setter 或域注入尽可能初始化带有 @Spy 和 @InjectMocks 注解的域或方法。 为了利用这一点特性，你需要使用 MockitoAnnotations.initMocks(Object)), MockitoJUnitRunner 或 MockitoRule。 为了 InjectMocks 请在 Java 文档中了解更多可用的技巧和注入的规范 1234567//instead:@Spy BeerDrinker drinker = new BeerDrinker();//you can write:@Spy BeerDrinker drinker;//same applies to @InjectMocks annotation:@InjectMocks LocalPub; 24. 单行测试桩 (1.9.0版本之后)Mockito 现在允许你在使用测试桩时创建模拟对象。基本上，它允许在一行代码中创建一个测试桩，这对保持代码的整洁很有用。举例来说，有些乏味的测试桩会被创建，并在测试初始化域时被打入，例如： 1234public class CarTest { Car boringStubbedCar = when(mock(Car.class).shiftGear()).thenThrow(EngineNotStarted.class).getMock(); @Test public void should... {} 25. 验证被忽略的测试桩 (1.9.0版本之后)Mockito 现在允许为了验证无视测试桩。在与 verifyNoMoreInteractions() 方法或验证 inOrder() 方法耦合时，有些时候会很有用。帮助避免繁琐的打入测试桩调用验证 - 显然我们不会对验证测试桩感兴趣。 警告，ignoreStubs() 可能会导致 verifyNoMoreInteractions(ignoreStubs(…)) 的过度使用。谨记在心，Mockito 没有推荐用 verifyNoMoreInteractions()) 方法连续地施用于每一个测试中，原因在 Java 文档中有。 一些例子： 1234567891011verify(mock).foo();verify(mockTwo).bar();//ignores all stubbed methods:verifyNoMoreInvocations(ignoreStubs(mock, mockTwo));//creates InOrder that will ignore stubbedInOrder inOrder = inOrder(ignoreStubs(mock, mockTwo));inOrder.verify(mock).foo();inOrder.verify(mockTwo).bar();inOrder.verifyNoMoreInteractions(); 更好的例子和更多的细节都可以在 Java 文档的 ignoreStubs(Object…)) 部分看到。 26. mock详情 (1.9.5版本之后)为了区别一个对象是模拟对象还是侦查对象： 12Mockito.mockingDetails(someObject).isMock();Mockito.mockingDetails(someObject).isSpy(); MockingDetails.isMock()) 和 MockingDetails.isSpy()) 方法都会返回一个布尔值。因为一个侦查对象只是模拟对象的一种变种，所以 isMock() 方法在对象是侦查对象是会返回 true。在之后的 Mockito 版本中 MockingDetails 会变得更健壮，并提供其他与模拟对象相关的有用信息，例如：调用，测试桩信息，等等…… 27. 委托调用真实实例 (Since 1.9.5)当使用常规的 spy API 去 mock 或者 spy 一个对象很困难时可以用 delegate 来 spy 或者 mock 对象的某一部分。从 Mockito 的 1.10.11 版本开始， delegate 有可能和 mock 的类型相同也可能不同。如果不是同一类型，delegate 类型需要提供一个匹配方法否则就会抛出一个异常。下面是关于这个特性的一些用例: 带有 interface 的 final 类 已经自定义代理的对象 带有 finalize 方法的特殊对象，就是避免重复执行。 和常规 spy 的不同: 标准的 spy (spy(Object)) 包含被 spy 实例的所有状态信息，方法在 spy 对象上被调用。被 spy 的对象只在 mock创建时被用来拷贝状态信息。如果你通过标准 spy 调用一个方法，这个 spy 会调用其内部的其他方法记录这次操作，以便后面验证使用。等效于存根 (stubbed)操作。 mock delegates 只是简单的把所有方法委托给 delegate。delegate 一直被当成它代理的方法使用。如果你从一个 mock 调用它被委托的方法，它会调用其内部方法，这些调用不会被记录，stubbing 在这里也不会生效。Mock 的 delegates 相对于标准的 spy 来说功能弱了很多，不过在标准 spy 不能被创建的时候很有用。 更多信息可以看这里 AdditionalAnswers.delegatesTo(Object). 28. MockMaker API (Since 1.9.5)为了满足用户的需求和 Android 平台使用。Mockito 现在提供一个扩展点，允许替换代理生成引擎。默认情况下，Mockito 使用 cglib 创建动态代理。 这个扩展点是为想要扩展 Mockito 功能的高级用户准备的。比如，我们现在就可以在 dexmaker 的帮助下使用 Mockito测试 Android。 更多的细节，原因和示例请看 MockMaker 的文档。 29. (new) BDD 风格的验证 (Since 1.10.0)开启 Behavior Driven Development (BDD) 风格的验证可以通过 BBD 的关键词 then 开始验证。 1234567given(dog.bark()).willReturn(2);// when...then(person).should(times(2)).ride(bike); 更多信息请查阅 BDDMockito.then(Object) . 30. (new) Spying 或 mocking 抽象类 (Since 1.10.12)现在可以方便的 spy 一个抽象类。注意，过度使用 spy 或许意味着代码的设计上有问题。(see spy(Object)). 之前，spying 只可以用在实例对象上。而现在新的 API 可以在创建一个 mock 实例时使用构造函数。这对 mock一个抽象类来说是很重要的，这样使用者就不必再提供一个抽象类的实例了。目前的话只支持无参构造函数，如果你认为这样还不够的话欢迎向我们反馈。 1234567891011//convenience API, new overloaded spy() method: SomeAbstract spy = spy(SomeAbstract.class); //Robust API, via settings builder: OtherAbstract spy = mock(OtherAbstract.class, withSettings() .useConstructor().defaultAnswer(CALLS_REAL_METHODS)); //Mocking a non-static inner abstract class: InnerAbstract spy = mock(InnerAbstract.class, withSettings() .useConstructor().outerInstance(outerInstance).defaultAnswer(CALLS_REAL_METHODS)); 更多信息请见 MockSettings.useConstructor() . 31. (new) Mockito mocks 可以通过 classloaders 序列化/反序列化 (Since 1.10.0) Mockito 通过 classloader 引入序列化。和其他形式的序列化一样，所有 mock 层的对象都要被序列化， 包括 answers。因为序列化模式需要大量的工作，所以这是一个可选择设置。 12345// 常规的 serializationmock(Book.class, withSettings().serializable());// 通过 classloaders 序列化mock(Book.class, withSettings().serializable(ACROSS_CLASSLOADERS)); 更多信息请查看 MockSettings.serializable(SerializableMode). 32. (new) Deep stubs 更好的泛型支持 (Since 1.10.0) Deep stubbing 现在可以更好的查找类的泛型信息。这就意味着像这样的类 不必去 mock 它的行为就可以使用。 123456789class Lines extends List&lt;Line&gt; { // ... } lines = mock(Lines.class, RETURNS_DEEP_STUBS); // Now Mockito understand this is not an Object but a Line Line line = lines.iterator().next(); 请注意，大多数情况下 mock 返回一个 mock 对象是错误的。 33. (new) Mockito JUnit rule (Since 1.10.17)Mockito 现在提供一个 JUnit rule。目前为止，有两种方法可以初始化 fields ，使用 Mockito 提供的注解比如@Mock, @Spy, @InjectMocks 等等。 用 @RunWith(@MockitoJUnitRunner.class) 标注 JUnit 测试类 在 @Before 之前调用 MockitoAnnotations.initMocks(Object) 现在你可以选择使用一个 rule: 12345@RunWith(YetAnotherRunner.class)public class TheTest { @Rule public MockitoRule mockito = MockitoJUnit.rule(); // ...} 更多信息到这里查看 MockitoJUnit.rule(). 34. (new) 开启和关闭 plugins (Since 1.10.15)这是一个测试特性，可以控制一个 mockito-plugin 开启或者关闭。详情请查看 PluginSwitch ###35. 自定义验证失败信息 (Since 2.0.0) 允许声明一个在验证失败时输出的自定义消息示例: 12345// will print a custom message on verification failureverify(mock, description(&quot;This will print on failure&quot;)).someMethod();// will work with any verification modeverify(mock, times(2).description(&quot;someMethod should be called twice&quot;)).someMethod();","link":"/mockito-zh-doc.html"},{"title":"利用 Let&#39;s Encrypt 配置 Apache SSL 证书","text":"HTTPS（全称：Hyper Text Transfer Protocol over Secure Socket Layer），是以安全为目标的 HTTP 通道，简单讲是 HTTP 的安全版。 即 HTTP 下加入 SSL 层，HTTPS 的安全基础是 SSL，因此加密的详细内容就需要 SSL。 本文介绍如何使用 Let’s Encrypt 签发免费证书实现 Apache HTTPS。 Let’s EncryptLet’s Encrypt 是一个由非营利性组织 互联网安全研究小组（ISRG）提供的免费、自动化和开放的证书颁发机构（CA）。 简单的说，借助 Let’s Encrypt 颁发的证书可以为我们的网站免费启用 HTTPS(SSL/TLS)。 Let’s Encrypt 免费证书的签发/续签都是脚本自动化的，官方提供了几种证书的申请方式方法，点击 此处 快速浏览。 官方推荐使用 Certbot 客户端来签发证书，可以帮我们获取免费的 Let’s Encrypt 证书。Certbot 支持所有 Unix 内核的操作系统。 安装 Certbot 并生成证书1$ sudo yum install certbot -y 安装完成后，可以先通过运行 certbot 进行测试，如无问题则继续下一步。 查看端口是否被占用，有其他服务（例如 Nginx 或者 Apache）占用了 80 端口和 443 端口，就必须先停止这些服务，在证书生成完毕后再启用。12$ netstat -tunlp | grep :443$ netstat -tunlp | grep :80 否则在执行下一步生成证书时会报 Problem binding to port 80: Could not bind to IPv4 or IPv6.。 接着继续生成证书1$ certbot certonly --standalone -d www.fcj.one 证书生成完毕后，可以在 /etc/letsencrypt/live/ 目录下看到对应域名的文件夹找到证书。 这时候我们的第一步生成证书已经完成了，接下来就是配置 Apache 服务器，启用 HTTPS。 Apache 启用 HTTPS打开 Apache 安装目录下 conf 目录中的 httpd.conf 文件，找到以下内容并去掉 ‘#’。 1LoadModule ssl_module modules/mod_ssl.so 如果不存在可手动添加，前提是已经安装 ssl 模块：yum install mod_ssl。 然后在 /etc/httpd/conf/httpd.conf 添加以下配置： 12345678&lt;VirtualHost *:443&gt; DocumentRoot &quot;/var/www/html&quot; ServerName www.fcj.one SSLEngine on SSLCertificateFile /etc/letsencrypt/live/www.fcj.one/cert.pem SSLCertificateKeyFile /etc/letsencrypt/live/www.fcj.one/privkey.pem SSLCertificateChainFile /etc/letsencrypt/live/www.fcj.one/chain.pem&lt;/VirtualHost&gt; 重启 Apache 服务器：service httpd restart 证书续约Let’s Encrypt 提供的免费证书只有 90 天的有效期，必须在证书到期之前，重新获取这些证书， certbot 给我们提供了一个很方便的命令 certbot renew。 通过这个命令，会自动检查系统内的证书，并且自动更新这些证书。 这里直接用 crontab 设置每月定时更新即可。crontab 用法参考 10 4 * */2 * certbot renew --pre-hook &quot;systemctl stop httpd&quot; --post-hook &quot;systemctl start httpd&quot; 每隔两个月凌晨四点进行证书更新，并先行停止 httpd 服务，之后再开启。 防火墙开放 443 端口如果你设置了防火墙，请在防火墙中开启 443 端口。 如果是 firewalld 的可以使用下面命令：123sudo firewall-cmd --add-service=httpsudo firewall-cmd --add-service=httpssudo firewall-cmd --runtime-to-permanent 如果是iptables的可以使用下面命令12sudo iptables -I INPUT -p tcp -m tcp --dport 80 -j ACCEPTsudo iptables -I INPUT -p tcp -m tcp --dport 443 -j ACCEPT 参考 https://www.jianshu.com/p/3aa5cb957d9f https://blog.csdn.net/qq_20240999/article/details/87618667 http://www.cnblogs.com/hi-bazinga/archive/2012/04/23/2466605.html","link":"/apache-https.html"},{"title":"利用 Travis CI 自动部署 Hexo 博客最佳实践","text":". Travis-CI 介绍 CI 即 Continuous Integration，译为持续集成。持续集成指的是只要代码有变更，都会触发 CI 服务器自动对项目运行构建和测试，反馈结果，最终甚至自动部署到测试或生产环境。 Travis CI 是一个提供持续集成功能的平台，在 Github 上，可以添加 Travis CI 应用，当有 code push 时候，会推送通知到 Travis，根据设置的脚本运行指定任务。和 Jenkins 不同，Travis CI 是由官方远端提供服务器而无需自己搭建，且只支持 Github，不支持其他代码托管服务。 目前有两个站点: travis-ci.org 对于所有 public 项目完全免费 travis-ci.com 只针对 private 项目，提供更多一些额外功能，如 cache，并行 build 个数 两个站点只能看到各自的项目，不能通用。 步骤通常更新一篇 Hexo 博客文章，基本流程是： 本地新建 post 页面 在文本编辑器里用 Markdown 语法编辑新建页面 本地生成 public 文件：hexo g &amp;&amp; gulp 启动本地测试web server：hexo s --debug 浏览器打开 http://localhost:4000/, 浏览生成文章 如果满意，即可部署到Github page仓库或者 VPS 上：hexo d 下面主要介绍如何利用 Travis CI 自动完成第 3-6 步. 前置条件 生成 SSH key 托管 Hexo 博客的 Github仓库，hexo 分支为源代码，master 分支存放生成的静态博客文件。参考 发布博客的 VPS，并可以通过 hexo-deployer-git 发布。参考 已经配置好 gulp 实现博文压缩。参考 开启 Travis CI直接进入 travis-ci.org 官网，用 Github 账号授权登录。在右上角账户头像处点击进入 Settings，在 Repositories Tab 页点击 Sync now 同步你的 Github 项目。选中 Hexo 博客项目将默认的 off 改变为 on 开启项目的持续集成。 加密 SSH 私钥 当 push 到 github 仓库时 travis 自动读取一个名为 .travis.yml 配置文件来完成 hexo 的 generate 和 deploy，但是 deploy 需要 VPS 和 Github 的 ssh 写权限，所以需要将 ssh key 上传到项目中，为方便自动化部署，本地系统、Github 和 VPS 上都使用同一套 ssh 公钥和秘钥 （下文的 id_rsa 和 id_rsa.pub）。因为 github 的项目是公开的，需要将 ssh key 加密放到项目中，travis 运行时再解密生成 key，保证秘钥安全性。 travis 加密命令是要通过 gem 安装的，gem 依赖 ruby 环境，请确保 ruby 已经安装。gem 在国内不太好访问，建议在 vps 上博客的项目目录里（没有就 clone一个，因为下面的 –add 会修改 .travis.yml ）安装执行下面的命令： 123gem install travistravis login # 使用 github 帐号和密码登录travis encrypt-file id_rsa --add # 加密 id_rsa 私钥，--add 将解密命令添加到 .travis.yml 集成 build 图标在 Travis CI 控制台里，点击 build:passing 图标，选择 Markdown 样式，粘贴到项目 Readme 里即可。 .travis.yml12345678910111213141516171819202122language: node_jsnode_js: 8install:- npm install -g hexo-cli- npm install -g hexo-deployer-git- npm install -g gulp- npm installaddons: ssh_known_hosts: host-ip:ssh-portscript:- hexo g- gulp- hexo dbranches: only: - hexobefore_install:- openssl aes-256-cbc -K $encrypted_34f58abb81d6_key -iv $encrypted_34f58abb81d6_iv -in id_rsa.enc -out ~/.ssh/id_rsa -d- chmod 600 ~/.ssh/id_rsa 配置完成后，以后当你本地编辑完 md 文件后，只需要运行 git push，推送代码到 Github 就会触发 Travis CI 自动生成 build，部署新的博客内容。 .travis.yml 字段解析ssh known_hosts 因为 travis-ci 默认只添加了 github.com, gist.github.com 和 ssh.github.com 为 known_hosts，hexo d 执行时会提示是否添加地址到 known_hosts，但是 travis-ci 里不能输入确认，所以需要将服务器的 IP 和端口添加到 known_hosts12addons: ssh_known_hosts: ssh_known_hosts: host-ip:ssh-port 参考资料 https://www.karlzhou.com/2016/05/28/travis-ci-deploy-blog/ https://blog.csdn.net/u012373815/article/details/53574002 https://blog.csdn.net/qq_23079443/article/details/79015225 https://segmentfault.com/a/1190000005687985 http://blog.acwong.org/2016/03/20/auto-deploy-hexo-with-travis-CI/ http://www.ruanyifeng.com/blog/2017/12/travis_ci_tutorial.html","link":"/hexo-travis.html"},{"title":"Hexo 博客静态资源压缩","text":"静态资源压缩可以优化网页的访问速度，提高用户体验。 在站点的根目录下执行以下命令：12$ npm install gulp -g$ npm install gulp-minify-css gulp-uglify gulp-htmlmin gulp-htmlclean gulp --save 在博客根目录下新建 gulpfile.js，并填入以下内容：123456789101112131415161718192021222324252627282930313233var gulp = require('gulp');var minifycss = require('gulp-minify-css');var uglify = require('gulp-uglify');var htmlmin = require('gulp-htmlmin');var htmlclean = require('gulp-htmlclean');// 压缩 public 目录 cssgulp.task('minify-css', function() { return gulp.src('./public/**/*.css') .pipe(minifycss()) .pipe(gulp.dest('./public'));});// 压缩 public 目录 htmlgulp.task('minify-html', function() { return gulp.src('./public/**/*.html') .pipe(htmlclean()) .pipe(htmlmin({ removeComments: true, minifyJS: true, minifyCSS: true, minifyURLs: true, })) .pipe(gulp.dest('./public'))});// 压缩 public/js 目录 jsgulp.task('minify-js', function() { return gulp.src('./public/**/*.js') .pipe(uglify()) .pipe(gulp.dest('./public'));});// 执行 gulp 命令时执行的任务gulp.task('default', [ 'minify-html','minify-css','minify-js']); 执行 hexo clean &amp; hexo g &amp;&amp; gulp 就会根据 gulpfile.js 中的配置，对 public 目录中的静态资源文件进行压缩。","link":"/hexo-gulp-post.html"},{"title":"后端书单","text":"读万卷书，行万里路。 《Java核心技术 卷I：基础知识（原书第10版）》 《Java并发编程实战》 《Java高并发编程详解：多线程与架构设计》 《深入理解Java虚拟机：JVM高级特性与最佳实践（第2版）》 《Spring实战（第4版）》 《深入浅出Spring Boot 2.x》 《Spring Cloud微服务实战》 《Redis设计与实现》 《Redis开发与运维》 《高性能MySQL（第3版）》 《MySQL技术内幕：InnoDB存储引擎（第2版）》 《大型网站系统与Java中间件实践》 《从Paxos到Zookeeper：分布式一致性原理与实践》 《Tomcat架构解析》 《Netty权威指南（第2版）》 《深入分析Java Web技术内幕（修订版）》 《亿级流量网站架构核心技术——跟开涛学搭建高可用高并发系统》 《重构：改善既有代码的设计（第2版）》 《数据结构与算法分析：Java语言描述（原书第3版）》 《剑指Offer：名企面试官精讲典型编程题（第2版）》","link":"/backend-book.html"},{"title":"Git 常用命令指南","text":"* 首次提交代码至远程仓库新建仓库123456$ git clone repository_url$ cd project_folder$ touch README.md$ git add README.md$ git commit -m &quot;add README&quot;$ git push -u origin master 本地仓库目录已存在123456$ cd existing_folder$ git init$ git remote add origin repository_url$ git add .$ git commit -m &quot;Initial commit&quot;$ git push -u origin master Git 分支命令 查看所有分支 1$ git branch # 查看所有分支，当前分支前面会标一个 * 号 创建新分支 123$ git checkout -b dev # 相当于以下两条命令$ git branch dev # 新建 dev 分支$ git checkout dev # 切换到 dev 分支 切换分支 123$ git checkout dev # 切换到 dev 分支$ git add .$ git commit -m &quot;dev&quot; # 在 dev 分支上提交 合并分支 1234$ git checkout master # 切换到主分支$ git merge dev # 将 dev 分支合并到当前分支（主分支）$ git push # 向远程仓库提交 master 分支$ git checkout dev # 切换回 dev 分支 推送分支 1$ git push origin dev # 向远程仓库推送 dev 分支 删除分支 12$ git brach -d dev # 删除本地 dev 分支$ git push orgin :dev # 删除远程 dev 分支 fork 项目后与源项目同步更新 配置上游项目地址。将你 fork 的项目地址配置到自己的项目上。比如我 fork 了一个项目，原项目是 theme-next/hexo-theme-next.git，我的项目就是 ChangingFond/hexo-theme-next.git。使用以下命令来配置。 1$ git remote add upstream https://github.com/theme-next/hexo-theme-next.git 查看一下配置状况，上游项目的地址已经被加进来了。 12345$ git remote -vorigin git@github.com:ChangingFond/hexo-theme-next.git.git (fetch)origin git@github.com:ChangingFond/hexo-theme-next.git.git (push)upstream https://github.com/theme-next/hexo-theme-next.git (fetch)upstream https://github.com/theme-next/hexo-theme-next.git (push) 获取上游项目更新。使用 fetch 命令更新，fetch 后会被存储在一个本地分支 upstream/master 上。 1$ git fetch upstream 合并到本地分支。切换到 master 分支，合并 upstream/master 分支。 1$ git merge upstream/master 提交推送。根据自己情况提交推送自己项目的代码。 1$ git push origin master 由于项目已经配置了上游项目的地址，所以如果 fork 的项目再次更新，重复步骤 3、4、5即可。 Git 远程分支覆盖本地分支123$ git fetch --all$ git reset --hard origin/master (master 为要拉取的远程分支名)$ git pull","link":"/git-tutorial.html"},{"title":"Elasticsearch配置文件详解","text":"Elasticsearch的配置文件位于/es-path/conf/elasticsearch.yml，本文基于elasticsearch 6.x版本对配置文件进行详细说明。对于未提及的配置参数可查阅 https://www.elastic.co/guide/en/elasticsearch/reference/current/modules.html 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225# ======================== Elasticsearch Configuration =========================## NOTE: Elasticsearch comes with reasonable defaults for most settings.# Before you set out to tweak and tune the configuration, make sure you# understand what are you trying to accomplish and the consequences.## The primary way of configuring a node is via this file. This template lists# the most important settings you may want to configure for a production cluster.## Please consult the documentation for further information on configuration options:# https://www.elastic.co/guide/en/elasticsearch/reference/index.html## ---------------------------------- Cluster -----------------------------------## Use a descriptive name for your cluster:# 配置es的集群名称，默认为elasticsearch。es会自动发现在同一网段下的es集群，如果在同一网段下有多个集群，可以用此属性来区分不同的集群。cluster.name: elasticsearch## ------------------------------------ Node ------------------------------------## Use a descriptive name for the node:# 节点名称node.name: node-master## 指定该节点是否有资格被选举成为master，默认是true，es默认集群中的第一台机器为master，如果这台机器宕机就会重新选举master。node.master: true## 指定该节点是否存储索引数据，默认为true。node.data: true## 默认情况下，多个节点可以在同一个安装路径启动，如果想让es只启动一个节点，可以进行如下设置# node.max_local_storage_nodes: 1## Add custom attributes to the node:## 指定节点的部落属性，这是一个比集群更大的范围。#node.attr.rack: r1## ----------------------------------- Index ------------------------------------# 设置索引的分片数,默认为5#index.number_of_shards: 5# 设置索引的副本数,默认为1:#index.number_of_replicas: 1# 配置文件中提到的最佳实践是,如果服务器够多,可以将分片提高,尽量将数据平均分布到大集群中去# 同时,如果增加副本数量可以有效的提高搜索性能# 需要注意的是,&quot;number_of_shards&quot; 是索引创建后一次生成的,后续不可更改设置# &quot;number_of_replicas&quot; 是可以通过API去实时修改设置的# ----------------------------------- Paths ------------------------------------## Path to directory where to store the data (separate multiple locations by comma):# 设置索引数据的存储路径，默认是es根目录下的data文件夹，可以设置多个存储路径，用逗号隔开，如 path.data: /path/to/data1,/path/to/data2#path.data: /path/to/data## Path to conf files:# 设置配置文件的存储路径，默认是es根目录下的config文件夹。#path.conf: /path/to/conf## Path to log files:# 设置日志文件的存储路径，默认是es根目录下的logs文件夹。#path.logs: /path/to/logs## Path to temp files:# 设置临时文件的存储路径，默认是es根目录下的work文件夹。#path.work: /path/to/work## Path to plugin files:# 设置插件的存放路径，默认是es根目录下的plugins文件夹。#path.plugins: /path/to/plugins## ----------------------------------- Memory -----------------------------------## Lock the memory on startup:# 设置为true来锁住内存。因为当jvm开始swapping时es的效率会降低，所以要保证它不swap。# 可以把ES_MIN_MEM和ES_MAX_MEM两个环境变量设置成同一个值，并且保证机器有足够的内存分配给es。# 同时也要允许elasticsearch的进程可以锁住内存，linux下可以通过`ulimit -l unlimited`命令。#bootstrap.memory_lock: true## Make sure that the heap size is set to about half the memory available# on the system and that the owner of the process is allowed to use this# limit.## Elasticsearch performs poorly when the system is swapping the memory.## Cache部分:# es有很多种方式来缓存其内部与索引有关的数据.其中包括filter cache# filter cache部分:# filter cache是用来缓存filters的结果的.默认的cache type是node type.# node type的机制是所有的索引内部的分片共享filter cache.node type采用的方式是LRU方式.# 即:当缓存达到了某个临界值之后，es会将最近没有使用的数据清除出filter cache.使让新的数据进入es.# 这个临界值的设置方法如下：indices.cache.filter.size 值类型：eg.:512mb 20%。默认的值是10%。# out of memory错误避免过于频繁的查询时集群假死# 1.设置es的缓存类型为Soft Reference,它的主要特点是据有较强的引用功能.# 只有当内存不够的时候,才进行回收这类内存,因此在内存足够的时候,它们通常不被回收.# 另外,这些引用对象还能保证在Java抛出OutOfMemory异常之前,被设置为null.# 它可以用于实现一些常用图片的缓存,实现Cache的功能,保证最大限度的使用内存而不引起OutOfMemory.# 在es的配置文件加上index.cache.field.type: soft即可.# 2.设置es最大缓存数据条数和缓存失效时间,通过设置index.cache.field.max_size: 50000把缓存field的最大值设置为50000,# 设置index.cache.field.expire: 10m把过期时间设置成10分钟.# index.cache.field.max_size: 50000# index.cache.field.expire: 10m# index.cache.field.type: soft# field data部分&amp;&amp;circuit breaker部分：# 用于fielddata缓存的内存数量,主要用于当使用排序,faceting操作时,elasticsearch会将一些热点数据加载到内存中来提供给客户端访问,# 但是这种缓存是比较珍贵的,所以对它进行合理的设置.# 可以使用值：eg:50mb 或者 30％(节点 node heap内存量),默认是：unbounded #indices.fielddata.cache.size： unbounded# field的超时时间.默认是-1,可以设置的值类型: 5m #indices.fielddata.cache.expire: -1# circuit breaker部分:# 断路器是elasticsearch为了防止内存溢出的一种操作,每一种circuit breaker都可以指定一个内存界限触发此操作,# 这种circuit breaker的设定有一个最高级别的设定:indices.breaker.total.limit 默认值是JVM heap的70%.# 当内存达到这个数量的时候会触发内存回收。# 另外还有两组子设置：#indices.breaker.fielddata.limit:当系统发现fielddata的数量达到一定数量时会触发内存回收.默认值是JVM heap的70%#indices.breaker.fielddata.overhead:在系统要加载fielddata时会预估,发现要加载进内存的值超过limit * overhead时会进行进行内存回收.默认是1.03#indices.breaker.request.limit:这种断路器是elasticsearch为了防止OOM(内存溢出),在每次请求数据时设定了一个固定的内存数量.默认值是40%#indices.breaker.request.overhead:同上,也是elasticsearch在发送请求时设定的一个预估系数,用来防止内存溢出.默认值是1# Translog部分:# 每一个分片(shard)都有一个transaction log或者是与它有关的预写日志,(write log),# 在es进行索引(index)或者删除(delete)操作时会将没有提交的数据记录在translog之中,# 当进行flush 操作的时候会将tranlog中的数据发送给Lucene进行相关的操作.一次flush操作的发生基于如下的几个配置#index.translog.flush_threshold_ops:当发生多少次操作时进行一次flush.默认是 unlimited #index.translog.#flush_threshold_size:当translog的大小达到此值时会进行一次flush操作.默认是512mb#index.translog.flush_threshold_period:在指定的时间间隔内如果没有进行flush操作,会进行一次强制flush操作.默认是30m#index.translog.interval:多少时间间隔内会检查一次translog,来进行一次flush操作.es会随机的在这个值到这个值的2倍大小之间进行一次操作,默认是5s#index.gateway.local.sync:多少时间进行一次的写磁盘操作,默认是5s# 以上的translog配置都可以通过API进行动态的设置## ---------------------------------- Network -----------------------------------## Set the bind address to a specific IP (IPv4 or IPv6):# 设置本机器绑定的监听ip地址，默认为0.0.0.0。network.host: 127.0.0.1## Set a custom port for HTTP:# 设置对外服务的http端口，默认为9200。http.port: 9200## 设置内容的最大容量，默认100mb# http.max_content_length: 100mb## 是否使用http协议对外提供服务，默认为true，开启。# http.enabled: false## 设置节点间交互的tcp端口，默认是9300。transport.tcp.port: 9300## 设置是否压缩tcp传输时的数据，默认为false，不压缩。# transport.tcp.compress: false## For more information, consult the network module documentation.## --------------------------------- Discovery ----------------------------------## Pass an initial list of hosts to perform discovery when new node is started:# The default list of hosts is [&quot;127.0.0.1&quot;, &quot;[::1]&quot;]# 设置集群中master节点的初始列表，可以通过这些节点来自动发现新加入集群的节点，默认的通讯端口是9300。discovery.zen.ping.unicast.hosts: [&quot;host1&quot;, &quot;host2:port&quot;, &quot;host3[portX-portY]&quot;]## Prevent the &quot;split brain&quot; by configuring the majority of nodes (total number of master-eligible nodes / 2 + 1):# 设置这个参数来保证集群中的节点可以知道其它N个有master资格的节点。默认为1，对于大的集群来说，可以设置大一点的值（2-4）#discovery.zen.minimum_master_nodes: 1## 设置集群中自动发现其它节点时ping连接超时时间，默认为3秒，对于比较差的网络环境可以高点的值来防止自动发现时出错(脑裂)。#discovery.zen.ping.timeout: 3s## 设置是否打开多播发现节点，默认是true。当多播不可用或者集群跨网段的时候集群通信建议用单播。# discovery.zen.ping.multicast.enabled: false## For more information, consult the zen discovery module documentation.## ---------------------------------- Gateway -----------------------------------## Block initial recovery after a full cluster restart until N nodes are started:# 设置集群中N个节点启动时进行数据恢复，默认为3。#gateway.recover_after_nodes: 3## gateway的类型，默认为local即为本地文件系统，可以设置为本地文件系统，分布式文件系统，hadoop的HDFS，和amazon的s3服务器等#gateway.type: local## 设置初始化数据恢复进程的超时时间，超时时间从上一个配置中配置的N个节点启动后算起，默认是5分钟。#gateway.recover_after_time: 5m## 设置这个集群中节点的数量，默认为2，一旦这N个节点启动，就会立即进行数据恢复。#gateway.expected_nodes: 2## For more information, consult the gateway module documentation.## ---------------------------- Recovery Throttling -----------------------------## 下面这些配置允许在初始化恢复,副本分配,再平衡,或者添加和删除节点时控制节点间的分片分配# 设置一个节点的并行恢复数# 1.初始化数据恢复时,并发恢复线程的个数,默认为4# cluster.routing.allocation.node_initial_primaries_recoveries: 4# 2.添加删除节点或负载均衡时并发恢复线程的个数,默认为2# cluster.routing.allocation.node_concurrent_recoveries: 2# 设置恢复时的吞吐量(例如:100mb,默认为0无限制.如果机器还有其他业务在跑的话还是限制一下的好)# indices.recovery.max_bytes_per_sec: 20mb# 设置来限制从其它分片恢复数据时最大同时打开并发流的个数,默认为5# indices.recovery.concurrent_streams: 5# 注意: 合理的设置以上参数能有效的提高集群节点的数据恢复以及初始化速度## ---------------------------------- Various -----------------------------------## Require explicit names when deleting indices:##action.destructive_requires_name: true# 如果启用了 HTTP 端口，开启跨域访问支持，默认为falsehttp.cors.enabled: true# 如果 http.cors.enabled 的值为 true，那么该属性会指定访问允许的域名地址，(允许所有域名)以上使用正则http.cors.allow-origin: /.*/ 参考 http://www.cnblogs.com/xiaochina/p/6855591.html https://www.cnblogs.com/sunxucool/p/3799190.html","link":"/es-config.html"},{"title":"CentOS 7 使用 cron 执行计划任务","text":"在Linux中，周期执行的任务一般由cron这个守护进程来处理ps -ef|grep cron。cron读取一个或多个配置文件，这些配置文件中包含了命令行及其调用时间。cron的配置文件称为 crontab，是 cron table 的简写。 cron服务CentOS 7下安装12yum install vixie-cronyum install crontabs启动服务1service crond start 开机自动启动1chkconfig --level 35 crond on 查看是否已加入开机自启动：使用 chkconfig | grep crond 看在2 3 4 5级别是不是oncrontab默认就是开机启动的，普通用户要有sudo的权限才能设置开机启动 其他命令1234 service crond stop //关闭服务 service crond restart //重启服务 service crond reload //重新载入配置 service crond status //查看服务状态 权限crontab权限问题到/var/adm/cron/下查看文件cron.allow和cron.deny是否存在用法如下：1、如果两个文件都不存在，则只有root用户才能使用crontab命令。2、如果cron.allow存在但cron.deny不存在，则只有列在cron.allow文件里的用户才能使用crontab命令，如果root用户也不在里面，则root用户也不能使用crontab。3、如果cron.allow不存在, cron.deny存在，则只有列在cron.deny文件里面的用户不能使用crontab命令，其它用户都能使用。4、如果两个文件都存在，则列在cron.allow文件中而且没有列在cron.deny中的用户可以使用crontab，如果两个文件中都有同一个用户，以cron.allow文件里面是否有该用户为准，如果cron.allow中有该用户，则可以使用crontab命令。 CentOS 7 中默认普通用户没有 crontab 权限 ，要想放开普通用户的 crontab 权限可以编辑/var/adm/cron/cron.deny crontab用法crontab命令用于安装、删除或者列出用于驱动cron后台进程的表格。用户把需要执行的命令序列放到crontab文件中以获得执行。每个用户都可以有自己的crontab文件。/var/spool/cron下的crontab文件不可以直接创建或者直接修改。该crontab文件是通过crontab命令创建的。 系统级crontab用ls /etc/cron然后敲两下TAB，可以看到相关文件及目录。cron.d/ cron.daily/ cron.hourly/ cron.monthly/ crontab cron.weekly/ cron文件目录解读可以编辑crontab文件，来创建计划任务。而以daily，hourly，weekly，monthly后缀的目录下分别存放每天，每月，每周，每月执行的任务。其中存放的就是Shell脚本文件，权限755。我们把要执行的任务写成Shell脚本丢进行相应的目录就可以了。而不规则周期的计划任务放在corn.d目录下面，可以看做是crontab文件的补充。 编辑crontab注意 crontab 是分用户的，以谁登录就会编辑到哪个用户的 crontab，必须在拥有 cron 权限的用户下编辑 crontab。 123456789101112crontab -e : 编辑某个用户的crontab文件内容。如果不指定用户，则表示编辑当前用户的crontab文件基本格式： * * * * * command对应参数： 分 时 日 月 周 命令举个例子： 00 00 * * * /usr/bin/php /xxx/Timer.php # 每天凌晨执行PHP脚本crontab -r : 从/var/spool/cron目录中删除某个用户的crontab文件，如果不指定用户，则默认删除当前用户的crontab文件crontab -l : 显示某个用户的crontab文件内容，如果不指定用户，则表示显示当前用户的crontab文件内容crontab -i : 会和-r 配合使用，在删除当前的crontab时询问，输入 y 则删除tail -f /var/log/cron : 查看cron日志 特殊符号“*”代表所有的取值范围内的数字。特别要注意哦！ “/“代表每的意思，如”*/5”表示每5个单位 “-“代表从某个数字到某个数字 “,”分散的数字 举例12345678910111213141516171819202122232425每晚21：30重启apache30 21 * * * service httpd restart每月的1, 10, 22日的4:55分重启apache, 用，号分割55 4 1,10,22 * * service httpd restart每月的1到10日重启apache， 用-号表示区间* * 1-10 * * service httpd restart每隔2分钟重启apache ， 这里的 */2 号 表示从0.0秒开始每隔2分钟执行*/2 * * * * service httpd restart每晚11点到早上7点每隔1小时重启服务器, 注意分钟是用0而不是* 假如是*则代表每分钟都在执行0 23-7/1 * * * service httpd restart每天18点到23点每隔30分钟重启服务器, 两种写法都可以*/30 18-23 * * * service httpd restart0,30 18-23 * * * service httpd restart每天0点执行python3脚本（亲测CentOS 7下在8点执行，由于默认bios时间是utc时间，所以相差了8小时）00 00 * * * /usr/local/bin/python3 /root/time.py每天0点执行php脚本00 00 * * * /usr/bin/php /xxx/Timer.php # 每天凌晨执行PHP脚本 参考 https://www.kancloud.cn/digest/yunwei/212799 https://segmentfault.com/a/1190000008560453 https://blog.csdn.net/zd147896325/article/details/80763908 https://www.cnblogs.com/longjshz/p/5779215.html https://www.cnblogs.com/intval/p/5763929.html","link":"/centos-crontab.html"},{"title":"Apache 2 配置二级域名","text":"本文介绍如何定义二级域名，并在vps的Apache服务器中将域名映射到网站目录下。 二级域名一级域名（abc.cn）也称作顶级域名，申请一级域名一般都需要收费。二级域名（blog.abc.cn）是对一级域名的延伸，www其实也是二级域名的一种，只不过大家平时习惯用 www 作为网站的主域名。通过DNS解析服务商，可以在域名管理页面为主域名添加一条解析记录，比如要添加一个 blog 开头的二级域名。 主机记录 记录类型 线路类型 记录值 MX优先级 TTL blog A 默认 45.54.23.1 - 600 设置完成后，ping blog.abc.com,如果返回的ip地址都是服务器IP，说明域名解析已经成功。 Apache配置方法一：现将创建的二级域名映射到服务器的某个网站目录下，需要配置apache的http.conf文件，vi /etc/httpd/conf/httpd.conf，在文件中增加以下代码：每一个二级域名对应一个 VirtualHost 标签，有多少二级域名，就需要多少个 VirtualHost 标签。 123456789101112131415161718192021NameVirtualHost *:80# www&lt;VirtualHost *:80&gt; ServerAdmin 782773117@qq.com DocumentRoot /var/www/html/www ServerName www.abc.cn ErrorLog logs/www-error_log CustomLog logs/www-access_log common&lt;/VirtualHost&gt;# blog&lt;VirtualHost *:80&gt; ServerAdmin 782773117@qq.com DocumentRoot /var/www/html/blog ServerName blog.abc.cn ErrorLog logs/blog-error_log CustomLog logs/blog-access_log common&lt;/VirtualHost&gt; 方法二： 1.将httpd.conf配置文件的两行取消注释；12DocumentRoot &quot;/var/www/html&quot;ServerAdmin you@example.com 2.然后取消Virtual hosts下面的Include注释，引入虚拟服务器配置文件；12# Virtual hostsInclude conf/extra/httpd-vhosts.conf 3.在配置文件conf/extra/httpd-vhosts.conf（若文件不存在则创建）同样加入上述配置内容 最后重启apache服务器，service httpd restart 参数含义配置虚拟主机的选项里面，可以出现的参数很多，但最少必须定义DocumentRoot和ServerName。附各个参数含义说明ServerAdmin 管理员邮箱DocumentRoot 所需指向路径ServerName 域名名称ServerAlias 域名别名 可要可不要ErrorLog 错误日志CustomLog 访问日志 参考 http://blog.sina.com.cn/s/blog_5375d76b01014fnt.html https://segmentfault.com/a/1190000007512622 http://www.cnblogs.com/hi-bazinga/archive/2012/04/23/2466605.html","link":"/apache-domain.html"},{"title":"Hexo博客跳过渲染，创建自定义网页","text":"Hexo 博客中所见文章都是经由渲染的静态网页，而静态网页的样式都直接由 Hexo 的主题控制，所以 Hexo 博客大部分都呈现出一种高度的统一化与规范化。不过 Hexo 提供了跳过渲染功能，使得我们可以直接在博客中放入自定义网页。比如在博客中放入图片、自定义 404.html 、自定义 About 页面等。 自定义网页网页可以是自己编写的，也可以是别人现成的源码。网页编写完成后，在 Hexo\\source 目录下创建一个文件夹，文件夹名称任意，将 Html 文件放置于此文件夹，并重命名为 index.html 。 方法一在html文件中添加跳过渲染指令： 用编辑器打开 Hexo\\source 创建的文件夹中的 index.html 文件，在开头添加如下代码即可 123---layout: false--- 添加该指令后，执行 hexo g 命令时便会跳过该 index.html 文件，使得 index.html 不受当前 hexo 主题影响，完全是一个独立的网页。 如果网页引用了 css 或 js ，这些 css 和 js 必须使用外链。 如果引用图片，可以在网页目录下建立 img 文件夹，可以直接引用图片，不必再去创建外链。 方法二使用编辑器打开 Hexo 目录下的_config.yml 文件，找到 skip_render skip_render 一般有以下四种常用参数： 跳过source目录下的 test.html: skip_render: test.html 跳过source目录下 test 文件夹内所有文件：skip_render: test/* 跳过source目录下 test 文件夹内所有文件包括子文件夹以及子文件夹内的文件：skip_render: test/** 跳过多个路径： 123skip_render: - test.html - test/* 对格式要求严格，注意填写参数时的格式，添加完成后便不会渲染指定文件/文件夹。 如果网页引用了 css 或 js ，并将整个网页目录设置为跳过渲染，则不必再为 css 和 js 创建外链，可以直接引用。","link":"/hexo-custom-page.html"},{"title":"行人重识别Person Re-identification总结","text":"Person re-identification, also known as person retrieval, is to match pedestrian images observed from non-overlapping camera views based on appearance.It receives increasing attentions in video surveillance for its important applications in threat detection, human retrieval, and multi-camera tracking. It saves a lot of human labor in exhaustively searching for a person of interest from large amounts of video sequences. Last Updated: Apr 26, 2019 Table of Contentsgenerated with DocToc Leaderboard Person Re-identification / Person Retrieval Person Search Pose/View for Re-ID GAN for Re-ID Human Parsing for Re-ID Partial Person Re-ID RGB-IR Re-ID Depth-Based Re-ID Low Resolution Re-ID Reinforcement Learning for Re-ID Attributes Prediction for Re-ID Video Person Re-Identification Re-ranking Unsupervised Re-ID Weakly Supervised Person Re-identification Vehicle Re-ID Deep Metric Learning Projects Evaluation Datasets Tutorials Experts Resources Leaderboard Method backbone test size Market1501 CUHK03 (detected) CUHK03 (detected/new) CUHK03 (labeled/new) CUHK-SYSU DukeMTMC-reID MARS rank1 / mAP rank1/ 5 / 10 rank1 / mAP rank1 / mAP rank1 / mAP rank1 / mAP AlignedReID ResNet50-X 92.6 / 82.3 91.9 / 98.7 / 99.4 86.8 / 79.1 95.3 / 93.7 AlignedReID (RK) 94.0 / 91.2 96.1 / 99.5 / 99.6 87.5 / 85.6 Deep-Person(SQ) ResNet-50 256×128 92.31 / 79.58 89.4 / 98.2 / 99.1 80.90 / 64.80 Deep-Person(MQ) ResNet-50 256×128 94.48 / 85.09 PCB(SQ) ResNet-50 384x128 92.4 / 77.3 61.3 / 54.2 81.9 / 65.3 PCB+RPP(SQ) ResNet-50 384x128 93.8 / 81.6 63.7 / 57.5 83.3 / 69.2 PN-GAN (SQ) ResNet-50 89.43 / 72.58 79.76/ 96.24/ 98.56 73.58 / 53.20 PN-GAN (MQ) ResNet-50 95.90 / 91.37 MGN (SQ) ResNet-50 95.7 / 86.9 66.8 / 66.0 68.0 / 67.4 88.7 / 78.4 MGN (MQ) ResNet-50 96.9 / 90.7 MGN (SQ+RK) ResNet-50 96.6 / 94.2 MGN (MQ+RK) ResNet-50 97.1 / 95.9 HPM(SQ) ResNet-50 384x128 94.2 / 82.7 63.1 / 57.5 86.6 / 74.3 HPM+HRE(SQ) ResNet-50 384x128 93.9 / 83.1 63.2 / 59.7 86.3 / 74.5 - SphereReID ResNet-50 288×144 94.4 / 83.6 93.1 / 98.7 / 99.4 63.2 / 59.7 95.4 / 93.9 83.9 / 68.5 - Auto-ReID 384x128 94.5 / 85.1 73.3 / 69.3 77.9 / 73.0 88.5 / 75.1 - Person Re-identification / Person RetrievalDeepReID: Deep Filter Pairing Neural Network for Person Re-Identification intro: CVPR 2014 paper: http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Li_DeepReID_Deep_Filter_2014_CVPR_paper.pdf An Improved Deep Learning Architecture for Person Re-Identification intro: CVPR 2015 paper: http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Ahmed_An_Improved_Deep_2015_CVPR_paper.pdf github: https://github.com/Ning-Ding/Implementation-CVPR2015-CNN-for-ReID Deep Ranking for Person Re-identification via Joint Representation Learning intro: IEEE Transactions on Image Processing (TIP), 2016 arxiv: https://arxiv.org/abs/1505.06821 PersonNet: Person Re-identification with Deep Convolutional Neural Networks arxiv: http://arxiv.org/abs/1601.07255 Learning Deep Feature Representations with Domain Guided Dropout for Person Re-identification intro: CVPR 2016 arxiv: https://arxiv.org/abs/1604.07528 github: https://github.com/Cysu/dgd_person_reid Person Re-Identification by Multi-Channel Parts-Based CNN with Improved Triplet Loss Function intro: CVPR 2016 paper: http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Cheng_Person_Re-Identification_by_CVPR_2016_paper.pdf Joint Learning of Single-image and Cross-image Representations for Person Re-identification intro: CVPR 2016 paper: http://openaccess.thecvf.com/content_cvpr_2016/papers/Wang_Joint_Learning_of_CVPR_2016_paper.pdf End-to-End Comparative Attention Networks for Person Re-identification paper: https://arxiv.org/abs/1606.04404 A Multi-task Deep Network for Person Re-identification intro: AAAI 2017 arxiv: http://arxiv.org/abs/1607.05369 A Siamese Long Short-Term Memory Architecture for Human Re-Identification arxiv: http://arxiv.org/abs/1607.08381 Gated Siamese Convolutional Neural Network Architecture for Human Re-Identification intro: ECCV 2016 keywords: Market1501 rank1 = 65.9% arxiv: https://arxiv.org/abs/1607.08378 Deep Neural Networks with Inexact Matching for Person Re-Identification intro: NIPS 2016 keywords: Normalized correlation layer, CUHK03/CUHK01/QMULGRID paper: https://papers.nips.cc/paper/6367-deep-neural-networks-with-inexact-matching-for-person-re-identification github: https://github.com/InnovArul/personreid_normxcorr Person Re-identification: Past, Present and Future paper: https://arxiv.org/abs/1610.02984 note: https://blog.csdn.net/zdh2010xyz/article/details/53741682 Deep Learning Prototype Domains for Person Re-Identification arxiv: https://arxiv.org/abs/1610.05047 Deep Transfer Learning for Person Re-identification arxiv: https://arxiv.org/abs/1611.05244 note: https://blog.csdn.net/shenxiaolu1984/article/details/53607268 A Discriminatively Learned CNN Embedding for Person Re-identification intro: TOMM 2017 arxiv: https://arxiv.org/abs/1611.05666 github(official, MatConvnet): https://github.com/layumi/2016_person_re-ID github: https://github.com/D-X-Y/caffe-reid Person Re-Identification via Recurrent Feature Aggregation intro: ECCV 2016 keywords: recurrent feature aggregation network (RFA-Net) arxiv: https://arxiv.org/abs/1701.06351 code: https://sites.google.com/site/yanyichao91sjtu/ github(official): https://github.com/daodaofr/caffe-re-id Structured Deep Hashing with Convolutional Neural Networks for Fast Person Re-identification arxiv: https://arxiv.org/abs/1702.04179 SVDNet for Pedestrian Retrieval intro: ICCV 2017 spotlight intro: On the Market-1501 dataset, rank-1 accuracy is improved from 55.2% to 80.5% for CaffeNet,and from 73.8% to 83.1% for ResNet-50 arxiv: https://arxiv.org/abs/1703.05693 github: https://github.com/syfafterzy/SVDNet-for-Pedestrian-Retrieval In Defense of the Triplet Loss for Person Re-Identification arxiv: https://arxiv.org/abs/1703.07737 github(Theano): https://github.com/VisualComputingInstitute/triplet-reid Beyond triplet loss: a deep quadruplet network for person re-identification intro: CVPR 2017 arxiv: https://arxiv.org/abs/1704.01719 ppaper: http://cvip.computing.dundee.ac.uk/papers/Chen_CVPR_2017_paper.pdf Quality Aware Network for Set to Set Recognition intro: CVPR 2017 arxiv: https://arxiv.org/abs/1704.03373 github: https://github.com/sciencefans/Quality-Aware-Network Learning Deep Context-aware Features over Body and Latent Parts for Person Re-identification intro: CVPR 2017. CASIA keywords: Multi-Scale Context-Aware Network (MSCAN) arxiv: https://arxiv.org/abs/1710.06555 supplemental: Li_Learning_Deep_Context-Aware_2017_CVPR_supplemental.pdf Point to Set Similarity Based Deep Feature Learning for Person Re-identification intro: CVPR 2017 paper: http://openaccess.thecvf.com/content_cvpr_2017/papers/Zhou_Point_to_Set_CVPR_2017_paper.pdf github(stay tuned): https://github.com/samaonline/Point-to-Set-Similarity-Based-Deep-Feature-Learning-for-Person-Re-identification Scalable Person Re-identification on Supervised Smoothed Manifold intro: CVPR 2017 spotlight arxiv: https://arxiv.org/abs/1703.08359 youtube: https://www.youtube.com/watch?v=bESdJgalQrg Attention-based Natural Language Person Retrieval intro: CVPR 2017 Workshop (vision meets cognition) keywords: Bidirectional Long Short Term Memory (BLSTM) arxiv: https://arxiv.org/abs/1705.08923 Part-based Deep Hashing for Large-scale Person Re-identification intro: IEEE Transactions on Image Processing, 2017 arxiv: https://arxiv.org/abs/1705.02145 Deep Person Re-Identification with Improved Embedding and Efficient Training intro: IJCB 2017 arxiv: https://arxiv.org/abs/1705.03332 Towards a Principled Integration of Multi-Camera Re-Identification and Tracking through Optimal Bayes Filters arxiv: https://arxiv.org/abs/1705.04608 github: https://github.com/VisualComputingInstitute/towards-reid-tracking Person Re-Identification by Deep Joint Learning of Multi-Loss Classification intro: IJCAI 2017 arxiv: https://arxiv.org/abs/1705.04724 Deep Representation Learning with Part Loss for Person Re-Identification keywords: Part Loss Networks arxiv: https://arxiv.org/abs/1707.00798 Pedestrian Alignment Network for Large-scale Person Re-identification arxiv: https://arxiv.org/abs/1707.00408 github: https://github.com/layumi/Pedestrian_Alignment Learning Efficient Image Representation for Person Re-Identification arxiv: https://arxiv.org/abs/1707.02319 Person Re-identification Using Visual Attention intro: ICIP 2017 arxiv: https://arxiv.org/abs/1707.07336 What-and-Where to Match: Deep Spatially Multiplicative Integration Networks for Person Re-identification arxiv: https://arxiv.org/abs/1707.07074 Deep Feature Learning via Structured Graph Laplacian Embedding for Person Re-Identification arxiv: https://arxiv.org/abs/1707.07791 Large Margin Learning in Set to Set Similarity Comparison for Person Re-identification intro: IEEE Transactions on Multimedia arxiv: https://arxiv.org/abs/1708.05512 Multi-scale Deep Learning Architectures for Person Re-identification intro: ICCV 2017 arxiv: https://arxiv.org/abs/1709.05165 Person Re-Identification by Deep Learning Multi-Scale Representations intro: ICCV 2017 keywords: Deep Pyramid Feature Learning (DPFL) paper: Chen_Person_Re-Identification_by_ICCV_2017_paper.pdf paper: http://www.eecs.qmul.ac.uk/~sgg/papers/ChenEtAl_ICCV2017WK_CHI.pdf HydraPlus-Net: Attentive Deep Features for Pedestrian Analysis intro: ICCV 2017. CUHK &amp; SenseTime, arxiv: https://arxiv.org/abs/1709.09930 github: https://github.com/xh-liu/HydraPlus-Net Person Re-Identification with Vision and Language arxiv: https://arxiv.org/abs/1710.01202 Margin Sample Mining Loss: A Deep Learning Based Method for Person Re-identification arxiv: https://arxiv.org/abs/1710.00478 Pseudo-positive regularization for deep person re-identification arxiv: https://arxiv.org/abs/1711.06500 Let Features Decide for Themselves: Feature Mask Network for Person Re-identification keywords: Feature Mask Network (FMN) arxiv: https://arxiv.org/abs/1711.07155 AlignedReID: Surpassing Human-Level Performance in Person Re-Identification intro: Megvii Inc &amp; Zhejiang University arxiv: https://arxiv.org/abs/1711.08184 evaluation website: (Market1501): http://reid-challenge.megvii.com/ evaluation website: (CUHK03): http://reid-challenge.megvii.com/cuhk03 github: https://github.com/huanghoujing/AlignedReID-Re-Production-Pytorch Region-based Quality Estimation Network for Large-scale Person Re-identification intro: AAAI 2018 arxiv: https://arxiv.org/abs/1711.08766 Beyond Part Models: Person Retrieval with Refined Part Pooling keywords: Part-based Convolutional Baseline (PCB), Refined Part Pooling (RPP) arxiv: https://arxiv.org/abs/1711.09349 Deep-Person: Learning Discriminative Deep Features for Person Re-Identification arxiv: https://arxiv.org/abs/1711.10658 Hierarchical Cross Network for Person Re-identification arxiv: https://arxiv.org/abs/1712.06820 Re-ID done right: towards good practices for person re-identification arxiv: https://arxiv.org/abs/1801.05339 Triplet-based Deep Similarity Learning for Person Re-Identification intro: ICCV Workshops 2017 arxiv: https://arxiv.org/abs/1802.03254 Group Consistent Similarity Learning via Deep CRFs for Person Re-Identification intro: CVPR 2018 oral paper: http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_Group_Consistent_Similarity_CVPR_2018_paper.pdf Image-Image Domain Adaptation with Preserved Self-Similarity and Domain-Dissimilarity for Person Re-identification intro: CVPR 2018 keywords: similarity preserving generative adversarial network (SPGAN), Siamese network, CycleGAN, domain adaptation arxiv: https://arxiv.org/abs/1711.07027 Harmonious Attention Network for Person Re-Identification intro: CVPR 2018 keywords: Harmonious Attention CNN (HA-CNN) arxiv: https://arxiv.org/abs/1802.08122 Camera Style Adaptation for Person Re-identfication intro: CVPR 2018 arxiv: https://arxiv.org/abs/1711.10295 github: https://github.com/zhunzhong07/CamStyle Image-Image Domain Adaptation with Preserved Self-Similarity and Domain-Dissimilarity for Person Re-identification intro: CVPR 2018 arxiv: https://arxiv.org/abs/1711.07027 Dual Attention Matching Network for Context-Aware Feature Sequence based Person Re-Identification intro: CVPR 2018 arxiv: https://arxiv.org/abs/1803.09937 Multi-Level Factorisation Net for Person Re-Identification intro: CVPR 2018 keywords: Multi-Level Factorisation Net (MLFN) arxiv: https://arxiv.org/abs/1803.09132 Features for Multi-Target Multi-Camera Tracking and Re-Identification intro: CVPR 2018 arxiv: https://arxiv.org/abs/1803.10859 Good Appearance Features for Multi-Target Multi-Camera Tracking intro: CVPR 2018 spotlight. Duke University keywords: adaptive weighted triplet loss, hard-identity mining project page: http://vision.cs.duke.edu/DukeMTMC/ arxiv: https://arxiv.org/abs/1803.10859 Mask-guided Contrastive Attention Model for Person Re-Identification intro: CVPR 2018 paper: http://openaccess.thecvf.com/content_cvpr_2018/papers/Song_Mask-Guided_Contrastive_Attention_CVPR_2018_paper.pdf Efficient and Deep Person Re-Identification using Multi-Level Similarity intro: CVPR 2018 arxiv: https://arxiv.org/abs/1803.11353 Person Re-identification with Cascaded Pairwise Convolutions intro: CVPR 2018 paper: http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Person_Re-Identification_With_CVPR_2018_paper.pdf Attention-Aware Compositional Network for Person Re-identification intro: CVPR 2018 intro: Sensets Technology Limited &amp; University of Sydney keywords: Attention-Aware Compositional Network (AACN), Pose-guided Part Attention (PPA), Attention-aware Feature Composition (AFC) arxiv: https://arxiv.org/abs/1805.03344 Deep Group-shuffling Random Walk for Person Re-identification intro: CVPR 2018 paper: http://openaccess.thecvf.com/content_cvpr_2018/papers/Shen_Deep_Group-Shuffling_Random_CVPR_2018_paper.pdf Adversarially Occluded Samples for Person Re-identification intro: CVPR 2018 paper: http://openaccess.thecvf.com/content_cvpr_2018/papers/Huang_Adversarially_Occluded_Samples_CVPR_2018_paper.pdf Easy Identification from Better Constraints: Multi-Shot Person Re-Identification from Reference Constraints intro: CVPR 2018 paper: http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhou_Easy_Identification_From_CVPR_2018_paper.pdf Eliminating Background-bias for Robust Person Re-identification intro: CVPR 2018 paper: http://openaccess.thecvf.com/content_cvpr_2018/papers/Tian_Eliminating_Background-Bias_for_CVPR_2018_paper.pdf End-to-End Deep Kronecker-Product Matching for Person Re-identification intro: CVPR 2018 paper: http://openaccess.thecvf.com/content_cvpr_2018/papers/Shen_End-to-End_Deep_Kronecker-Product_CVPR_2018_paper.pdf Exploiting Transitivity for Learning Person Re-identification Models on a Budget intro: CVPR 2018 paper: http://openaccess.thecvf.com/content_cvpr_2018/papers/Roy_Exploiting_Transitivity_for_CVPR_2018_paper.pdf Resource Aware Person Re-identification across Multiple Resolutions intro: CVPR 2018 paper: http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Resource_Aware_Person_CVPR_2018_paper.pdf Multi-Channel Pyramid Person Matching Network for Person Re-Identification intro: 32nd AAAI Conference on Artificial Intelligence keywords: Multi-Channel deep convolutional Pyramid Person Matching Network (MC-PPMN) arxiv: https://arxiv.org/abs/1803.02558 Pyramid Person Matching Network for Person Re-identification intro: 9th Asian Conference on Machine Learning (ACML2017) JMLR Workshop and Conference Proceedings arxiv: https://arxiv.org/abs/1803.02547 Virtual CNN Branching: Efficient Feature Ensemble for Person Re-Identification arxiv: https://arxiv.org/abs/1803.05872 Adversarial Binary Coding for Efficient Person Re-identification arxiv: https://arxiv.org/abs/1803.10914 Learning View-Specific Deep Networks for Person Re-Identification intro: IEEE Transactions on image processing. Sun Yat-Sen University keywords: cross-view Euclidean constraint (CV-EC), cross-view center loss (CV-CL) arxiv: https://arxiv.org/abs/1803.11333 Learning Discriminative Features with Multiple Granularities for Person Re-Identification intro: Shanghai Jiao Tong University &amp; CloudWalk keywords: Multiple Granularity Network (MGN) arxiv: https://arxiv.org/abs/1804.01438 Recurrent Neural Networks for Person Re-identification Revisited intro: Stanford University &amp; Google AI arxiv: https://arxiv.org/abs/1804.03281 MaskReID: A Mask Based Deep Ranking Neural Network for Person Re-identification arxiv: https://arxiv.org/abs/1804.03864 Horizontal Pyramid Matching for Person Re-identification intro: AAAI 2019 intro: UIUC &amp; IBM Research &amp; Cornell University &amp; Stevens Institute of Technology &amp;CloudWalk Technology keywords: Horizontal Pyramid Matching (HPM), Horizontal Pyramid Pooling (HPP), horizontal random erasing (HRE) arxiv: https://arxiv.org/abs/1804.05275 github: https://github.com/OasisYang/HPM Part-Aligned Bilinear Representations for Person Re-identification intro: Seoul National University &amp; Microsoft Research &amp; Max Planck Institute &amp; University of Tubingen &amp; JD.COM arxiv: https://arxiv.org/abs/1804.07094 Deep Co-attention based Comparators For Relative Representation Learning in Person Re-identification arxiv: https://arxiv.org/abs/1804.11027 Feature Affinity based Pseudo Labeling for Semi-supervised Person Re-identification arxiv: https://arxiv.org/abs/1805.06118 Resource Aware Person Re-identification across Multiple Resolutions intro: CVPR 2018 arxiv: https://arxiv.org/abs/1805.08805 Semantically Selective Augmentation for Deep Compact Person Re-Identification arxiv: https://arxiv.org/abs/1806.04074 SphereReID: Deep Hypersphere Manifold Embedding for Person Re-Identification intro: it achieves 94.4% rank-1 accuracy on Market-1501 and 83.9% rank-1 accuracy on DukeMTMC-reID arxiv: https://arxiv.org/abs/1807.00537 Multi-task Mid-level Feature Alignment Network for Unsupervised Cross-Dataset Person Re-Identification intro: BMVC 2018. University of Warwick &amp; Nanyang Technological University &amp; Charles Sturt University arxiv: https://arxiv.org/abs/1807.01440 Discriminative Feature Learning with Foreground Attention for Person Re-Identification arxiv: https://arxiv.org/abs/1807.01455 Part-Aligned Bilinear Representations for Person Re-identification intro: ECCV 2018 intro: Seoul National University &amp; Microsoft Research &amp; Max Planck Institute &amp; University of Tubingen &amp; JD.COM arxiv: https://arxiv.org/abs/1804.07094 github: https://github.com/yuminsuh/part_bilinear_reid Mancs: A Multi-task Attentional Network with Curriculum Sampling for Person Re-identification intro: ECCV 2018. Huazhong University of Science and Technology &amp; Horizon Robotics Inc. Improving Deep Visual Representation for Person Re-identification by Global and Local Image-language Association intro: ECCV 2018 arxiv: https://arxiv.org/abs/1808.01571 Deep Sequential Multi-camera Feature Fusion for Person Re-identification arxiv: https://arxiv.org/abs/1807.07295 Improving Deep Models of Person Re-identification for Cross-Dataset Usage intro: AIAI 2018 (14th International Conference on Artificial Intelligence Applications and Innovations) proceeding arxiv: https://arxiv.org/abs/1807.08526 Measuring the Temporal Behavior of Real-World Person Re-Identification arxiv: https://arxiv.org/abs/1808.05499 Alignedreid＋+: Dynamically Matching Local Information for Person Re-Identification github: https://github.com/michuanhaohao/AlignedReID Sparse Label Smoothing for Semi-supervised Person Re-Identification arxiv: https://arxiv.org/abs/1809.04976 github: https://github.com/jpainam/SLS_ReID In Defense of the Classification Loss for Person Re-Identification intro: University of Science and Technology of China &amp; Microsoft Research Asia arxiv: https://arxiv.org/abs/1809.05864 FD-GAN: Pose-guided Feature Distilling GAN for Robust Person Re-identification intro: NIPS 2018 arxiv: https://arxiv.org/abs/1810.02936 github(Pytorch, official): https://github.com/yxgeee/FD-GAN Image-to-Video Person Re-Identification by Reusing Cross-modal Embeddings arxiv: https://arxiv.org/abs/1810.03989 Attention Driven Person Re-identification intro: Pattern Recognition (PR) arxiv: https://arxiv.org/abs/1810.05866 A Coarse-to-fine Pyramidal Model for Person Re-identification via Multi-Loss Dynamic Training intro: YouTu Lab, Tencent arxiv: https://arxiv.org/abs/1810.12193 M2M-GAN: Many-to-Many Generative Adversarial Transfer Learning for Person Re-Identification arxiv: https://arxiv.org/abs/1811.03768 Batch Feature Erasing for Person Re-identification and Beyond arxiv: https://arxiv.org/abs/1811.07130 github(official, Pytorch): https://github.com/daizuozhuo/batch-feature-erasing-network Re-Identification with Consistent Attentive Siamese Networks arxiv: https://arxiv.org/abs/1811.07487 One Shot Domain Adaptation for Person Re-Identification arxiv: https://arxiv.org/abs/1811.10144 Parameter-Free Spatial Attention Network for Person Re-Identification arxiv: https://arxiv.org/abs/1811.12150 Spectral Feature Transformation for Person Re-identification intro: University of Chinese Academy of Sciences &amp; TuSimple arxiv: https://arxiv.org/abs/1811.11405 Identity Preserving Generative Adversarial Network for Cross-Domain Person Re-identification arxiv: https://arxiv.org/abs/1811.11510 Dissecting Person Re-identification from the Viewpoint of Viewpoint arxiv: https://arxiv.org/abs/1812.02162 Fast and Accurate Person Re-Identification with RMNet intro: IOTG Computer Vision (ICV), Intel arxiv: https://arxiv.org/abs/1812.02465 Spatial-Temporal Person Re-identification intro: AAAI 2019 intro: Sun Yat-sen University arxiv: https://arxiv.org/abs/1812.03282 github: https://github.com/Wanggcong/Spatial-Temporal-Re-identification Omni-directional Feature Learning for Person Re-identification intro: Tongji University keywords: OIM loss arxiv: https://arxiv.org/abs/1812.05319 Learning Incremental Triplet Margin for Person Re-identification intro: AAAI 2019 spotlight intro: Hikvision Research Institute arxiv: https://arxiv.org/abs/1812.06576 Densely Semantically Aligned Person Re-Identification intro: USTC &amp; MSRA arxiv: https://arxiv.org/abs/1812.08967 EANet: Enhancing Alignment for Cross-Domain Person Re-identification intro: CRISE &amp; CASIA &amp; Horizon Robotics arxiv: https://arxiv.org/abs/1812.11369 github(official, Pytorch): https://github.com/huanghoujing/EANet blog: https://zhuanlan.zhihu.com/p/53660395 Backbone Can Not be Trained at Once: Rolling Back to Pre-trained Network for Person Re-Identification intro: AAAI 2019 intro: Seoul National University &amp; Samsung SDS arxiv: https://arxiv.org/abs/1901.06140 Ensemble Feature for Person Re-Identification keywords: EnsembleNet arxiv: https://arxiv.org/abs/1901.05798 Adversarial Metric Attack for Person Re-identification intro: University of Oxford &amp; Johns Hopkins University arxiv: https://arxiv.org/abs/1901.10650 Discovering Underlying Person Structure Pattern with Relative Local Distance for Person Re-identification intro: SYSU arxiv: https://arxiv.org/abs/1901.10100 github: https://github.com/Wanggcong/RLD_codes Attributes-aided Part Detection and Refinement for Person Re-identification arxiv: https://arxiv.org/abs/1902.10528 Bags of Tricks and A Strong Baseline for Deep Person Re-identification arxiv: https://arxiv.org/abs/1903.07071 github: https://github.com/michuanhaohao/reid-strong-baseline Auto-ReID: Searching for a Part-aware ConvNet for Person Re-Identification keywords: NAS arxiv: https://arxiv.org/abs/1903.09776 Perceive Where to Focus: Learning Visibility-aware Part-level Features for Partial Person Re-identification intro: CVPR 2019 intro: Tsinghua University &amp; Megvii Technology keywords: Visibility-aware Part Model (VPM) arxiv: https://arxiv.org/abs/1904.00537 Pedestrian re-identification based on Tree branch network with local and global learning intro: ICME 2019 oral arxiv: https://arxiv.org/abs/1904.00355 Invariance Matters: Exemplar Memory for Domain Adaptive Person Re-identification intro: CVPR 2019 arxiv: https://arxiv.org/abs/1904.01990 github: https://github.com/zhunzhong07/ECN Person Re-identification with Bias-controlled Adversarial Training arxiv: https://arxiv.org/abs/1904.00244 Person Re-identification with Metric Learning using Privileged Information intro: IEEE TIP arxiv: https://arxiv.org/abs/1904.05005 Joint Discriminative and Generative Learning for Person Re-identification intro: CVPR 2019 oral intro: NVIDIA &amp; University of Technology Sydney &amp; Australian National University arxiv: https://arxiv.org/abs/1904.07223 Person SearchJoint Detection and Identification Feature Learning for Person Search intro: CVPR 2017 Spotlight keywords: Online Instance Matching (OIM) loss function homepage(dataset+code):http://www.ee.cuhk.edu.hk/~xgwang/PS/dataset.html arxiv: https://arxiv.org/abs/1604.01850 paper: http://www.ee.cuhk.edu.hk/~xgwang/PS/paper.pdf github(official. Caffe): https://github.com/ShuangLI59/person_search Person Re-identification in the Wild intro: CVPR 2017 spotlight keywords: PRW dataset project page: http://www.liangzheng.com.cn/Project/project_prw.html arxiv: https://arxiv.org/abs/1604.02531 github: https://github.com/liangzheng06/PRW-baseline youtube: https://www.youtube.com/watch?v=dbOGwBITJqo IAN: The Individual Aggregation Network for Person Search arxiv: https://arxiv.org/abs/1705.05552 Neural Person Search Machines intro: ICCV 2017 arxiv: https://arxiv.org/abs/1707.06777 End-to-End Detection and Re-identification Integrated Net for Person Search keywords: I-Net arxiv: https://arxiv.org/abs/1804.00376 Person Search via A Mask-guided Two-stream CNN Model intro: ECCV 2018 arxiv: https://arxiv.org/abs/1807.08107 Person Search by Multi-Scale Matching intro: ECCV 2018 keywords: Cross-Level Semantic Alignment (CLSA) arxiv: https://arxiv.org/abs/1807.08582 Learning Context Graph for Person Search intro: CVPR 2019 intro: Shanghai Jiao Tong University &amp; Tencent YouTu Lab &amp; Inception Institute of Artificial Intelligence, UAE arxiv: https://arxiv.org/abs/1904.01830 Pose/View for Re-IDPose Invariant Embedding for Deep Person Re-identification keywords: pose invariant embedding (PIE), PoseBox fusion (PBF) CNN arixv: https://arxiv.org/abs/1701.07732 Deeply-Learned Part-Aligned Representations for Person Re-Identification intro: ICCV 2017 arxiv: https://arxiv.org/abs/1707.07256 github(official, Caffe): https://github.com/zlmzju/part_reid Spindle Net: Person Re-identification with Human Body Region Guided Feature Decomposition and Fusion intro: CVPR 2017 paper: http://openaccess.thecvf.com/content_cvpr_2017/papers/Zhao_Spindle_Net_Person_CVPR_2017_paper.pdf github: https://github.com/yokattame/SpindleNet Pose-driven Deep Convolutional Model for Person Re-identification intro: ICCV 2017 arxiv: https://arxiv.org/abs/1709.08325 A Pose-Sensitive Embedding for Person Re-Identification with Expanded Cross Neighborhood Re-Ranking intro: CVPR 2018 arxiv: https://arxiv.org/abs/1711.10378 github(official): https://github.com/pse-ecn/pose-sensitive-embedding Pose-Driven Deep Models for Person Re-Identification intro: Masters thesis arxiv: https://arxiv.org/abs/1803.08709 Pose Transferrable Person Re-Identification intro: CVPR 2018 paper: http://openaccess.thecvf.com/content_cvpr_2018/papers/Liu_Pose_Transferrable_Person_CVPR_2018_paper.pdf Person re-identification with fusion of hand-crafted and deep pose-based body region features arxiv: https://arxiv.org/abs/1803.10630 GAN for Re-IDUnlabeled Samples Generated by GAN Improve the Person Re-identification Baseline in vitro intro: ICCV 2017 arxiv: https://arxiv.org/abs/1701.07717 github(official, Matlab): https://github.com/layumi/Person-reID_GAN github: https://github.com/qiaoguan/Person-reid-GAN-pytorch Person Transfer GAN to Bridge Domain Gap for Person Re-Identification intro: CVPR 2018 spotlight intro: PTGAN arxiv: https://arxiv.org/abs/1711.08565 github: https://github.com/JoinWei-PKU/PTGAN Pose-Normalized Image Generation for Person Re-identification keywords: PN-GAN arxiv: https://arxiv.org/abs/1712.02225 github: https://github.com/naiq/PN_GAN Multi-pseudo Regularized Label for Generated Samples in Person Re-Identification arxiv: https://arxiv.org/abs/1801.06742 Human Parsing for Re-IDHuman Semantic Parsing for Person Re-identification intro: CVPR 2018. SPReID arxiv: https://arxiv.org/abs/1804.00216 Improved Person Re-Identification Based on Saliency and Semantic Parsing with Deep Neural Network Models keywords: Saliency-Semantic Parsing Re-Identification (SSP-ReID) arxiv: https://arxiv.org/abs/1807.05618 Partial Person Re-IDPartial Person Re-identification intro: ICCV 2015 arxiv: https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Zheng_Partial_Person_Re-Identification_ICCV_2015_paper.pdf Deep Spatial Feature Reconstruction for Partial Person Re-identification: Alignment-Free Approach intro: CVPR 2018. keywords: Market1501 rank1=83.58% arxiv: https://arxiv.org/abs/1801.00881 Occluded Person Re-identification intro: ICME 2018 arxiv: https://arxiv.org/abs/1804.02792 Partial Person Re-identification with Alignment and Hallucination intro: Imperial College London keywords: Partial Matching Net (PMN) arxiv: https://arxiv.org/abs/1807.09162 SCPNet: Spatial-Channel Parallelism Network for Joint Holistic and Partial Person Re-Identification intro: ACCV 2018 arxiv: https://arxiv.org/abs/1810.06996 STNReID : Deep Convolutional Networks with Pairwise Spatial Transformer Networks for Partial Person Re-identification intro: Zhejiang University &amp; Megvii Inc arxiv: https://arxiv.org/abs/1903.07072 Foreground-aware Pyramid Reconstruction for Alignment-free Occluded Person Re-identification arxiv: https://arxiv.org/abs/1904.04975 RGB-IR Re-IDRGB-Infrared Cross-Modality Person Re-Identification arxiv: Wu_RGB-Infrared_Cross-Modality_Person_ICCV_2017_paper.pdf Depth-Based Re-IDReinforced Temporal Attention and Split-Rate Transfer for Depth-Based Person Re-Identification intro: ECCV 2018 arxiv: Nikolaos_Karianakis_Reinforced_Temporal_Attention_ECCV_2018_paper.pdf A Cross-Modal Distillation Network for Person Re-identification in RGB-Depth arxiv: https://arxiv.org/abs/1810.11641 Low Resolution Re-IDMulti-scale Learning for Low-resolution Person Re-identification intro: ICCV 2015 arxiv: https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Li_Multi-Scale_Learning_for_ICCV_2015_paper.pdf Cascaded SR-GAN for Scale-Adaptive Low Resolution Person Re-identification intro: IJCAI 2018 arxiv: https://www.ijcai.org/proceedings/2018/0541.pdf Deep Low-Resolution Person Re-Identification intro: AAAI 2018 keywords: Super resolution and Identity joiNt learninG (SING) paper: http://www.eecs.qmul.ac.uk/~xiatian/papers/JiaoEtAl_2018AAAI.pdf Reinforcement Learning for Re-IDDeep Reinforcement Learning Attention Selection for Person Re-IdentificationIdentity Alignment by Noisy Pixel Removal intro: BMVC 2017 arxiv: https://arxiv.org/abs/1707.02785 paper: http://www.eecs.qmul.ac.uk/~sgg/papers/LanEtAl_2017BMVC.pdf Attributes Prediction for Re-IDMulti-Task Learning with Low Rank Attribute Embedding for Person Re-identification intro: ICCV 2015 paper: http://legacydirs.umiacs.umd.edu/~fyang/papers/iccv15.pdf Deep Attributes Driven Multi-Camera Person Re-identification intro: ECCV 2016 arxiv: https://arxiv.org/abs/1605.03259 Improving Person Re-identification by Attribute and Identity Learning arxiv: https://arxiv.org/abs/1703.07220 Person Re-identification by Deep Learning Attribute-Complementary Information intro: CVPR 2017 workshop paper: https://sci-hub.tw/10.1109/CVPRW.2017.186 CA3Net: Contextual-Attentional Attribute-Appearance Network for Person Re-Identification arxiv: https://arxiv.org/abs/1811.07544 Video Person Re-IdentificationRecurrent Convolutional Network for Video-based Person Re-Identification intro: CVPR 2016 paper: McLaughlin_Recurrent_Convolutional_Network_CVPR_2016_paper.pdf github: https://github.com/niallmcl/Recurrent-Convolutional-Video-ReID Deep Recurrent Convolutional Networks for Video-based Person Re-identification: An End-to-End Approach arxiv: https://arxiv.org/abs/1606.01609 Jointly Attentive Spatial-Temporal Pooling Networks for Video-based Person Re-Identification intro: ICCV 2017 arxiv: https://arxiv.org/abs/1708.02286 Three-Stream Convolutional Networks for Video-based Person Re-Identification arxiv: https://arxiv.org/abs/1712.01652 LVreID: Person Re-Identification with Long Sequence Videos arxiv: https://arxiv.org/abs/1712.07286 Multi-shot Pedestrian Re-identification via Sequential Decision Making intro: CVPR 2018. TuSimple keywords: reinforcement learning arxiv: https://arxiv.org/abs/1712.07257 github: https://github.com/TuSimple/rl-multishot-reid LVreID: Person Re-Identification with Long Sequence Videos arxiv: https://arxiv.org/abs/1712.07286 Diversity Regularized Spatiotemporal Attention for Video-based Person Re-identification intro: CUHK-SenseTime &amp; Argo AI arxiv: https://arxiv.org/abs/1803.09882 Video Person Re-identification with Competitive Snippet-similarity Aggregation and Co-attentive Snippet Embedding intro: CVPR 2018 Poster paper: http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_Video_Person_Re-Identification_CVPR_2018_paper.pdf Exploit the Unknown Gradually: One-Shot Video-Based Person Re-Identification by Stepwise Learning intro: CVPR 2018 paper: http://openaccess.thecvf.com/content_cvpr_2018/papers/Wu_Exploit_the_Unknown_CVPR_2018_paper.pdf Revisiting Temporal Modeling for Video-based Person ReID arxiv: https://arxiv.org/abs/1805.02104 github: https://github.com/jiyanggao/Video-Person-ReID Video Person Re-identification by Temporal Residual Learning arxiv: https://arxiv.org/abs/1802.07918 A Spatial and Temporal Features Mixture Model with Body Parts for Video-based Person Re-Identification arxiv: https://arxiv.org/abs/1807.00975 Video-based Person Re-identification via 3D Convolutional Networks and Non-local Attention intro: University of Science and Technology of China &amp; University of Chinese Academy of Sciences arxiv: https://arxiv.org/abs/1807.05073 Spatial-Temporal Synergic Residual Learning for Video Person Re-Identification arxiv: https://arxiv.org/abs/1807.05799 Where-and-When to Look: Deep Siamese Attention Networks for Video-based Person Re-identification intro: IEEE Transactions on Multimedia arxiv: https://arxiv.org/abs/1808.01911 STA: Spatial-Temporal Attention for Large-Scale Video-based Person Re-Identification intro: AAAI 2019 arxiv: https://arxiv.org/abs/1811.04129 Multi-scale 3D Convolution Network for Video Based Person Re-Identification intro: AAAI 2019 arxiv: https://arxiv.org/abs/1811.07468 Deep Active Learning for Video-based Person Re-identification arxiv: https://arxiv.org/abs/1812.05785 Spatial and Temporal Mutual Promotion for Video-based Person Re-identification intro: AAAI 2019 arxiv: https://arxiv.org/abs/1812.10305 3D PersonVLAD: Learning Deep Global Representations for Video-based Person Re-identification arxiv: https://arxiv.org/abs/1812.10222 SCAN: Self-and-Collaborative Attention Network for Video Person Re-identification intro: TIP 2019 arxiv: https://arxiv.org/abs/1807.05688 GAN-based Pose-aware Regulation for Video-based Person Re-identification intro: Heriot-Watt University &amp; University of Edinburgh &amp; Queen’s University Belfast &amp; Anyvision keywords: Weighted Fusion (WF) &amp; Weighted-Pose Regulation (WPR) arxiv: https://arxiv.org/abs/1903.11552 Convolutional Temporal Attention Model for Video-based Person Re-identification intro: ICME 2019 arxiv: https://arxiv.org/abs/1904.04492 Re-rankingDivide and Fuse: A Re-ranking Approach for Person Re-identification intro: BMVC 2017 arxiv: https://arxiv.org/abs/1708.04169 Re-ranking Person Re-identification with k-reciprocal Encoding intro: CVPR 2017 arxiv: https://arxiv.org/abs/1701.08398 github: https://github.com/zhunzhong07/person-re-ranking A Pose-Sensitive Embedding for Person Re-Identification with Expanded Cross Neighborhood Re-Ranking intro: CVPR 2018 arxiv: https://arxiv.org/abs/1711.10378 github(official): https://github.com/pse-ecn/expanded-cross-neighborhood Adaptive Re-ranking of Deep Feature for Person Re-identification arxiv: https://arxiv.org/abs/1811.08561 Unsupervised Re-IDUnsupervised Person Re-identification: Clustering and Fine-tuning arxiv: https://arxiv.org/abs/1705.10444 github: https://github.com/hehefan/Unsupervised-Person-Re-identification-Clustering-and-Fine-tuning Stepwise Metric Promotion for Unsupervised Video Person Re-identification intro: ICCV 2017 paper: http://openaccess.thecvf.com/content_ICCV_2017/papers/Liu_Stepwise_Metric_Promotion_ICCV_2017_paper.pdf github: https://github.com/lilithliu/StepwiseMetricPromotion-code Dynamic Label Graph Matching for Unsupervised Video Re-Identification intro: ICCV 2017 arxiv: https://arxiv.org/abs/1709.09297 github: https://github.com/mangye16/dgm_re-id Unsupervised Cross-dataset Person Re-identification by Transfer Learning of Spatio-temporal Patterns intro: CVPR 2018 arxiv: https://arxiv.org/abs/1803.07293 github: https://github.com/ahangchen/TFusion blog: https://zhuanlan.zhihu.com/p/34778414 Cross-dataset Person Re-Identification Using Similarity Preserved Generative Adversarial Networks arxiv: https://arxiv.org/abs/1806.04533 Transferable Joint Attribute-Identity Deep Learning for Unsupervised Person Re-Identification intro: CVPR 2018 arxiv: https://arxiv.org/abs/1803.09786 Adaptation and Re-Identification Network: An Unsupervised Deep Transfer Learning Approach to Person Re-Identification intro: CVPR 2018 workshop. National Taiwan University &amp; Umbo Computer Vision keywords: adaptation and re-identification network (ARN) arxiv: https://arxiv.org/abs/1804.09347 Domain Adaptation through Synthesis for Unsupervised Person Re-identification arxiv: https://arxiv.org/abs/1804.10094 Deep Association Learning for Unsupervised Video Person Re-identification intro: BMVC 2018 arxiv: https://arxiv.org/abs/1808.07301 Support Neighbor Loss for Person Re-Identification intro: ACM Multimedia (ACM MM) 2018 arxiv: https://arxiv.org/abs/1808.06030 Unsupervised Person Re-identification by Deep Learning Tracklet Association intro: ECCV 2018 Oral arxiv: https://arxiv.org/abs/1809.02874 Unsupervised Tracklet Person Re-Identification intro: TPAMI 2019 arxiv: https://arxiv.org/abs/1903.00535 github: https://github.com/liminxian/DukeMTMC-SI-Tracklet Unsupervised Person Re-identification by Deep Asymmetric Metric Embedding intro: TPAMI keywords: DEep Clustering-based Asymmetric MEtric Learning (DECAMEL) arxiv: https://arxiv.org/abs/1901.10177 github: https://github.com/KovenYu/DECAMEL Unsupervised Person Re-identification by Soft Multilabel Learning intro: CVPR 2019 oral intro: Sun Yat-sen University &amp; YouTu Lab &amp; Queen Mary University of London keywords: MAR (MultilAbel Reference learning), soft multilabel-guided hard negative mining project page: https://kovenyu.com/publication/2019-cvpr-mar/ arxiv: https://arxiv.org/abs/1903.06325 github(official, Pytorch): https://github.com/KovenYu/MAR A Novel Unsupervised Camera-aware Domain Adaptation Framework for Person Re-identification arxiv: https://arxiv.org/abs/1904.03425 Weakly Supervised Person Re-identificationWeakly Supervised Person Re-Identification intro: CVPR 2019 keywords: multi-instance multi-label learning (MIML), Cross-View MIML (CV-MIML) arxiv: https://arxiv.org/abs/1904.03832 Weakly Supervised Person Re-identification: Cost-effective Learning with A New Benchmark keywords: SYSU-30k arxiv: https://arxiv.org/abs/1904.03845 Vehicle Re-IDLearning Deep Neural Networks for Vehicle Re-ID with Visual-spatio-temporal Path Proposals intro: ICCV 2017 arxiv: https://arxiv.org/abs/1708.03918 Viewpoint-Aware Attentive Multi-View Inference for Vehicle Re-Identification intro: CVPR 2018 paper: http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhou_Viewpoint-Aware_Attentive_Multi-View_CVPR_2018_paper.pdf RAM: A Region-Aware Deep Model for Vehicle Re-Identification intro: ICME 2018 arxiv: https://arxiv.org/abs/1806.09283 Vehicle Re-Identification in Context intro: Pattern Recognition - 40th German Conference, (GCPR) 2018, Stuttgart project page: https://qmul-vric.github.io/ arxiv: https://arxiv.org/abs/1809.09409 Vehicle Re-identification Using Quadruple Directional Deep Learning Features arxiv: https://arxiv.org/abs/1811.05163 Coarse-to-fine: A RNN-based hierarchical attention model for vehicle re-identification intro: ACCV 2018 arxiv: https://arxiv.org/abs/1812.04239 Vehicle Re-Identification: an Efficient Baseline Using Triplet Embedding arxiv: https://arxiv.org/abs/1901.01015 A Two-Stream Siamese Neural Network for Vehicle Re-Identification by Using Non-Overlapping Cameras intro: ICIP 2019 arxiv: https://arxiv.org/abs/1902.01496 CityFlow: A City-Scale Benchmark for Multi-Target Multi-Camera Vehicle Tracking and Re-Identification intro: Accepted for oral presentation at CVPR 2019 with review ratings of 2 strong accepts and 1 accept (work done during an internship at NVIDIA) arxiv: https://arxiv.org/abs/1903.09254 Vehicle Re-identification in Aerial Imagery: Dataset and Approach intro: Northwestern Polytechnical University arxiv: https://arxiv.org/abs/1904.01400 Deep Metric LearningDeep Metric Learning for Person Re-Identification intro: ICPR 2014 paper: http://www.cbsr.ia.ac.cn/users/zlei/papers/ICPR2014/Yi-ICPR-14.pdf Deep Metric Learning for Practical Person Re-Identification arxiv: https://arxiv.org/abs/1407.4979 Constrained Deep Metric Learning for Person Re-identification arxiv: https://arxiv.org/abs/1511.07545 Embedding Deep Metric for Person Re-identication A Study Against Large Variations intro: ECCV 2016 arxiv: https://arxiv.org/abs/1611.00137 DarkRank: Accelerating Deep Metric Learning via Cross Sample Similarities Transfer intro: TuSimple keywords: pedestrian re-identification arxiv: https://arxiv.org/abs/1707.01220 ProjectsOpen-ReID: Open source person re-identification library in python intro: Open-ReID is a lightweight library of person re-identification for research purpose. It aims to provide a uniform interface for different datasets, a full set of models and evaluation metrics, as well as examples to reproduce (near) state-of-the-art results. project page: https://cysu.github.io/open-reid/ github(PyTorch): https://github.com/Cysu/open-reid examples: https://cysu.github.io/open-reid/examples/training_id.html benchmarks: https://cysu.github.io/open-reid/examples/benchmarks.html caffe-PersonReID intro: Person Re-Identification: Multi-Task Deep CNN with Triplet Loss gtihub: https://github.com/agjayant/caffe-Person-ReID Person_reID_baseline_pytorch intro: Pytorch implement of Person re-identification baseline arxiv: https://github.com/layumi/Person_reID_baseline_pytorch deep-person-reid intro: Pytorch implementation of deep person re-identification models. github: https://github.com/KaiyangZhou/deep-person-reid ReID_baseline intro: Baseline model (with bottleneck) for person ReID (using softmax and triplet loss). github: https://github.com/L1aoXingyu/reid_baseline blog: https://zhuanlan.zhihu.com/p/40514536 gluon-reid intro: A code gallery for person re-identification with mxnet-gluon, and I will reproduce many STOA algorithm. github: https://github.com/xiaolai-sqlai/gluon-reid EvaluationDukeMTMC-reID intro: The Person re-ID Evaluation Code for DukeMTMC-reID Dataset (Including Dataset Download) github: https://github.com/layumi/DukeMTMC-reID_evaluation DukeMTMC-reID_baseline (Matlab) github: https://github.com/layumi/DukeMTMC-reID_baseline Code for IDE baseline on Market-1501 github: https://github.com/zhunzhong07/IDE-baseline-Market-1501 DatasetsRe-ID 数据集汇总https://robustsystems.coe.neu.edu/sites/robustsystems.coe.neu.edu/files/systems/projectpages/reiddataset.html Attribute相关数据集RAP: http://rap.idealtest.org/Attribute for Market-1501 and DukeMTMC_reID: https://vana77.github.io/ 视频相关数据集Mars: http://liangzheng.org/Project/project_mars.htmlPRID2011: https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/ NLP相关数据集自然语言搜图像: http://xiaotong.me/static/projects/person-search-language/dataset.html自然语言搜行人所在视频: http://www.mi.t.u-tokyo.ac.jp/projects/person_search Tutorials1st Workshop on Target Re-Identification and Multi-Target Multi-Camera Trackinghttps://reid-mct.github.io/ Target Re-Identification and Multi-Target Multi-Camera Trackinghttp://openaccess.thecvf.com/CVPR2017_workshops/CVPR2017_W17.py Person Re-Identification: Theory and Best Practicehttp://www.micc.unifi.it/reid-tutorial/ Experts Listed in No Particular Order Shaogang Gong - [http://www.eecs.qmul.ac.uk/~sgg/] Xiaogang Wang - [http://www.ee.cuhk.edu.hk/~xgwang/] Weishi Zheng - [http://isee.sysu.edu.cn/~zhwshi/] Liang Zheng - [http://www.liangzheng.com.cn/] Li Zhang - [http://www.robots.ox.ac.uk/~lz/] Xiatian Zhu - [http://www.eecs.qmul.ac.uk/~xiatian/index.html] Chen Change Loy - [https://staff.ie.cuhk.edu.hk/~ccloy/] Qi Tian - [http://www.cs.utsa.edu/~qitian/tian-publication-year.html] Shengcai Liao - [http://www.cbsr.ia.ac.cn/users/scliao/] Rui Zhao - [http://www.ee.cuhk.edu.hk/~rzhao/] Yang Yang - [http://www.cbsr.ia.ac.cn/users/yyang/main.htm] Ling Shao - [http://lshao.staff.shef.ac.uk] Ziyan Wu - [http://wuziyan.com/] DaPeng Chen - [http://gr.xjtu.edu.cn/web/dapengchen/home] Horst Bischof - [https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/prid450s] Niki Martinel - [http://users.dimi.uniud.it/~niki.martinel/] Liang Lin - [http://hcp.sysu.edu.cn/home/] Le An - [http://auto.hust.edu.cn/index.php?a=shows&amp;catid=28&amp;id=134] Xiang Bai - [http://mc.eistar.net/~xbai/index.html] Xiaoyuan Jing - [http://mla.whu.edu.cn/plus/list.php?tid=2] Fei Xiong - [http://robustsystems.coe.neu.edu/?q=content/research] DaPeng Chen - [http://gr.xjtu.edu.cn/web/dapengchen/home] Zhedong Zheng - [http://zdzheng.xyz/] Zhun Zhong - [http://zhunzhong.site/] ResourcesRe-id Resourceshttps://wangzwhu.github.io/home/re_id_resources.html Zhuanzhihttp://www.zhuanzhi.ai/topic/2001183057160970 Zhihu行人重识别: https://zhuanlan.zhihu.com/personReidPerson Re-id: https://zhuanlan.zhihu.com/re-idTopci: https://www.zhihu.com/topic/20087378/hot Blogs行人重识别简介: https://www.jianshu.com/p/98cc04cca0ae基于深度学习的Person Re-ID（综述）: https://blog.csdn.net/linolzhang/article/details/71075756行人再识别（行人重识别）【包含与行人检测的对比】: https://blog.csdn.net/liuqinglong110/article/details/41699861行人重识别综述（Person Re-identification: Past, Present and Future）: https://blog.csdn.net/auto1993/article/details/74091803行人重识别: http://cweihang.cn/ml/reid/","link":"/reid-overview.html"},{"title":"Person Re-identification数据集描述——Market-1501","text":"数据集简介 Market-1501 数据集在清华大学校园中采集，夏天拍摄，在 2015 年构建并公开。它包括由6个摄像头（其中5个高清摄像头和1个低清摄像头）拍摄到的 1501 个行人、32668 个检测到的行人矩形框。每个行人至少由2个摄像头捕获到，并且在一个摄像头中可能具有多张图像。训练集有 751 人，包含 12,936 张图像，平均每个人有 17.2 张训练数据；测试集有 750 人，包含 19,732 张图像，平均每个人有 26.3 张测试数据。3368 张查询图像的行人检测矩形框是人工绘制的，而 gallery 中的行人检测矩形框则是使用DPM检测器检测得到的。该数据集提供的固定数量的训练集和测试集均可以在single-shot或multi-shot测试设置下使用。 目录结构Market-1501 ├── bounding_box_test ├── 0000_c1s1_000151_01.jpg ├── 0000_c1s1_000376_03.jpg ├── 0000_c1s1_001051_02.jpg ├── bounding_box_train ├── 0002_c1s1_000451_03.jpg ├── 0002_c1s1_000551_01.jpg ├── 0002_c1s1_000801_01.jpg ├── gt_bbox ├── 0001_c1s1_001051_00.jpg ├── 0001_c1s1_009376_00.jpg ├── 0001_c2s1_001976_00.jpg ├── gt_query ├── 0001_c1s1_001051_00_good.mat ├── 0001_c1s1_001051_00_junk.mat ├── query ├── 0001_c1s1_001051_00.jpg ├── 0001_c2s1_000301_00.jpg ├── 0001_c3s1_000551_00.jpg └── readme.txt 目录介绍1） “bounding_box_test”——用于测试集的 750 人，包含 19,732 张图像，前缀为 0000 表示在提取这 750 人的过程中DPM检测错的图（可能与query是同一个人），-1 表示检测出来其他人的图（不在这 750 人中）2） “bounding_box_train”——用于训练集的 751 人，包含 12,936 张图像3） “query”——为 750 人在每个摄像头中随机选择一张图像作为query，因此一个人的query最多有 6 个，共有 3,368 张图像4） “gt_query”——matlab格式，用于判断一个query的哪些图片是好的匹配（同一个人不同摄像头的图像）和不好的匹配（同一个人同一个摄像头的图像或非同一个人的图像）5） “gt_bbox”——手工标注的bounding box，用于判断DPM检测的bounding box是不是一个好的box 命名规则以 0001_c1s1_000151_01.jpg 为例1） 0001 表示每个人的标签编号，从0001到1501；2） c1 表示第一个摄像头(camera1)，共有6个摄像头；3） s1 表示第一个录像片段(sequece1)，每个摄像机都有数个录像段；4） 000151 表示 c1s1 的第000151帧图片，视频帧率25fps；5） 01 表示 c1s1_001051 这一帧上的第1个检测框，由于采用DPM检测器，对于每一帧上的行人可能会框出好几个bbox。00 表示手工标注框 测试协议Cumulative Matching Characteristics (CMC) curves 是目前行人重识别领域最流行的性能评估方法。考虑一个简单的 single-gallery-shot 情形，每个数据集中的ID(gallery ID)只有一个实例. 对于每一次的识别(query), 算法将根据要查询的图像(query) 到所有gallery samples的距离从小到大排序，CMC top-k accuracy 计算如下： Acc_k = 1, if top-k ranked gallery samples contain query identity Acc_k = 0, otherwise 这是一个 shifted step function, 最终的CMC 曲线(curve) 通过对所有queries的shifted step functions取平均得到。尽管在 single-gallery-shot 情形下，CMC 有很明确的定义，但是在 multi-gallery-shot 情形下，它的定义并不明确，因为每个gallery identity 可能存在多个instances. Market-1501中 Query 和 gallery 集可能来自相同的摄像头视角，但是对于每个query identity, 他/她的来自同一个摄像头的 gallery samples 会被排除掉。对于每个 gallery identity，他们不会只随机采样一个instance. 这意味着在计算CMC时， query 将总是匹配 gallery 中“最简单”的正样本，而不关注其他更难识别的正样本。bounding_box_test 文件夹是 gallery 样本，bounding_box_train 文件夹是 train 样本，query 文件夹是 query 样本 由上面可以看出，在 multi-gallery-shot 情形下，CMC评估具有缺陷。因此，也使用 mAP（mean average precsion）作为评估指标。mAP可认为是PR曲线下的面积，即平均的查准率。 Market-1501 Evaluation Code 下载地址 Google Drive Baidu Disk State of the art State of the art on the Market-1501 dataset CitationIf you use this dataset, please kindly cite this paper:123456@inproceedings{zheng2015scalable, title={Scalable Person Re-identification: A Benchmark}, author={Zheng, Liang and Shen, Liyue and Tian, Lu and Wang, Shengjin and Wang, Jingdong and Tian, Qi}, booktitle={Computer Vision, IEEE International Conference on}, year={2015}} 参考文献 Zheng, Liang, et al. “Scalable Person Re-identification: A Benchmark.” IEEE International Conference on Computer Vision IEEE Computer Society, 2015:1116-1124. Liang Zheng Person re-ID","link":"/reid-market-1501.html"},{"title":"Person Re-identification数据集描述——DukeMTMC-reID","text":"数据集简介 DukeMTMC 数据集是一个大规模标记的多目标多摄像机行人跟踪数据集。它提供了一个由 8 个同步摄像机记录的新型大型高清视频数据集，具有 7,000 多个单摄像机轨迹和超过 2,700 多个独立人物，DukeMTMC-reID 是 DukeMTMC 数据集的行人重识别子集，并且提供了人工标注的bounding box。 目录结构DukeMTMC-reID ├── bounding_box_test ├── 0002_c1_f0044158.jpg ├── 3761_c6_f0183709.jpg ├── 7139_c2_f0160815.jpg ├── bounding_box_train ├── 0001_c2_f0046182.jpg ├── 0008_c3_f0026318.jpg ├── 7140_c4_f0175988.jpg ├── query ├── 0005_c2_f0046985.jpg ├── 0023_c4_f0031504.jpg ├── 7139_c2_f0160575.jpg └── CITATION_DukeMTMC.txt └── CITATION_DukeMTMC-reID.txt └── LICENSE_DukeMTMC.txt └── LICENSE_DukeMTMC-reID.txt └── README.md 目录介绍从视频中每 120 帧采样一张图像，得到了 36,411 张图像。一共有 1,404 个人出现在大于两个摄像头下，有 408 个人 (distractor ID) 只出现在一个摄像头下。1） “bounding_box_test”——用于测试集的 702 人，包含 17,661 张图像（随机采样，702 ID + 408 distractor ID）2） “bounding_box_train”——用于训练集的 702 人，包含 16,522 张图像（随机采样）3） “query”——为测试集中的 702 人在每个摄像头中随机选择一张图像作为 query，共有 2,228 张图像 命名规则以 0001_c2_f0046182.jpg 为例1） 0001 表示每个人的标签编号；2） c2 表示来自第二个摄像头(camera2)，共有 8 个摄像头；3） f0046182 表示来自第二个摄像头的第 46182 帧。 Dataset Insights数据分布 Figure. The image distribution of DukeMTMC-reID training set. We note that the median of images per ID is 20. But some ID may contain lots of images, which may compromise some algorithms. (For example, ID 5388 contains 426 images.) Thank Xun for suggestions. 地理位置 This picture is from DukeMTMC Homepage. 测试协议(Matlab)To evaluate, you need to calculate your gallery and query feature (i.e., 17661x2048 and 2228x2048 matrix) and save them in advance. Then download the codes in this repository. You just need to change the image path and the feature path in the evaluation_res_duke_fast.m and run it to evaluate. (Python)We also provide an evaluation code in python. You may refer to here. 下载地址 Google Drive Baidu Disk 密码：bhbh DukeMTMC Project BaselineWe release our baseline training code and pretrained model in [Matconvnet Version] and [Pytorch Version]. You can choose one of the two tools to conduct the experiment. Furthermore, you may try our new Pedestrain Alignment Code which combines person alignment with re-ID. Or you can directly download the finetuned ResNet-50 baseline feature. You can download it from GoogleDriver or BaiduYun, which includes the feature of training set, query set and gallery set. The DukeMTMC-reID LICENSE is also included. State-of-the-art State of the art on the DukeMTMC-reID dataset CitationIf you use this dataset, please kindly cite the following two papers:123456789101112@inproceedings{zheng2017unlabeled, title={Unlabeled Samples Generated by GAN Improve the Person Re-identification Baseline in vitro}, author={Zheng, Zhedong and Zheng, Liang and Yang, Yi}, booktitle={Proceedings of the IEEE International Conference on Computer Vision}, year={2017}}@inproceedings{ristani2016MTMC, title = {Performance Measures and a Data Set for Multi-Target, Multi-Camera Tracking}, author = {Ristani, Ergys and Solera, Francesco and Zou, Roger and Cucchiara, Rita and Tomasi, Carlo}, booktitle = {European Conference on Computer Vision workshop on Benchmarking Multi-Target Tracking}, year = {2016}} 参考文献 Unlabeled Samples Generated by GAN Improve the Person Re-identification Baseline in vitro. Zheng et al., ICCV 2017 Performance Measures and a Data Set for Multi-Target, Multi-Camera Tracking. Ristani et al., ECCVWS 2016 DukeMTMC-reID Description https://blog.csdn.net/Layumi1993/article/details/72716551","link":"/reid-duke.html"},{"title":"Person Re-identification数据集描述——CUHK03","text":"CUHK03是第一个足以进行深度学习的大规模行人重识别数据集，该数据集的图像采集于香港中文大学（CUHK）校园。数据以”cuhk-03.mat”的 MAT 文件格式存储，含有 1467 个不同的人物，由 5 对摄像头采集。 数据集简介目录结构CUHK-03 ├── “detected”── 5 x 1 cell ├── 843x10 cell ├── 440x10 cell ├── 77x10 cell ├── 58x10 cell ├── 49x10 cell ├── “labeled”── 5 x 1 cell ├── 843x10 cell ├── 440x10 cell ├── 77x10 cell ├── 58x10 cell ├── 49x10 cell ├── “testsets”── 20 x 1 cell ├── 100 x 2 double matrix 目录介绍（1）”detected”—— 5 x 1 cells，由机器标注，每个 cell 中包含一对摄像头组采集的照片，如下所示： 每个摄像头组由 M x 10 cells 组成，M 为行人索引，前 5 列和后 5 列分别来自同一组的不同摄像头。 cell 内每个元素为一幅 H x W x 3 的行人框图像(uint8 数据类型)，个别图像可能空缺，为空集。 843x10 cell ——&gt; 摄像头组pair 1。 440x10 cell ——&gt; 摄像头组pair 2。 77x10 cell ——&gt; 摄像头组pair 3。 58x10 cell ——&gt; 摄像头组pair 4。 49x10 cell ——&gt; 摄像头组pair 5。 （2）”labeled”—— 5 x 1 cells，行人框由人工标注，格式和内容和”detected”相同。 （3）”testsets”—— 20 x 1 cells，测试协议，由 20 个 100 x 2 double 类型矩阵组成 (重复二十次)。 100 x 2 double，100 行代表 100 个测试样本，第 1 列为摄像头 pair 索引，第 2 列为行人索引。 测试协议CUHK-03的测试协议有两种。 第一种为旧的版本(参考文献 [1], 即数据集的出处)，参见数据集中的’testsets’测试协议。具体地说，即随机选出100个行人作为测试集，1160 个行人作为训练集，100 个行人作为验证集（这里总共 1360 个行人而不是 1467 个，这是因为实验中没有用到摄像头组pair 4 和 5 的数据），重复二十次。这种测试协议是 single-shot setting. 第二种测试协议(参考文献 [2])类似于 Market-1501 ，它将数据集分为包含 767 个行人的训练集和包含 700 个行人的测试集。在测试阶段，我们随机选择一张图像作为 query，剩下的作为 gallery，这样的话，对于每个行人，有多个 ground truth 在 gallery 中。（新测试协议可以参考这里） 下载地址 Google Drive Baidu Disk 密码：rhjq State-of-the-art State of the art on the CUHK03 CitationIf you use this dataset, please kindly cite the following paper:123456@inproceedings{li2014deepreid, title={DeepReID: Deep Filter Pairing Neural Network for Person Re-identification}, author={Li, Wei and Zhao, Rui and Xiao, Tong and Wang, Xiaogang}, booktitle={CVPR}, year={2014}} 参考文献 Li, W., Zhao, R., Xiao, T., &amp; Wang, X. (2014). Deepreid: Deep filter pairing neural network for person re-identification. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 152-159). Zhong Z, Zheng L, Cao D, et al. Re-ranking person re-identification with k-reciprocal encoding[C]//Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on. IEEE, 2017: 3652-3661. zhunzhong07/person-re-ranking https://blog.csdn.net/hyk_1996/article/details/79387053 http://www.ee.cuhk.edu.hk/~xgwang/CUHK_identification.html","link":"/reid-cuhk03.html"},{"title":"深度残差网络ResNet初探","text":"微软亚洲研究院 Kaiming He 博士在 2015 年凭借深度残差网络 Deep Residual Network (DRN) 在 Imagenet 比赛的识别、检测和定位三个任务、以及 COCO 比赛的检测和分割任务上都获得了冠军。论文《Deep Residual Learning for Image Recognition》获得 2016 CVPR best paper，ResNet因此声名大噪，很大程度上引发了 deep network 的革命。 问题提出 现有的深度学习思想可能认为深层的网络一般会比浅层的网络效果好，如果要进一步地提升模型的准确率，最直接的方法就是把网络设计得越深越好，这样模型的准确率也就会越来越准确。例如在图像处理任务中，CNN 能够提取 low / mid / high-level 的特征，网络的层数越多，意味着能够提取到不同 level 的特征越丰富。越深的网络提取的特征越抽象，越具有语义信息。 Kaiming 博士在论文中做了这样一组实验：在 CIFAR-10 数据集上分别训练了一个 20 层和 56 层的 plain network (卷积、池化、全连接构成的传统 CNN )，发现 56 层网络的训练误差和测试误差都大于 20 层网络的训练误差，即网络层数加深时，模型效果却越来越差，在训练集上的准确率甚至下降了，因此这个显然不是由于 overfitting 导致的，因为 overfitting 应该表现为在训练集上效果更好才对。 分析思考1.为什么不能直接简单地增加层数？ 神经网络的深度加深，一个众所周知的问题就是梯度的消失和爆炸 (gradients vanishing / gradients exploding)，它会导致深层的网络参数得不到有效的校正信号或使得训练难以收敛，通过正则化初始化或者中间的正则化层 (Batch Normalization) 方法可以得到有效的缓解，但并不能解决这里提出的问题。 2.为什么网络层数加深时，网络的性能反而下降？ 我们假设现在有一个浅层 (假设层数为 n) 的神经网络plain network A ，具有比较理想的输出结果，现在在这个神经网络的后边再加 m 层得到一个新的神经网络 B，我们发现输出结果的准确度反而下降了。这是不合理的，因为如果后边加上的那 m 层是对前 n 层的输出结果做恒等映射 (identity mapping)，至少 B 也能和 A 的性能持平才对。但是实验的结果表明现在的求解方法并不能得到理想的结果，这说明 B 网络在学习恒等映射的时候出了问题，也就是传统网络 (plain networks) 很难去学习恒等映射，这就是所谓的退化 (degradation) 现象。 核心思想 如果深层网络的后面那些层是恒等映射，那么模型就退化为一个浅层网络，现在要解决的就是如何学习恒等映射函数。但是直接让一些层去拟合一个潜在的恒等映射函数 H(x) = x 是很困难的，但是如果使用残差函数 H(x) = F(x) + x，F(x) = H(x) - x，如果能使 F(x) = 0，H(x) 就是恒等映射。 网络输入是 x，网络的输出是 F(x)，网络要拟合的目标是 H(x)，传统网络的训练目标是 F(x) = H(x)。 残差网络，则是把传统网络的输出 F(x) 处理一下，加上输入 x，变成 F(x) + x 作为最终的输出，训练目标是 F(x) = H(x) - x。 现在我们要训练一个深层的网络，它可能过深，假设存在一个性能最强的完美网络 N，与它相比我们的网络中必定有一些层是多余的，那么这些多余的层的训练目标是恒等变换，只有达到这个目标我们的网络性能才能跟 N 一样。对于这些需要实现恒等变换的多余的层，要拟合的目标就成了 H(x) = x，在传统网络中，网络的输出目标是 F(x) = x，这比较困难，而在残差网络中，拟合的目标成了 x - x = 0，网络的输出目标为 F(x) = 0，这比前者要容易得多。 这里的 F(x) + x 为什么是 x 而不是其他值？因为多余的层的目标是恒等变换，即 F(x) + x = x，那 F(x) 的训练目标就是 0，比较容易。如果是其他，比如 x/2 ，那 F(x) 的训练目标就是 x/2，是一个非 0 的值，比 0 难实现。Kaiming 博士的另一篇文章[2]中探讨了这个问题，对6种结构的残差结构进行实验比较证明 F(x) 加上输入值 x 的效果最好。 Residual Block 在上图的残差网络结构图中，通过“shortcut connections (捷径连接)”的方式，直接把输入x传到输出作为初始结果，输出结果为 H(x) = F(x) + x，当 F(x) = 0 时，那么 H(x) = x，也就是上面所提到的恒等映射。于是，ResNet相当于将学习目标改变了，不再是学习一个完整的输出，而是目标值H(X)和x的差值，即所谓的残差F(x) = H(x) - x，因此，后面的训练目标就是要将残差结果逼近于 0，使得随着网络加深，准确率不下降。 它有二层，如下表达式，其中 $\\sigma$ 代表非线性函数ReLU：$$\\mathcal{F} = W_2\\sigma(W_1x)$$ 然后通过一个 shortcut connection，和第 2 个 ReLU，获得输出 y：$${y}= \\mathcal{F}({x}, {W_{i}}) + {x}.$$ F(x) 与 x 相加就是逐元素相加，但是如果两者维度不同，需要给 x 执行一个线性变换来匹配维度，如下式： $${y}= \\mathcal{F}({x}, {W_{i}}) + W_s{x}.$$ 实验证明，这个残差块往往需要两层以上，单单一层的残差块 $y = W_1x + x$ 并不能起到提升作用。 这种残差跳跃式的结构，打破了传统的神经网络 n - 1 层的输出只能给 n 层作为输入的惯例，使某一层的输出可以直接跨过几层作为后面某一层的输入，其意义在于为叠加多层网络而使得整个学习模型的错误率不降反升的难题提供了新的方向 (后来的 DenseNet)。至此，神经网络的层数可以超越之前的约束，达到几十层、上百层甚至千层，为高级语义特征提取和分类提供了可行性。 Model Structure 作者由 VGG19 设计出了 plain network 和 Resnet-34，如下图中部和右侧网络。 对于输出 feature map 大小相同的层，有相同数量的 filters，即 channel 数相同； 当 feature map 大小减半时（pooling），filters数量翻倍。 对于残差网络，维度匹配的shortcut连接为实线，反之为虚线。维度不匹配时，同等映射有两种可选方案： 直接通过 zero padding 来增加维度（channel）。 乘以 W 矩阵投影到新的空间。实现是用 1 x 1 卷积实现的，直接改变 1 x 1 卷积的 filters 数目。这种会增加参数。 下图是Resnet对应于ImageNet的结构框架。中括号中为残差块的参数，多个残差块进行堆叠。下采样由 stride 为 2 的 conv3_1、conv4_1 和 conv5_1 来实现。 Bottle neck 考虑到时间花费和降低参数的数目，将原来的 Residual Block (残差学习结构) 改为 Bottleneck 结构，如上图。首端和末端的 1 x 1 卷积用来削减和恢复维度，相比于原本结构，只有中间 3 x 3 成为瓶颈部分。两种结构分别针对 ResNet-34 （左图）和 ResNet-50/ 101 / 152（右图）。 左图是两个 3 x 3 x 256的卷积，参数数目: 3 x 3 x 256 x 256 x 2 = 1179648；右图是第一个 1 x 1 的卷积把 256 维通道降到 64 维，然后在最后通过 1 x 1 卷积恢复，整体上用的参数数目：1 x 1 x 256 x 64 + 3 x 3 x 64 x 64 + 1 x 1 x 64 x 256 = 69632，右图的参数量比左图减少了 16.94 倍。对于常规的ResNet，可以用于34层或者更少的网络中（左图），对于更深的网络（如50 / 101 / 152层），则使用右图，其目的是减少计算和参数量。 TensorFlow实现 KaimingHe/deep-residual-networks wenxinxu/resnet-in-tensorflow tensorpack/examples/ResNet ry/tensorflow-resnet Python示例123456789101112131415161718192021222324252627282930313233def residual_block(x, out_channels, down_sample, projection=False): in_channels = x.get_shape().as_list()[3] if down_sample: x = max_pool(x) output = conv2d_with_batch_norm(x, [3, 3, in_channels, out_channels], 1) output = conv2d_with_batch_norm(output, [3, 3, out_channels, out_channels], 1) if in_channels != out_channels: if projection: # projection shortcut input_ = conv2d(x, [1, 1, in_channels, out_channels], 2) else: # zero-padding input_ = tf.pad(x, [[0,0], [0,0], [0,0], [0, out_channels - in_channels]]) else: input_ = x return output + input_def residual_group(name,x,num_block,out_channels): assert num_block&gt;=1,'num_block must greater than 1' with tf.variable_scope('%s_head'%name): output = residual_block(x, out_channels, True) for i in range (num_block-1): with tf.variable_scope('%s_%d' % (name,i+1)): output = residual_block(output,out_channels, False) return output 参考资料 He, K., Zhang, X., Ren, S., &amp; Sun, J. (2016). Deep Residual Learning for Image Recognition. IEEE Conference on Computer Vision and Pattern Recognition (pp.770-778). IEEE Computer Society. https://www.jianshu.com/p/e58437f39f65 https://zhuanlan.zhihu.com/p/32085715 https://my.oschina.net/u/876354/blog/1622896 https://blog.csdn.net/wspba/article/details/57074389","link":"/resnet.html"},{"title":"Ubuntu 16.04安装NCCL 2","text":"NCCL是Nvidia Collective multi-GPU Communication Library的简称，它是一个实现多GPU的collective communication通信（all-gather, reduce, broadcast）库，Nvidia做了很多优化，以在PCIe、Nvlink、InfiniBand上实现较高的通信速度。本文介绍如何在Ubuntu 16.04 LTS上安装NCCL 2库。 环境要求确保您的环境符合以下要求： glibc 2.19或更高 CUDA 8.0或更高版本 NCCL支持所有具有3.0或更高计算能力的CUDA设备。如何查看所有NVIDIA GPU的计算能力? 安装NCCL为了下载NCCL，请确保您已注册NVIDIA开发者账号。 打开NVIDIA NCCL主页。 点击下载。 完成简短调查问卷并点击提交。 接受条款和条件。查看NCCL显示的可用下载版本列表。 选择您想要安装的NCCL版本。显示可用版本列表。根据您使用的Linux发行版以选择正确的软件包。 Ubuntu 14.04 LTS和Ubuntu 16.04 LTS在Ubuntu上安装NCCL需要您首先向包含NCCL软件包的APT系统添加存储库，然后通过APT 安装NCCL软件包，有两个存储库可用——本地存储库和网络存储库。建议选择更新版本以便在发布新版本时轻松升级。 安装存储库对于本地NCCL存储库：sudo dpkg -i nccl-repo-&lt;version&gt;.deb对于网络存储库：sudo dpkg -i nvidia-machine-learning-repo-&lt;version&gt;.deb 更新APT数据库：sudo apt update 利用APT安装libnccl2。此外，如果您需要使用NCCL编译应用程序，则同时安装 libnccl-dev包。如果您正在使用网络存储库，则使用以下命令。 sudo apt install libnccl2 libnccl-dev如果您希望保留较旧版本的CUDA，请指定特定版本，例如： sudo apt-get install libnccl2=2.0.0-1+cuda8.0 libnccl-dev=2.0.0-1+cuda8.0请参阅下载页面以了解确切的软件包版本。 其他方式 下载tar文件包，将NCCL包解压到您的主目录或/usr/local12cd /usr/localtar xvf nccl-&lt;version&gt;.txz 当编译应用程序时，指定到安装目录路径 NCCL，例如/usr/local/nccl-&lt;版本&gt;/。 参考资料 NCCL Installation Guide :: Deep Learning SDK Documentation","link":"/ubuntu-nccl2.html"},{"title":"Ubuntu 16.04安装配置OpenCV 2.4.9","text":"Ubuntu 16.04安装配置OpenCV 2.4.9 安装环境 Ubuntu 16.04 Intel(R) Core(TM) i7-6800K CPU @ 3.40GHz opencv-2.4.9 安装依赖1234sudo apt-get install build-essentialsudo apt-get install libgtk2.0-dev libavcodec-dev libavformat-dev libtiff4-dev libswscale-dev libjasper-dev # 图片视频支持sudo apt-get install cmake # 安装cmakesudo apt-get install pkg-config # 提供从源代码中编译软件时查询已安装的库时使用的统一接口 下载安装包 下载opencv2.4.9安装包至你的路径123456unzip opencv-2.4.9.zipcd opencv-2.4.9mkdir releasecd release# 下面这行cmake参数网上有多种选择，此处选择不包含CUDA和EIGEN，避免后续编译出错。默认安装至/usr/local目录下cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D WITH_CUDA=OFF -D WITH_OPENMP=ON -D WITH_QT=ON -D WITH_EIGEN=OFF .. 编译12sudo make -j4sudo make install 配置12345# 默认至目录：/usr/local/lib，可自定义安装目录，加参数--prefix=&quot;/usr/local/openmpi&quot;sudo vi /etc/ld.so.conf.d/opencv.conf# 添加一行/usr/local/libsudo ldconfig -v 测试123cd opencv-2.4.9/samples/c./build_all.sh./find_obj 参考链接 Ubuntu16.04 caffe Opencv2.4.13 GPU环境配置 Opencv 2.4.9在Ubuntu下的配置与安装","link":"/ubuntu-opencv.html"},{"title":"Windows 10安装Cuda9、Cudnn7配置Tensorflow 1.8环境","text":"Windows 10安装Cuda9.0、Cudnn7.0，配置Tensorflow r1.8环境步骤全记录。当前安装时间：2018年5月10日 安装环境 Windows 10 Intel(R) Core(TM) i7-6800K CPU @ 3.40GHz 2 * NVIDIA GTX 1080 Ti Tensorflow r1.8 CUDA 9.0、Cudnn 7.0 Python 3.6 安装CUDA 下载CUDA对应版本：https://developer.nvidia.com/cuda-toolkit-archive，选择**CUDA Toolkit 9.0 (Sept 2017)-&gt;Windows-&gt;x86_64-&gt;10-&gt;exe(local) 下载完成后，打开直接点击next下一步进行安装，安装路径默认为C盘 配置Cuda环境变量 右击“我的电脑”，选择“属性”，点击“高级系统设置” 选择“环境变量”，在“系统变量”框中找到“path”，点击选中，并点击“编辑”按钮 点击“新建”按钮，添加以下路径 C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\bin C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\libnvvp C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\lib\\x64 C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\extras\\CUPTI\\libx64 命令行输入nccv -V检查是否成功 安装Cudnn 进入 https://developer.nvidia.com/rdp/cudnn-archive ，选择对应的7.0版本下载即可。 解压压缩包，把压缩包中bin,include,lib中的文件分别拷贝到C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0目录的对应目录下。 安装TensorFlow-gpu1pip install tensorflow-gpu 参考链接 win10+cuda9.0+cuDNN 7.0+Tensorflow1.5（GPU）安装","link":"/win10-tf.html"},{"title":"Ubuntu 16.04安装OpenMPI","text":"Ubuntu 16.04安装OpenMPI环境 安装环境 Ubuntu 16.04 Intel(R) Core(TM) i7-6800K CPU @ 3.40GHz openmpi-1.8.0 下载安装包1wget http://www.open-mpi.org/software/ompi/v1.8/downloads/openmpi-1.8.0.tar.gz 解压缩12tar zxvf openmpi-1.8.0.tar.gzcd openmpi-1.8.0 配置安装文件12# 默认至目录：/usr/local/lib，可自定义安装目录，加参数--prefix=&quot;/usr/local/openmpi&quot;./configure --prefix=&quot;/usr/local/openmpi&quot; 安装openMPI12sudo makesudo make all install 配置环境变量1234sudo gedit ~/.bashrc# 在.bashrc文件的最后加上下面这行export PATH=/usr/local/openmpi/bin${PATH:+:${PATH}}export LD_LIBRARY_PATH=/usr/local/openmpi/lib${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}} 测试123cd openmpi-1.8.0/examplesmakempirun -np 4 hello_c","link":"/ubuntu-openmpi.html"},{"title":"Windows常见问题及解决技巧","text":"收集整理Windows系统使用过程中遇到的一些问题和解决办法，不定期更新。 Windows8/8.1/10安装.NET Framework 3.5 之前在重装win 10系统后安装Microsoft SQL Server 2012，却提示需要.net framework3.5环境，但是Windows8/8.1/10现在都是默认的4.0，用微软自带的在线安装等了半天进度条根本不动。 方法一： 先挂载Win8&amp;Win8.1&amp;Win10的镜像（安装系统的那个iso镜像文件，可以使用Daemon虚拟光驱挂载，加载之后注意盘符名称，假设为G）; 然后以管理员身份运行命令提示符，输入并回车运行以下命令： Dism /online /enable-feature /featurename:NetFx3 /All /Source:G:\\sources\\sxs /LimitAccess 注意将G:替换成你挂载系统所在的盘符，等待部署进度100%即可。 方法二： 上述方法安装过程中可能会出现错误提示安装失败，可使用cab格式的.NET Framework 3.5离线安装包进行安装。 cab格式.NET Framework 3.5离线安装包下载地址：百度网盘 先把下载的名为NetFx3.cab的离线安装包放到Win10系统盘C:\\Windows文件夹里； 然后以管理员身份运行命令提示符，输入并回车运行以下命令： Dism /online /Enable-Feature /FeatureName:NetFx3 /Source:&quot;%windir%&quot; /LimitAccess 等待部署进度100%即可。 关闭Win 10自动更新 第一种方法适用win10所有版本系统。打开控制面板-&gt;管理工具-&gt;服务-&gt;双击Windows Update，点击停止按钮停止服务，将启动类型改为禁用。打开恢复选项卡，将第一次失败改为无操作 第二种方法适用于除了win10家庭版的其他系统。先按 win键+R 运行gpedit.msc，打开计算机配置–&gt;管理模板–&gt;Windows组件–&gt;Windows更新，点击配置自动更新，选择已禁用后保存 Win 10家庭中文版开启远程桌面 Win 10家庭版默认是不支持远程桌面的，下载安装一个自动化工具，解压后以管理员身份运行install.bat即可。链接地址 按住Shift键右键点击空白处“在此处打开命令提示符”而不是PowerShell窗口 打开注册表编辑器，定位至： \\HKEY_CLASSES_ROOT\\Directory\\Background\\shell\\Powershell\\command 更改注册表项所有者权限，在command项上点击右键，选择权限，点击高级按钮打开“command的高级安全设置”窗口，点击“所有者：TrustedInstaller”右侧的“更改”按钮，打开“选择用户或组”窗口。在“输入要选择的对象名称”框中输入当前用户名，然后点击右侧的“检查名称”按钮。如果输入正确，点击“检查名称”之后就会自动把你输入的对象名称显示为标准的用户名称，并添加下划线（如上图）；反之，如果输入的用户名错误，点击“检查名称”之后就会显示提示。（如果不清楚当前登录系统的用户名，你也可以输入“Everyone”，这个不会有错，但是却会修改所有用户的权限，可能存在安全隐患。）点击“确定”关闭“选择用户或组”窗口，回到“command的高级安全设置”窗口，你会发现“所有者”已经变成了你刚才输入的用户。然后点击“确定”关闭“command的高级安全设置”窗口，回到“command的权限”设置窗口。选中“组或用户名”列表中的“Administrators”，在下面的“Administrators的权限”设置框中勾选“完全控制”。点击“确定”关闭“command的权限”设置窗口，回到注册表编辑器。 在右侧窗口双击默认值打开编辑字符串窗口，把数值数据修改为 cmd.exe /s /k pushd &quot;%V&quot; 如果想要取消修改的话，把默认值的数值数据改回如下值即可： powershell.exe -noexit -command Set-Location -literalPath '%V' Win 10家庭中文版打开组策略 在桌面新建记事本文件，粘贴下列代码，并将文件格式改为bat。123456@echo offpushd &quot;%~dp0&quot;dir /b C:\\Windows\\servicing\\Packages\\Microsoft-Windows-GroupPolicy-ClientExtensions-Package~3*.mum &gt;List.txtdir /b C:\\Windows\\servicing\\Packages\\Microsoft-Windows-GroupPolicy-ClientTools-Package~3*.mum &gt;&gt;List.txtfor /f %%i in ('findstr /i . List.txt 2^&gt;nul') do dism /online /norestart /add-package:&quot;C:\\Windows\\servicing\\Packages\\%%i&quot;pause","link":"/windows-tips.html"},{"title":"行人重识别(Person Re-identification)顶级会议论文汇总","text":"近几年ICCV、CVPR、ECCV等顶级国际会议关于行人重识别(person re-identification)的论文汇总，不定期更新。如有疏漏或不足之处，欢迎指正。 Last Updated: Apr 26, 2019Updated Content: add AAAI 2019、CVPR 2019 索引目录generated with DocToc ICCV ICCV 2017 ICCV 2015 ICCV 2013 CVPR CVPR 2019 CVPR 2018 CVPR 2017 CVPR 2016 CVPR 2015 CVPR 2014 CVPR 2013 ECCV ECCV 2018 ECCV 2016 ECCV 2014 BMVC BMVC 2018 BMVC 2017 BMVC 2016 BMVC 2015 BMVC 2014 ICPR ICPR 2014 AAAI AAAI 2019 AAAI 2018 AAAI 2017 AAAI 2016 AAAI 2015 NIPS 2016 NIPS 2018 IJCAI IJCAI 2018 IJCAI 2017 IJCAI 2016 IJCAI 2015 ICCVICCV 2017 Unlabeled Samples Generated by GAN Improve the Person Re-Identification Baseline in Vitro. Zhedong Zheng, Liang Zheng, Yi Yang SVDNet for Pedestrian Retrieval. Yifan Sun, Liang Zheng, Weijian Deng, Shengjin Wang HydraPlus-Net: Attentive Deep Features for Pedestrian Analysis. Xihui Liu, Haiyu Zhao, Maoqing Tian, Lu Sheng, Jing Shao, Shuai Yi, Junjie Yan, Xiaogang Wang Neural Person Search Machines. Hao Liu, Jiashi Feng, Zequn Jie, Karlekar Jayashree, Bo Zhao, Meibin Qi, Jianguo Jiang, Shuicheng Yan SHaPE: A Novel Graph Theoretic Algorithm for Making Consensus-Based Decisions in Person Re-Identification Systems. Arko Barman, Shishir K. Shah Cross-View Asymmetric Metric Learning for Unsupervised Person Re-Identification. Hong-Xing Yu, Ancong Wu, Wei-Shi Zheng Spatio-Temporal Person Retrieval via Natural Language Queries. Masataka Yamaguchi, Kuniaki Saito, Yoshitaka Ushiku, Tatsuya Harada A Two Stream Siamese Convolutional Neural Network for Person Re-Identification. Dahjung Chung, Khalid Tahboub, Edward J. Delp Learning View-Invariant Features for Person Identification in Temporally Synchronized Videos Taken by Wearable Cameras. Kang Zheng, Xiaochuan Fan, Yuewei Lin, Hao Guo, Hongkai Yu, Dazhou Guo, Song Wang Efficient Online Local Metric Adaptation via Negative Samples for Person Re-Identification. Jiahuan Zhou, Pei Yu, Wei Tang, Ying Wu Stepwise Metric Promotion for Unsupervised Video Person Re-Identification. Zimo Liu, Dong Wang, Huchuan Lu RMPE: Regional Multi-Person Pose Estimation. Hao-Shu Fang, Shuqin Xie, Yu-Wing Tai, Cewu Lu Deeply-Learned Part-Aligned Representations for Person Re-Identification. Liming Zhao, Xi Li, Yueting Zhuang, Jingdong Wang Pose-Driven Deep Convolutional Model for Person Re-Identification. Chi Su, Jianing Li, Shiliang Zhang, Junliang Xing, Wen Gao, Qi Tian Dynamic Label Graph Matching for Unsupervised Video Re-Identification. Mang Ye, Andy J. Ma, Liang Zheng, Jiawei Li, Pong C. Yuen Jointly Attentive Spatial-Temporal Pooling Networks for Video-Based Person Re-Identification. Shuangjie Xu, Yu Cheng, Kang Gu, Yang Yang, Shiyu Chang, Pan Zhou RGB-Infrared Cross-Modality Person Re-Identification. Ancong Wu, Wei-Shi Zheng, Hong-Xing Yu, Shaogang Gong, Jianhuang Lai Multi-Scale Deep Learning Architectures for Person Re-Identification. Xuelin Qian, Yanwei Fu, Yu-Gang Jiang, Tao Xiang, Xiangyang Xue ICCV 2015 Partial Person Re-Identification. Wei-Shi Zheng, Xiang Li, Tao Xiang, Shengcai Liao, Jianhuang Lai, Shaogang Gong Scalable Person Re-Identification: A Benchmark. Liang Zheng, Liyue Shen, Lu Tian, Shengjin Wang, Jingdong Wang, Qi Tian Person Re-Identification Ranking Optimisation by Discriminant Context Information Analysis. Jorge GarcÃ­a, Niki Martinel, Christian Micheloni, Alfredo Gardel Person Re-Identification With Correspondence Structure Learning. Yang Shen, Weiyao Lin, Junchi Yan, Mingliang Xu, Jianxin Wu, Jingdong Wang Efficient PSD Constrained Asymmetric Metric Learning for Person Re-Identification. Shengcai Liao, Stan Z. Li Multi-Task Learning With Low Rank Attribute Embedding for Person Re-Identification. Chi Su, Fan Yang, Shiliang Zhang, Qi Tian, Larry S. Davis, Wen Gao Multi-Scale Learning for Low-Resolution Person Re-Identification. Xiang Li, Wei-Shi Zheng, Xiaojuan Wang, Tao Xiang, Shaogang Gong Person Re-Identification With Discriminatively Trained Viewpoint Invariant Dictionaries. Srikrishna Karanam, Yang Li, Richard J. Radke ICCV 2013 POP: Person re-identification post-rank optimisation. S. G. C. Liu, C. C. Loy, G. Wang Person re-identification by salience matching. R. Zhao, W. Ouyang, X. Wang Domain Transfer Support Vector Ranking for Person Re-Identification without Target Camera Label Information. Andy Jinhua Ma, Pong Chi Yuen, Jiawei Li Human Re-identification by Matching Compositional Template with Cluster Sampling. Yuanlu Xu, Liang Lin, Weishi Zheng, Xiaobai Liu CVPRCVPR 2019 Perceive Where to Focus: Learning Visibility-aware Part-level Features for Partial Person Re-identification. Yifan Sun, Qin Xu, Yali Li, Chi Zhang, Yikang Li, Shengjin Wang, Jian Sun CityFlow: A City-Scale Benchmark for Multi-Target Multi-Camera Vehicle Tracking and Re-Identification. Zheng Tang, Milind Naphade, Ming-Yu Liu, Xiaodong Yang, Stan Birchfield, Shuo Wang, Ratnesh Kumar, David Anastasiu, Jenq-Neng Hwang Dissecting Person Re-identification from the Viewpoint of Viewpoint. Xiaoxiao Sun, Liang Zheng Weakly Supervised Person Re-Identification. Jingke Meng, Sheng Wu, Wei-Shi Zheng Unsupervised Person Re-identification by Soft Multilabel Learning. Hong-Xing Yu, Wei-Shi Zheng, Ancong Wu, Xiaowei Guo, Shaogang Gong, Jian-Huang Lai Learning Context Graph for Person Search. Yichao Yan, Qiang Zhang, Bingbing Ni, Wendong Zhang, Minghao Xu, Xiaokang Yang Joint Discriminative and Generative Learning for Person Re-identification. Zhedong Zheng, Xiaodong Yang, Zhiding Yu, Liang Zheng, Yi Yang, Jan Kautz Invariance Matters: Exemplar Memory for Domain Adaptive Person Re-identification. Zhun Zhong, Liang Zheng, Zhiming Luo, Shaozi Li, Yi Yang CVPR 2018 Group Consistent Similarity Learning via Deep CRFs for Person Re-Identification. Dapeng Chen, Dan Xu, Hongsheng Li, Nicu Sebe, Xiaogang Wang Person Transfer GAN to Bridge Domain Gap for Person Re-Identification. Longhui Wei, Shiliang Zhang, Wen Gao, Qi Tian Disentangled Person Image Generation. Liqian Ma, Qianru Sun, Stamatios Georgoulis, Mario Fritz, Bernt Schiele, Luc Van Gool Unsupervised Person Image Synthesis in Arbitrary Poses. Albert Pumarola, Antonio Agudo, Alberto Sanfeliu, Francesc Moreno-Noguer Good Appearance Features for Multi-Target Multi-Camera Tracking. Ergys Ristani, Carlo Tomasi Diversity Regularized Spatiotemporal Attention for Video-based Person Re-identification. Shuang Li, Slawomir Bak, Peter Carr A Pose-Sensitive Embedding for Person Re-Identification with Expanded Cross Neighborhood Re-Ranking. M. Saquib Sarfraz, Arne Schumann, Andreas Eberle, Rainer Stiefelhagen Image-Image Domain Adaptation with Preserved Self-Similarity and Domain-Dissimilarity for Person Re-identification. Weijian Deng, Liang Zheng, Guoliang Kang, Yi Yang, Qixiang Ye, Jianbin Jiao Human Semantic Parsing for Person Re-identification. Mahdi Kalayeh, Emrah Basaran, Mubarak Shah Video Person Re-identification with Competitive Snippet-similarity Aggregation and Co-attentive Snippet Embedding. Dapeng Chen, Hongsheng Li, Tong Xiao, Shuai Yi, Xiaogang Wang Mask-guided Contrastive Attention Model for Person Re-Identification. Chunfeng Song, Yan Huang, Wanli Ouyang, Liang Wang Person Re-identification with Cascaded Pairwise Convolutions. Yicheng Wang, Zhenzhong Chen, Feng Wu, Gang Wang Multi-Level Factorisation Net for Person Re-Identification. Xiaobin Chang, Timothy Hospedales, Tao Xiang Attention-aware Compositional Network for Person Re-Identification. Jing Xu, Rui Zhao, Feng Zhu, Huaming Wang, Wanli Ouyang Deep Group-shuffling Random Walk for Person Re-identification. Yantao Shen, Hongsheng Li, Tong Xiao, Shuai Yi, Dapeng Chen, Xiaogang Wang Transferable Joint Attribute-Identity Deep Learning for Unsupervised Person Re-Identification. Jingya Wang, Xiatian Zhu, Shaogang Gong, Wei Li Harmonious Attention Network for Person Re-Identification. Wei Li, Xiatian Zhu, Shaogang Gong Efficient and Deep Person Re-Identification using Multi-Level Similarity. Yiluan Guo, Ngai-Man Cheung Pose Transferrable Person Re-Identification. Jinxian Liu, Yichao Yan, Bingbing Ni, Peng Zhou, Shuo Cheng, jianguo Hu Adversarially Occluded Samples for Person Re-identification. Houjing Huang, Dangwei Li, Zhang Zhang, Xiaotang Chen, Kaiqi Huang Camera Style Adaptation for Person Re-identification. Zhun Zhong, Liang Zheng, Zhedong Zheng, Shaozi Li, Yi Yang Exploit the Unknown Gradually: One-Shot Video-Based Person Re-Identification by Stepwise Learning. Yu Wu, Yutian Lin, Xuanyi Dong, Yan Yan, Wanli Ouyang, Yi Yang Dual Attention Matching Network for Context-Aware Feature Sequence based Person Re-Identification. Jianlou Si, Honggang Zhang, Chun-Guang Li, Jason Kuen, Xiangfei Kong, Alex Kot, Gang Wang Easy Identification from Better Constraints: Multi-Shot Person Re-Identification from Reference Constraints. Jiahuan Zhou, Bing Su, Ying Wu Eliminating Background-bias for Robust Person Re-identification. Maoqing Tian, Shuai Yi, Hongsheng Li, Shihua Li, Xuesen Zhang, Jianping Shi, Junjie Yan, Xiaogang Wang End-to-End Deep Kronecker-Product Matching for Person Re-identification. Yantao Shen, Tong Xiao, Hongsheng Li, Shuai Yi, Xiaogang Wang Exploiting Transitivity for Learning Person Re-identification Models on a Budget. Sourya Roy, Sujoy Paul, Neal Young, Amit Roy-Chowdhury Deep Spatial Feature Reconstruction for Partial Person Re-identification. Lingxiao He, Jian Liang, Haiqing Li, Zhenan Sun Unsupervised Cross-dataset Person Re-identification by Transfer Learning of Spatio-temporal Patterns. Jianming Lv, Weihang Chen, Qing Li, Can Yang Resource Aware Person Re-identification across Multiple Resolutions. Yan Wang, Lequn Wang, Yurong You, xu Zou, Vincent Chen, Serena Li, Bharath Hariharan, Gao Huang, Kilian Weinberger Multi-shot Pedestrian Re-identification via Sequential Decision Making. Jianfu Zhang, Naiyan Wang, Liqing Zhang Deep Mutual Learning. Ying Zhang, Tao Xiang, Timothy Hospedales, Huchuan Lu CVPR 2017 Spindle Net: Person Re-Identification With Human Body Region Guided Feature Decomposition and Fusion. Haiyu Zhao, Maoqing Tian, Shuyang Sun, Jing Shao, Junjie Yan, Shuai Yi, Xiaogang Wang, Xiaoou Tang Beyond Triplet Loss: A Deep Quadruplet Network for Person Re-Identification. Weihua Chen, Xiaotang Chen, Jianguo Zhang, Kaiqi Huang Person Re-identification in the Wild. Liang Zheng, Hengheng Zhang, Shaoyan Sun, Manmohan Chandraker, Yi Yang, Qi Tian Scalable Person Re-identification on Supervised Smoothed Manifold. Song Bai, Xiang Bai, Qi Tian Joint Detection and Identification Feature Learning for Person Search. Tong Xiao, Shuang Li, Bochao Wang, Liang Lin, Xiaogang Wang Consistent-Aware Deep Learning for Person Re-identification in a Camera Network. Ji Lin, Liangliang Ren, Jiwen Lu, Jianjiang Feng, Jie Zhou Multiple People Tracking by Lifted Multicut and Person Re-identification. Siyu Tang, Mykhaylo Andriluka, Bjoern Andres, Bernt Schiele Point to Set Similarity Based Deep Feature Learning for Person Re-Identification. Sanping Zhou, Jinjun Wang, Jiayun Wang, Yihong Gong, Nanning Zheng Person Search with Natural Language Description. Shuang Li, Tong Xiao, Hongsheng Li, Bolei Zhou, Dayu Yue, Xiaogang Wang Fast Person Re-identification via Cross-Camera Semantic Binary Transformation. Jiaxin Chen, Yunhong Wang, Jie Qin, Li Liu, Ling Shao See the Forest for the Trees: Joint Spatial and Temporal Recurrent Neural Networks for Video-Based Person Re-identification. Zhen Zhou, Yan Huang, Wei Wang, Liang Wang, Tieniu Tan Learning Deep Context-Aware Features over Body and Latent Parts for Person Re-identification. Dangwei Li, Xiaotang Chen, Zhang Zhang, Kaiqi Huang CVPR 2016 Recurrent Attention Models for Depth-Based Person Identification. Albert Haque, Alexandre Alahi, Li Fei-Fei Learning a Discriminative Null Space for Person Re-identification. Li Zhang, Tao Xiang, Shaogang Gong Learning Deep Feature Representations with Domain Guided Dropout for Person Re-identification. Tong Xiao, Hongsheng Li, Wanli Ouyang, Xiaogang Wang Similarity Learning with Spatial Constraints for Person Re-identification. Dapeng Chen, Zejian Yuan, Badong Chen, Nanning Zheng Sample-Specific SVM Learning for Person Re-identification. Ying Zhang, Baohua Li, Huchuan Lu, Atshushi Irie, Xiang Ruan Joint Learning of Single-Image and Cross-Image Representations for Person Re-identification. Faqiang Wang, Wangmeng Zuo, Liang Lin, David Zhang, Lei Zhang Unsupervised Cross-Dataset Transfer Learning for Person Re-identification. Peixi Peng, Tao Xiang, Yaowei Wang, Massimiliano Pontil, Shaogang Gong, Tiejun Huang, Yonghong Tian Recurrent Convolutional Network for Video-Based Person Re-identification. Niall McLaughlin, Jesús Martínez del Rincón, Paul C. Miller Person Re-identification by Multi-Channel Parts-Based CNN with Improved Triplet Loss Function. De Cheng, Yihong Gong, Sanping Zhou, Jinjun Wang, Nanning Zheng Top-Push Video-Based Person Re-identification. Jinjie You, Ancong Wu, Xiang Li, Wei-Shi Zheng Improving Person Re-identification via Pose-Aware Multi-shot Matching. Yeong-Jun Cho, Kuk-Jin Yoon Hierarchical Gaussian Descriptor for Person Re-identification. Tetsu Matsukawa, Takahiro Okabe, Einoshin Suzuki, Yoichi Sato CVPR 2015 Super-Resolution Person Re-Identification With Semi-Coupled Low-Rank Discriminant Dictionary Learning. Xiao-Yuan Jing, Xiaoke Zhu, Fei Wu, Xinge You, Qinglong Liu, Dong Yue, Ruimin Hu, Baowen Xu Similarity Learning on an Explicit Polynomial Kernel Feature Map for Person Re-Identification. Dapeng Chen, Zejian Yuan, Gang Hua, Nanning Zheng, Jingdong Wang Query-Adaptive Late Fusion for Image Search and Person Re-Identification. Liang Zheng, Shengjin Wang, Lu Tian, Fei He, Ziqiong Liu, Qi Tian Learning to Rank in Person Re-Identification With Metric Ensembles. Sakrapee Paisitkriangkrai, Chunhua Shen, Anton van den Hengel Person Re-Identification by Local Maximal Occurrence Representation and Metric Learning. Shengcai Liao, Yang Hu, Xiangyu Zhu, Stan Z. Li An Improved Deep Learning Architecture for Person Re-Identification. Ejaz Ahmed, Michael Jones, Tim K. Marks.【PDF】 Transferring a Semantic Representation for Person Re-Identification and Search. Zhiyuan Shi, Timothy M. Hospedales, Tao Xiang CVPR 2014 Learning Mid-level Filters for Person Re-identification. Rui Zhao, Wanli Ouyang, Xiaogang Wang.【PDF】 Semi-Supervised Coupled Dictionary Learning for Person Re-identification. Xiao Liu, Mingli Song, Dacheng Tao, Xingchen Zhou , Chun Chen, Jiajun Bu DeepReID: Deep Filter Pairing Neural Network for Person Re-identification. Wei Li, Rui Zhao, Tong Xiao, Xiaogang Wang.【PDF】 CVPR 2013 Unsupervised Salience Learning for Person Re-identification. Rui Zhao, Wanli Ouyang, Xiaogang Wang Locally Aligned Feature Transforms across Views. Wei Li, Xiaogang Wang Learning Locally-Adaptive Decision Functions for Person Verification. Zhen Li, Shiyu Chang, Feng Liang, Thomas S. Huang, Liangliang Cao, John R. Smith. ECCVECCV 2018 Part-Aligned Bilinear Representations for Person Re-identification. ** Mancs: A Multi-task Attentional Network with Curriculum Sampling for Person Re-identification. ** Improving Deep Visual Representation for Person Re-identification by Global and Local Image-language Association. ** Person Search via A Mask-guided Two-stream CNN Model. ** Person Search by Multi-Scale Matching. ** Reinforced Temporal Attention and Split-Rate Transfer for Depth-Based Person Re-Identification. ** Unsupervised Person Re-identification by Deep Learning Tracklet Association ** ECCV 2016 Embedding Deep Metric for Person Re-identification: A Study Against Large Variations. Hailin Shi, Yang Yang, Xiangyu Zhu, Shengcai Liao, Zhen Lei, Wei-Shi Zheng, Stan Li Human Re-identification in Crowd Videos Using Personal, Social and Environmental Constraints. Shayan Modiri Assari, Haroon Idrees, Mubarak Shah Person Re-identification by Unsupervised L1 Graph Learning. Elyor Kodirov, Tao Xiang, Zhenyong Fu, Shaogang Gong Gated Siamese Convolutional Neural Network Architecture for Human Re-Identification. Rahul Rama Varior, Mrinal Haloi, Gang Wang Deep Attributes Driven Person Re-identification. Chi Su, Shiliang Zhang, Junliang Xing, Wen Gao, Qi Tian Human-In-The-Loop Person Re-Identification. Hanxiao Wang, Shaogang Gong, Xiatian Zhu, Tao Xiang Temporal Model Adaptation for Person Re-Identification. Niki Martinel, Abir Das, Christian Micheloni, Amit Roy-Chowdhury Gated Siamese Convolutional Neural Network Architecture for Human Re-Identification. Rahul Rama Varior, Mrinal Haloi, Gang Wang Person Re-Identification via Recurrent Feature Aggregation. Yichao Yan, Bingbing Ni, Zhichao Song, chao Ma, Yan Yan, xiaokang Yang MARS: A Video Benchmark for Large-Scale Person Re-identification. Liang Zheng, Zhi Bie, Yifan Sun, Jingdong Wang, Chi Su, Shengjin Wang, Qi Tian A Siamese Long Short-Term Memory Architecture for Human Re-Identification. Rahul Rama Varior, Bing Shuai, Jiwen Lu, Dong Xu, Gang Wang ECCV 2014 Salient Color Names for Person Re-Identification. Yang Yang, Jimei Yang, Junjie Yan, Shengcai Liao, Dong Yi, Stan Li Person Re-Identification by Video Ranking. Taiqing Wang, Shaogang Gong, Xiatian Zhu, Shengjin Wang Person Re-Identification using Kernel-based Metric Learning Methods. Fei Xiong, Mengran Gou, Octavia Camps, Mario Sznaier ECCV 2014 Workshop on Visual Surveillance and Re-identification A Novel Visual Word Co-occurrence Model for Person Re-identification. Ziming Zhang, Yuting Chen, Venkatesh Saligrama. Saliency Weighted Features for Person Re-identification. Niki Martinel, Christian Micheloni, Gian Luca Foresti. Joint Learning for Attribute-Consistent Person Re-Identification. Sameh Khamis, Cheng-Hao Kuo, Vivek K.Singh, Vinay D.Shet, Larry S.Davis. BMVCBMVC 2018 Multi-task Mid-level Feature Alignment Network for Unsupervised Cross-Dataset Person Re-Identification. ** Deep Association Learning for Unsupervised Video Person Re-identification. ** BMVC 2017 Person Re-Identification by Localizing Discriminative Regions. Tanzila Rahman, Mrigank Rochan, Yang Wang Deep Reinforcement Learning Attention Selection For Person Re-Identification. Xu Lan, HangXiao Wang, Shaogang Gong, Xiatian Zhu Key Person Aided Re-identification in Partially Ordered Pedestrian Set. Chen Chen, Min Cao, Silong Peng Divide and Fuse: A Re-ranking Approach for Person Re-identification. Rui Yu, Zhichao Zhou, Song Bai, Xiang Bai Cross-View GAN Based Vehicle Generation for Re-identification. Yi Zhou, Ling Shao Efficient Video Summarization Using Principal Person Appearance for Video-Based Person Re-Identification. Seongro Yoon, Furqan Khan, Francois Bremond BMVC 2016 Person Re-identification in Appearance Impaired Scenarios. Mengran Gou, Xikang Zhang, Angels Rates-Borras, Sadjad Asghari-Esfeden, Octavia I. Camps, Mario Sznaier Highly Efficient Regression for Scalable Person Re-Identification. Hanxiao Wang, Shaogang Gong, Tao Xiang BMVC 2015 Kernelized View Adaptive Subspace Learning for Person Re-identification. Qin Zhou, Shibao Zheng, Hang Su, Hua Yang, Yu Wang, Shuang Wu Dictionary Learning with Iterative Laplacian Regularisation for Unsupervised Person Re-identification. Elyor Kodirov, Tao Xiang, Shaogang Gong Multi-Shot Human Re-Identification Using Adaptive Fisher Discriminant Analysis. Yang Li, Ziyan Wu, Srikrishna Karanam, Richard J. Radke BMVC 2014 Re-id: Hunting Attributes in the Wild. Ryan Layne, Timothy M. Hospedales, Shaogang Gong Unsupervised Learning of Generative Topic Saliency for Person Re-identification. Hanxiao Wang, Shaogang Gong, Tao Xiang Open-world Person Re-Identification by Multi-Label Assignment Inference. Brais Cancela, Timothy M. Hospedales, Shaogang Gong ICPRICPR 2014 Deep Metric Learning for Person Re-Identification. Dong Yi, Zhen Lei, Shengcai Liao, Stan Z. Li.【PDF】 AAAIAAAI 2019 Horizontal Pyramid Matching for Person Re-identification. Yang Fu, Yunchao Wei, Yuqian Zhou, Honghui Shi, Gao Huang, Xinchao Wang, Zhiqiang Yao, Thomas Huang Spatial-Temporal Person Re-identification. Guangcong Wang, Jianhuang Lai, Peigen Huang, Xiaohua Xie Learning Resolution-Invariant Deep Representations for Person Re-Identification. Yun-Chun Chen, Yu-Jhe Li, Xiaofei Du, Yu-Chiang Frank Wang Learning Incremental Triplet Margin for Person Re-identification. Yingying Zhang, Qiaoyong Zhong, Liang Ma, Di Xie, Shiliang Pu Backbone Can Not be Trained at Once: Rolling Back to Pre-trained Network for Person Re-Identification. Youngmin Ro, Jongwon Choi, Dae Ung Jo, Byeongho Heo, Jongin Lim, Jin Young Choi A Bottom-Up Clustering Approach to Unsupervised Person Re-identification. Yutian Lin, Xuanyi Dong, Liang Zheng, Yan Yan, Yi Yang HSME: Hypersphere Manifold Embedding for Visible Thermal Person Re-identification. Yi Hao, Nannan Wan, Li Jie, Xinbo Gao STA: Spatial-Temporal Attention for Large-Scale Video-based Person Re-Identification. Yang Fu, Xiaoyang Wang, Yunchao Wei, Thomas Huang Multi-scale 3D Convolution Network for Video Based Person Re-Identification. Jianing Li, Shiliang Zhang, Tiejun Huang Spatial and Temporal Mutual Promotion for Video-based Person Re-identification. Yiheng Liu, Zhenxun Yuan, Wengang Zhou, Houqiang Li AAAI 2018 Cross-View Person Identification by Matching Human Poses Estimated with Confidence on Each Body Joint. Guoqiang Liang, Xuguang Lan, Kang Zheng, Song Wang, Nanning Zheng Deep Low-Resolution Person Re-Identification. Jiening Jiao, Wei-Shi Zheng, Ancong Wu, Xiatian Zhu, Shaogang Gong Discriminative Semi-coupled Projective Dictionary Learning for Low-Resolution Person Re-Identification. Kai Li, Zhengming Ding, Sheng Li, Yun Fu Graph Correspondence Transfer for Person Re-identification. Qin Zhou, Heng Fan, Shibao Zheng, Hang Su, Xinzhe Li, Shuang Wu, Haibin Ling Hierarchical Attention Transfer Network for Cross-domain Sentiment Classification. Zheng Li, Ying Wei, Yu Zhang, Qiang Yang Multi-Channel Pyramid Person Matching Network for Person Re-Identification. Chaojie Mao, Yingming Li, zhongfei Zhang, yaqing Zhang, Xi Li Multi-rate Gated Recurrent Convolutional Networks for Video-Based Pedestrian Re-Identification. Zhihui Li, Lina Yao, Feiping Nie, Dingwen Zhang, Min Xu Region-based Quality Estimation Network for Large-scale Person Re-identification. Guanglu Song, Biao Leng, Yu Liu, Congrui Hetang, Shaofan Cai Semi-supervised Bayesian Attribute Learning for Person Re-identification. Wenhe Liu, Ling Chen, Xiaojun Chang, Yi Yang Temporal-Enhanced Convolutional Network for Person Re-identification. Yang Wu, Jie Qiu, Jun Takamatsu, Tsukasa Ogasawara Video-based Person Re-identification via Self Paced Weighting. Wenjun Huang, Chao Liang, Yi Yu, Zheng Wang, Weijian Ruan, Ruimin Hu AAAI 2017 A Multi-Task Deep Network for Person Re-Identification. Weihua Chen, Xiaotang Chen, Jianguo Zhang, Kaiqi Huang Unsupervised Learning of Multi-Level Descriptors for Person Re-Identification. Yang Yang, Longyin Wen, Siwei Lyu, Stan Z. Li Learning Heterogeneous Dictionary Pair with Feature Projection Matrix for Pedestrian Video Retrieval via Single Query Image. Xiaoke Zhu, Xiao-Yuan Jing, Fei Wu, Yunhong Wang, Wangmeng Zuo, Wei-Shi Zheng AAAI 2016 Large Scale Similarity Learning Using Similar Pairs for Person Verification. Yang Yang, Shengcai Liao, Zhen Lei, Stan Z. Li Metric Embedded Discriminative Vocabulary Learning for High-Level Person Representation. Yang Yang, Zhen Lei, Shifeng Zhang, Hailin Shi, Stan Z. Li DARI: Distance metric And Representation Integration for Person Verification. Guangrun Wang, Liang Lin, Shengyong Ding, Ya Li, Qing Wang AAAI 2015 Swiss-System Based Cascade Ranking for Gait-Based Person Re-Identification. Lan Wei, Yonghong Tian, Yaowei Wang, Tiejun Huang NIPS 2016 Deep Neural Networks with Inexact Matching for Person Re-Identification. Arulkumar Subramaniam, Moitreya Chatterjee, Anurag Mittal. NIPS 2018 FD-GAN: Pose-guided Feature Distilling GAN for Robust Person Re-identification. ** IJCAIIJCAI 2018 Cascaded SR-GAN for Scale-Adaptive Low Resolution Person Re-identification. heng Wang, Mang Ye, Fan Yang, Xiang Bai, Shin’ichi Satoh Adversarial Attribute-Image Person Re-identification. Zhou Yin, Wei-Shi Zheng, Ancong Wu, Hong-Xing Yu, Hai Wan, Xiaowei Guo, Feiyue Huang, Jianhuang Lai Learning with Sparse and Biased Feedback for Personal Search. Michael Bendersky, Xuanhui Wang, Marc Najork, Donald Metzler Deep View-Aware Metric Learning for Person Re-Identification. Pu Chen, Xinyi Xu, Cheng Deng Cross-Modality Person Re-Identification with Generative Adversarial Training. Pingyang Dai, Rongrong Ji, Haibin Wang, Qiong Wu, Yuyu Huang SafeNet: Scale-normalization and Anchor-based Feature Extraction Network for Person Re-identification. Kun Yuan, Qian Zhang, Chang Huang, Shiming Xiang, Chunhong Pan Visible Thermal Person Re-Identification via Dual-Constrained Top-Ranking. Mang Ye, Zheng Wang, Xiangyuan Lan, Pong C. Yuen IJCAI 2017 Discriminative Dictionary Learning With Ranking Metric Embedded for Person Re-Identification. De Cheng, Xiaojun Chang, Li Liu, Alexander Hauptmann, Yihong Gong, Nanning Zheng Person Re-Identification by Deep Joint Learning of Multi-Loss Classification. Wei Li, Xiatian Zhu, Shaogang Gong IJCAI 2016 Learning Cross-View Binary Identities for Fast Person Re-Identification. Feng Zheng, Ling Shao Scale-Adaptive Low-Resolution Person Re-Identification via Learning a Discriminating Surface. Zheng Wang, Ruimin Hu, Yi Yu, Junjun Jiang, Chao Liang, Jinqiao Wang Semantics-Aware Deep Correspondence Structure Learning for Robust Person Re-Identification. Yaqing Zhang, Xi Li, Liming Zhao, Zhongfei Zhang Video-Based Person Re-Identification by Simultaneously Learning Intra-Video and Inter-Video Distance Metrics. Xiaoke Zhu, Xiao-Yuan Jing, Fei Wu, Hui Feng IJCAI 2015 Cross-View Projective Dictionary Learning for Person Re-Identification. Sheng Li, Ming Shao, Yun Fu Mirror Representation for Modeling View-Specific Transform in Person Re-Identification. Ying-Cong Chen, Wei-Shi Zheng, Jianhuang Lai","link":"/reid-papers.html"},{"title":"Ubuntu 16.04安装Cuda、Cudnn配置Caffe环境","text":"Ubuntu16.04安装Cuda8.0、Cudnn6.0，配置Caffe环境步骤全记录 安装环境 Ubuntu 16.04 Intel(R) Core(TM) i7-6800K CPU @ 3.40GHz 2 * NVIDIA GTX 1080 Ti 安装依赖包12345sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compilersudo apt-get install --no-install-recommends libboost-all-devsudo apt-get install libopenblas-dev liblapack-dev libatlas-base-devsudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-devsudo apt-get install git cmake build-essential 有一定几率安装失败而导致后续步骤出现问题，要确保以上依赖包都已安装成功，验证方法就是重新运行安装命令如验证git cmake build-essential是否安装成功则再次运行以下命令：sudo apt-get install git cmake build-essential界面提示如下则说明已成功安装依赖包，否则继续安装直到安装成功。1234567891011test@GTX1080Ti:~$ sudo apt-get install git cmake build-essential正在读取软件包列表... 完成正在分析软件包的依赖关系树 正在读取状态信息... 完成 build-essential 已经是最新版 (12.1ubuntu2)。cmake 已经是最新版 (3.5.1-1ubuntu3)。git 已经是最新版 (1:2.7.4-0ubuntu1.1)。下列软件包是自动安装的并且现在不需要了： lib32gcc1 libc6-i386使用'sudo apt autoremove'来卸载它(它们)。升级了 0 个软件包，新安装了 0 个软件包，要卸载 0 个软件包，有 94 个软件包未被升级。 安装Cuda 8.0 进入 https://developer.nvidia.com/cuda-downloads ，依次选择 CUDA 类型然后下载即可。 下载的CUDA安装中包含有 nvidia 显卡驱动，故此步骤 CUDA 的安装包括了 nvidia 显卡驱动的安装，此时注意你是否已经安装过 nvidia 显卡驱动，若无法保证已安装的 nvidia 显卡驱动一定正确，那就卸载掉之前安装的 nvidia 显卡驱动，然后开始安装 CUDA 8.0；若可以保证已安装正确的 nvidia 显卡驱动，则直接开始安装 CUDA 8.0，在安装过程中选择不再安装 nvidia 显卡驱动。 为了方便开始安装过程的路径查找，把下载的 CUDA 安装文件移动到 HOME 路径下，然后通过 Ctrl + Alt + F1 进入文本模式，输入帐号密码登录，通过 Ctrl + Alt + F7 可返回图形化模式，然后运行 CUDA 安装文件进行安装，之前我们已经把 CUDA 安装文件移动至 HOME，直接通过 sh 命令运行安装文件即可： sudo sh cuda_8.0.61_375.26_linux.run --no-opengl-libs 其中 cuda_8.0.61_375.26_linux.run 是我的 CUDA 安装文件名，而你需替换为自己的 CUDA 安装文件名。 执行此命令约1分钟后会出现 0%信息，此时长按回车键让此百分比增长，直到100%，然后按照提示操作即可，先输入 accept ，然后让选择是否安装 nvidia 驱动，这里的选择对应第5步开头，若未安装则输入 “y”，若确保已安装正确驱动则输入“n”。 剩下的选择则都输入“y”确认安装或确认默认路径安装，开始安装，此时若出现安装失败提示则可能为未关闭桌面服务或在已安装 nvidia 驱动的情况下重复再次安装 nvidia 驱动，安装完成后输入reboot命令重启： 配置环境变量重启后登录进入系统，配置 CUDA 环境变量终端输入：sudo gedit ~/.bashrc在该文件最后加入以下两行并保存： export PATH=/usr/local/cuda-8.0/bin${PATH:+:${PATH}} export LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}使该配置生效：source ~/.bashrc 终端输入：sudo gedit /etc/profile文件末尾加入：export PATH=&quot;/usr/local/cuda/bin:$PATH&quot;运行：source /etc/profile，查看是否有误 设置动态链接库终端输入：sudo gedit /etc/ld.so.conf.d/cuda.conf添加：/usr/local/cuda/lib64执行生效：sudo ldconfig 测试Cuda samples123cd /usr/local/cuda/samples/1_Utilities/deviceQuerymakesudo ./deviceQuery 安装Cudnn 6.0 确定已经安装的Cuda版本，以Cuda8.0为例，到官网 https://developer.nvidia.com/rdp/cudnn-download 下载相应的库文件 下载后进行解压 进入include文件夹，执行sudo cp cudnn.h /usr/local/cuda/include/ # 复制头文件 进入lib64文件夹，执行sudo cp lib* /usr/local/cuda/lib64/ # 复制动态链接库 执行123456cd /usr/local/cuda/lib64/sudo rm -rf libcudnn.so libcudnn.so.6 # 删除原有动态文件sudo ln -s libcudnn.so.6.0.21 libcudnn.so.6 # 生成软链接sudo ln -s libcudnn.so.6 libcudnn.so # 生成软链接locate libcudnn.so # 查看安装位置 安装完成后可用 nvcc -V 命令验证是否安装成功 安装caffe从git中clone出源码: git clone https://github.com/BVLC/caffe.git修改Makefile.config： cp Makefile.config.example Makefile.config vi Makefile.config找到#USE_CUDNN := 1,取消注释（设置为GPU模式） 找到 INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib修改为 INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu/hdf5/serial 在 caffe 目录下执行 ： make all -j8编译成功后可运行测试： make runtest -j8 参考链接 Ubuntu16.04 Caffe 安装步骤记录（超详尽） 【深度学习】一、Ubuntu16.04 安装配置Caffe Ubuntu16.04安装Nvidia显卡驱动+Cuda8.0+Cudnn6.0","link":"/ubuntu-cuda.html"},{"title":"CentOS 7安装MongoDB数据库","text":"在CentOS 7服务器上安装MongoDB数据库，并设置开机启动。 下载安装包 打开MongoDB官网下载地址 选择对应的版本和系统环境，获取下载链接，如CentOS 7的下载链接为https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel70-3.4.9.tgz 运行123wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel70-3.4.9.tgztar zxvf mongodb-linux-x86_64-rhel70-3.4.9.tgz # 解压mv mongodb-linux-x86_64-rhel70-3.4.9 /usr/src/mongodb # 移动 创建数据文件路径1234567cd /usr/src/mongodbmkdir dbmkdir logs# 修改权限chmod -R 755 dbchmod -R 755 logschmod -R 755 bin 创建配置文件12345678910cd binvi mongodb.conf# 添加以下内容dbpath=/usr/src/mongodb/db # 数据文件路径logpath=/usr/src/mongodb/logs/mongodb.log # 日志文件路径port=27017 # 端口(默认)fork=true # 开启守护进程logappend=true # 追加日志nohttpinterface=true # 关闭http接口 启动测试12345678910# 启动数据库cd /usr/src/mongodb/bin./mongod -f ./mongodb.conf# 测试./mongo 127.0.0.1# 启动成功MongoDB shell version: 2.4.9connecting to: 127.0.0.1/test 注意： 使用外部工具连接mongodb数据库前，应先开启vps的防火墙27017端口123456# 开启端口 firewall-cmd --zone=public --add-port=27017/tcp --permanent # 查看端口 firewall-cmd --permanent --query-port=27017/tcp # 重启防火墙 firewall-cmd --reload 设置开机自动启动1234567891011121314151617181920212223242526272829# 注册自定义服务cd /lib/systemd/system vi mongodb.service# 添加以下内容***********************************[Unit]Description=mongodbAfter=network.target remote-fs.target nss-lookup.target[Service]Type=forkingExecStart=/usr/src/mongodb/bin/mongod -f /usr/src/mongodb/bin/mongodb.confExecReload=/bin/kill -s HUP $MAINPIDExecStop=/usr/src/mongodb/bin/mongod --shutdown -f /usr/src/mongodb/bin/mongodb.confPrivateTmp=true[Install] WantedBy=multi-user.target***********************************# 修改权限chmod 754 mongodb.service # 服务命令systemctl start mongodb.service # 启动服务 systemctl stop mongodb.service # 关闭服务systemctl enable mongodb.service # 开机启动 添加管理员与用户认证MongoDB数据库的用户权限分为以下四种： userAdminAnyDatabase 拥有分配角色和用户的权限，但没有读写的权限 root 这是超级管理员 readWrite 有读写权限 read 有读权限 1.开启MongoDB数据库，运行/usr/src/mongodb/bin/mongo，use admin进入admin数据库，创建管理员账户12345678db.createUser( { user: &quot;root&quot;, pwd: &quot;pwd&quot;, roles: [ { role: &quot;root&quot;, db: &quot;admin&quot; } ] })db.system.users.find() # 查看所有用户2.修改配置文件mongodb.conf，在最下面加入一行auth = on，重启mongodb，进入admin数据库再运行show dbs发现已经没有权限3.此时需要对数据库进行权限认证，运行db.auth('root', 'pwd')，返回1表示成功4.对于具体的数据库，创建用户与上述步骤相同，角色不同。","link":"/centos7-mongodb.html"},{"title":"NexT主题个性化配置","text":"Hexo博客的NexT主题个性化配置记录 本文中提及的站点配置文件代指位于博客站点根目录下的_config.yml文件，包含对Hexo博客本身的配置，而主题配置文件代指位于主题目录下的_config.yml文件，配置与主题相关的选项。 1.设置网站图标Favicon.ico从网上下载或制作一张(最好是32*32)你喜欢的图标，并将文件名改为favicon.ico，放在/hexo-site/source/文件夹下，修改主题配置文件：1favicon: /favicon.ico 2.fork me on github ribbon打开网页1或网页2选择一个样式，复制样式对应的代码，粘贴到themes/next/layout/_layout.swig文件的&lt;div class=&quot;headband&quot;&gt;&lt;/div&gt;这一行代码下面，并将a标签的href属性改成你的github地址。 3.修改网站字体大小与行高打开\\themes\\next\\source\\css\\ _variables\\base.styl文件12$font-size-base = 14px // 修改字体大小$line-height-base = 2 // 修改行高 4.主页和正文的文章添加阴影效果打开\\themes\\next\\source\\css\\_custom\\custom.styl文件，加入以下代码1234567.post {margin-top: 20px;margin-bottom: 20px;padding: 25px;-webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5);-moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5);} 5.主页文章阅读全文按钮调整打开\\themes\\next\\source\\css\\_custom\\custom.styl文件，加入以下代码1234.post-button { margin-top: 20px; text-align: right;} 6.网站访问量统计打开主题配置文件，找到如下代码，并修改123456789101112131415busuanzi_count: # count values only if the other configs are false enable: true # custom uv span for the whole site site_uv: true site_uv_header: &lt;i class=&quot;fa fa-user&quot;&gt; 访客数&lt;/i&gt; site_uv_footer: # custom pv span for the whole site site_pv: true site_pv_header: &lt;i class=&quot;fa fa-eye&quot;&gt; 总访问量&lt;/i&gt; site_pv_footer: # custom pv span for one page only page_pv: true page_pv_header: &lt;i class=&quot;fa fa-eye&quot;&gt; 热度&lt;/i&gt; page_pv_footer: ℃ 7.打赏字体不闪动修改文件\\themes\\next\\source\\css\\_common\\components\\post\\post-reward.styl，注释以下代码：123456789101112/* #wechat:hover p{ animation: roll 0.1s infinite linear; -webkit-animation: roll 0.1s infinite linear; -moz-animation: roll 0.1s infinite linear; } #alipay:hover p{ animation: roll 0.1s infinite linear; -webkit-animation: roll 0.1s infinite linear; -moz-animation: roll 0.1s infinite linear; } */ 8.自定义鼠标样式打开themes\\next\\source\\css\\_custom\\custom.styl文件，添加如下代码：123456* { cursor: url(&quot;图片地址&quot;),auto!important}:active { cursor: url(&quot;图片地址&quot;),auto!important}注：url中的图片必须为ico文件 9.修改两侧留白的大小打开\\themes\\next\\source\\css\\_variables\\base.styl文件，找到如下代码修改：12345$main-desktop = 1160px //$main-desktop-large = 1200px$content-desktop = 900px //低于1600px的宽度$content-desktop-large = 900px //大于1600px的宽度 10.修改顶部加载条样式打开themes\\next\\source\\css\\_custom\\custom.styl文件，添加如下代码：1234567891011.pace .pace-progress { background: #0d0c0c; /*进度条颜色*/ height: 3px;}.pace .pace-progress-inner { box-shadow: 0 0 10px #0d0c0c, 0 0 5px #0d0c0c; /*阴影颜色*/}.pace .pace-activity { border-top-color: #0d0c0c; /*上边框颜色*/ border-left-color: #0d0c0c; /*左边框颜色*/} 11.h2标题底部横线打开themes\\next\\source\\css\\_custom\\custom.styl文件，添加如下代码：123.posts-expand .post-body h2 { border-bottom: 1px solid #eee;} 12.自定义代码块样式打开themes\\next\\source\\css\\_custom\\custom.styl文件，添加如下代码：1234567891011121314code { color: #ff7600; background: #fbf7f8; margin: 2px;}/*大代码块的自定义样式*/.highlight, pre { margin: 5px 0; padding: 5px; border-radius: 3px;}.highlight, code, pre { border: 1px solid #d6d6d6;} 13.网站侧边栏作者头像旋转打开\\themes\\next\\source\\css\\_common\\components\\sidebar\\sidebar-author.styl，添加以下代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758.site-author-image { display: block; margin: 0 auto; padding: $site-author-image-padding; max-width: $site-author-image-width; height: $site-author-image-height; border: $site-author-image-border-width solid $site-author-image-border-color; /* 头像圆形 */ border-radius: 80px; -webkit-border-radius: 80px; -moz-border-radius: 80px; box-shadow: inset 0 -1px 0 #333sf; /* 设置循环动画 [animation: (play)动画名称 (2s)动画播放时长单位秒或微秒 (ase-out)动画播放的速度曲线为以低速结束(1s)等待1秒然后开始动画 (1)动画播放次数(infinite为循环播放) ] */ /* 鼠标经过头像旋转360度 */ -webkit-transition: -webkit-transform 1.0s ease-out; -moz-transition: -moz-transform 1.0s ease-out; transition: transform 1.0s ease-out;}img:hover { /* 鼠标经过停止头像旋转 -webkit-animation-play-state:paused; animation-play-state:paused;*/ /* 鼠标经过头像旋转360度 */ -webkit-transform: rotateZ(360deg); -moz-transform: rotateZ(360deg); transform: rotateZ(360deg);}/* Z 轴旋转动画 */@-webkit-keyframes play { 0% { -webkit-transform: rotateZ(0deg); } 100% { -webkit-transform: rotateZ(-360deg); }}@-moz-keyframes play { 0% { -moz-transform: rotateZ(0deg); } 100% { -moz-transform: rotateZ(-360deg); }}@keyframes play { 0% { transform: rotateZ(0deg); } 100% { transform: rotateZ(-360deg); }} 14.修改文章中链接文本样式修改文件themes\\next\\source\\css\\_common\\components\\post\\post.styl，在末尾添加如下代码：12345678910.post-body p a { color: #0593d3; border-bottom: none; border-bottom: 1px solid #0593d3; &amp;:hover { color: #fc6423; border-bottom: none; border-bottom: 1px solid #fc6423; }}","link":"/next-config.html"},{"title":"JavaScript学习笔记","text":"JavaScript学习过程中的一些笔记，不定期更新。 JavaScript与Html JavaScript = ECMAScript + DOM(文档对象模型) + BOM(浏览器对象模型) HTML页面中&lt;script&gt;标签type属性默认为text/javascript。 在使用&lt;script&gt;标签嵌入html页面时，只需指定type属性即可。嵌入的js代码中不要包含&lt;/script&gt;字符串，浏览器会认为其是结束标签。 html包含外部js文件时，必需指定src属性，必需有闭合标签&lt;/script&gt;，两个标签之中不能含有js代码（不会被执行）。 现代Web应用程序一般把js引用全部放在body元素中内容的后面，使附录中的步骤2,3滞后。 defer属性会使js外部脚本延迟到整个html页面加载完毕后再执行。 async属性会使js外部脚本会在页面load事件之前执行，但可能会在DOMContentLoaded事件之前或之后执行。 所有&lt;script&gt;元素都会按照在页面中出现的顺序依次解析（不包含defer、async属性）。 附: DOM文档加载的步骤：参考事件DOMContentLoaded和load的区别 解析HTML结构。 加载外部脚本和样式表文件。 解析并执行脚本代码。 DOM树构建完成。//DOMContentLoaded 加载图片等外部文件。 页面加载完毕。//load 文档开始处没有文档类型声明，则浏览器默认开启混杂模式（包含非标准类型）。HTML5页面的标准模式文档类型声明为&lt;!DOCTYPE html&gt;。 &lt;noscript&gt;元素中的内容在浏览器不支持脚本或者脚本被禁用时显示。 js启用严格模式&quot;use strict&quot;(脚本文件的顶部或函数体内容的开头声明)，严格模式的不同如下：1231.八进制Number变量无效2.不允许使用严格模式3.初始化未经声明的变量会导致错误 语法 标识符第一个字符可以为$，采用驼峰大小写格式，第一个字母小写，剩下的每个有意义的单词的首字母大写。 建议使用分号结尾，建议使用{}组织代码块（即使代码块只有一行）。 js变量为松散类型（可以用来保存任何类型-弱类型语言），不建议修改变量所保存值的类型，但是修改有效。 使用var定义的变量成为定义该变量的作用域中的局部变量，不使用var定义则为全局变量（不推荐）。 一条语句定义多个变量123var message = &quot;hi&quot;, found = false, age = 29; js包括五种基本数据类型:Undefined, Null, Boolean, Number, String和一种复杂类型Object（本质是一组无序的键值对组成)。 typeof操作符结果有：undefined, boolean, string, number, object, function，typeof后可不接圆括号，typeof null = object(空的对象引用)。 Undefined类型只有唯一值undefined，如用var进行变量声明但未初始化时该变量的值即为undefined，对未初始化和未声明的变量执行typeof操作都返回undefined。 Null类型只有唯一值null,如果定义的变量用来保存对象，最好将其初始化为null,可与undefined区分开。 undefined == null // true Boolean类型有两个字面值true和false(与True,False两个标识符区分)。对任何数据类型调用Boolean()函数都可返回Boolean值，取决于该数据类型及其对应转化规则 数据类型 转换为true 转换为false Boolean true false String 非空字符串 “”空字符串 Number 非零数值（无穷大） 0和NaN Object 任何对象 null Undefined 无 undefined Null 无 null 浮点数值必须包含一个小数点，小数点前可以没数字（不推荐），但小数点后至少有一个数字。 保存浮点数的内存空间是保存整值的两倍（为节省空间，1.0会自动解析为1）。 浮点数值最高精度是17位小数，0.1 + 0.2 = 0.30000000000000004. Number.MIN_VALUE = 5e-324 Number.MAX_VALUE = 1.7976931348623157e+308，计算结果超出此范围则转换为(+/-)Infinity,Infinity值无法参与计算，ifFinite()可判断某个数值是否在此范围内。 NaN(Not a Number)表示本来要返回数值的操作数未返回数值的情况。 isNaN判断一个值能否被转换为数值，是为false，否为true Number() parseInt() parseFloat()的用法。 双字节字符：单字节指只占一个字，英文字符。双字是占两个字节的，中文字符占两个字节。 ECMAScript中字符串不可变，拼接字符串会先创建两字符串拼接后长度的字符串，然后填充，最后销毁拼接的两个字符串。 null和undefined无toString()方法，toString()可带一个指定输出数值的基数作为参数，如num.toString(2)=1000(num=8)，String()函数可以对null和undefined输出。 Object的每个实例都有如下属性和方法： Constructor：构建函数，var o = Object()的构建函数就是Object() hasOwnProperty(propertyName)：用于检查给定属性是否存在于当前对象实例中，参数必须为字符串。 isPrototypeOf(object)：检查传入的对象是否是另一个对象的原型。 propertyIsEnumerable(propertyName)：检查给定属性是否能用for-in语句进行枚举。 toLocaleString()：返回对象的字符串表示，该字符串与执行环境的地区对应。 toString()：返回对象的字符串表示。 valueOf()：返回对象的字符串、数值或布尔值表示。 有符号整数存储：第31位保存符(0正1负)，正数为二进制，负数为取反加一。 按位非~:操作数的负值减一；按位与&amp;,按位或|,按位异或^ 左移：左移n位，原数值的右侧多出n个空位，会以0填充这些空位，但左移不影响符号位。 有符号右移(&gt;&gt;)：右移n位(除符号位)，原数值的左侧、符号位的右侧多出n个空位，会以符号位的值填充这些空位。 无符号右移(&gt;&gt;&gt;)：将所有位(包括)右移n位，右侧用0填充这些空位。 逻辑与与逻辑或都为短路操作符，即第一个操作数结果决定，就不会对后面操作数求值。 相等(==)——先转换后比较，全等(===)——仅比较不转换。转换原则如下： 有一个操作数为布尔值，将其转换为数值——false转0，true转1 字符串与数值相比较，字符串先转成数值 有一个操作数为对象，另一个不是，则调用对象的valueOf()方法 如果两个操作数都是对象，则比较是不是同一个对象。 null == undefined(√) null === undefined(×) NaN == NaN(×) switch语句在比较值时使用的是全等操作符，因此不会发生类型转换。 函数return语句可不带返回值，此时函数在停止执行后会返回undefined值。 定义两个名字相同的函数，则该名字只属于后定义的函数(无重载)。通过检查传入函数中参数(arguments对象)的类型和数量并作出不同的反应，可模仿函数的重载。 基本类型变量复制，会在变量对象上创建一个新值，然后把该值复制到为新变量分配的位置上，复制后这两个变量参与的操作互不影响。 引用类型变量复制，将存储在变量对象中的值复制一份放到为新变量分配的空间，此值为一个指针，指向存储在堆中的一个对象，复制后两个变量实际上引用同一个对象。 ECMAScript中所有函数的参数都是按值传递的，可以把函数的参数看作局部变量。 确定一个值是哪种基本类型使用typeof操作符，是哪种引用类型使用instanceof操作符。所有引用类型的值都是Object的实例。 内部环境可以通过作用域链访问所有的外部环境，但外部环境不能访问内部环境中的任何变量和函数。如果内部环境中存在着同名标识符，就不会使用位于外部环境的标识符。 不存在块级作用域，如由for循环创建的变量i即使在for循环执行结束后，也会存在于循环外部的执行环境中。 ‘标记清除’是目前主流的垃圾收集算法，给当前不使用的值加上标记，然后回收其内存。 ES6 函数的Rest参数 123456function sum(...m) { let total = 0; for(var i of m) { total += i; }} 扩展 12345console.log(...[4, 8]); // 4 8[...arr1, ...arr2] // 拼接数组arr1和arr2var [x, ...y] = [4, 8, 10, 30] // y = [8, 10, 30]let [a, b, c] = 'ES6' // a='E' b='S' c='6'let d = [...'ES6'] // d = ['E', 'S', '6'] Promise 1234567891011121314151617181920212223242526272829303132333435363738let checkLogin = function() { /* 固定写法 */ return new Promise(function (resolve, reject) { let flag = true; if(flag) { resolve({ status: 0, result: true }) }else { reject(&quot;error&quot;); } });};let getUserInfo = ()=&gt; { return new Promise((resolve, reject) =&gt; { let userInfo = { userId: '101' }; resolve(userInfo); });};checkLogin().then((res) =&gt; { if(res.status == 0) { console.log(&quot;login success&quot;); return getUserInfo(); }}).catch((err) =&gt; { console.log(`errors:${ err }`);}).then((res2) =&gt; { console.log(`userId:${ res2.userId }`);});/* 同时调用多个接口 */Promise.all([checkLogin(), getUserInfo)()]).then(([res1, res2]) =&gt; { console.log(`res1:${ res1.result}, res2:${ res2.userId }`);}); import与export1234567/* util.js */export let sum = (x, y)=&gt;{ return x + y;};import { sum } from './util' // sum()直接调用import * as util from './util' // util.sum()调用","link":"/javascript-note.html"},{"title":"VPS配置Git Hooks实现hexo博客更新","text":"客户端使用Hexo生成静态文件，通过Git推送到VPS的Git仓库。VPS配置Git Hooks,将静态文件同步到站点目录，实现hexo博客更新。 本机准备工作 安装Hexo环境 安装Git 生成ssh秘钥 VPS配置工作VPS以CentOS 7为例，使用Xshell5连接到VPS，登录root账户。 安装Git123git --version # 查看系统是否安装gityum install git # 安装gityum remove git # 卸载git 新建用户123adduser gitchmod 740 /etc/sudoersvi /etc/sudoers 在vi编辑器中找到如下行 12## Allow root to run any commands anywhereroot ALL=(ALL) ALL 在下面新增一行 1git ALL=(ALL) ALL 保存后退出(linux命令 :wq)，执行 1chmod 440 /etc/sudoers 新建git仓库12345678su gitcd ~mkdir .ssh &amp;&amp; cd .sshtouch authorized_keysvi authorized_keys # 粘贴进本地机器的ssh公钥（一般在C:\\Users\\用户名\\.ssh\\id_rsa.pub文件中）cd ~mkdir hexo.git &amp;&amp; cd hexo.gitgit init --bare # 初始化git仓库 ssh连接测试在git bash命令行中输入ssh git@VPS的IP地址，如果能登录远程主机，则表示Git配置成功 ssh可同时支持publickey和password两种授权方式，publickey默认不开启，开启配置为yes。如果客户端不存在.ssh/id_rsa，则使用password授权。存在则使用publickey授权；如果publickey授权失败，依然会继续使用password授权。 赋予git用户对网站目录的权限123cd /var/www/html # apache服务器的网站根目录mkdir blog # 新建blog文件夹用以放置hexo博客文件chown git:git -R /var/www/html/blog # 将目录所有者改为git用户 配置Git Hooks1234su gitcd /home/git/hexo.git/hookstouch post-receive # 新建脚本文件vi post-receive 在vi编辑中输入以下代码后保存退出 123456789#!/bin/bash GIT_REPO=/home/git/hexo.git # git仓库 TMP_GIT_CLONE=/tmp/hexo PUBLIC_WWW=/var/www/html/blog # 网站目录 rm -rf ${TMP_GIT_CLONE} git clone $GIT_REPO $TMP_GIT_CLONE rm -rf ${PUBLIC_WWW}/* cp -rf ${TMP_GIT_CLONE}/* ${PUBLIC_WWW} chmod +x post-receive # 赋予脚本的执行权限 本机配置工作进入本地hexo博客文件夹，打开站点配置文件_config.yml,修改deploy选项 1234567deploy: type: git repo: github: git@github.com:ChangingFond/ChangingFond.github.io.git #同步到GitHub vps: git@vps的ip:hexo.git仓库地址,master #同步到自己的VPS branch: master message: Hexo Blog updated - {{ now('YYYY-MM-DD HH:mm:ss') }}) 按住shift右击，选择在此处打开命令窗口，运行hexo g -d,如果一切正常，静态文件已经被成功的push到了blog的仓库里。至此，我们完成了通过git将hexo博客部署到VPS上的功能。 参考资料感谢以下作者的文章对笔者的帮助 在VPS上搭建hexo博客，利用git更新 VPS(CentOS)搭建Hexo博客与Git Hooks更新 开始新的折腾，Hexo博客Git-VPS部署完整记录 常见问题 ssh使用公钥授权免密登录不通过Permission denied(publickey,gssapi-keyex,gssapi-with-mic) 尝试以下步骤： 1.运行vi /etc/ssh/sshd_config，找到以下代码，按如下格式修改 1234RSAAuthentication yesPubkeyAuthentication yesStrictModes noAuthorizedKeysFile .ssh/authorized_keys 保存后退出，重启sshd服务 123456# sshd服务相关命令systemctl restart sshd.servicesystemctl status sshd.service # 查看ssh服务的状态systemctl start sshd.service # 开启ssh服务sytemctl enable sshd.service # ssh服务随开机启动，反之disabledsystemctl stop sshd.ervice # 停止ssh服务 2.修改文件夹以及文件权限 12chmod 700 /home/git/.sshchmod 644 /home/git/.ssh/authorized_keys 3.关闭SELinux 1234setenforce 0 # 暂时关闭，重启后恢复vi /etc/selinux/config # 永久关闭SELINUX=disabled","link":"/hexo-git-vps.html"},{"title":"CentOS 7安装锐速高速上网","text":"锐速serverspeeder是一款TCP网络加速软件，能在Linux系统和Windows系统的服务器中安装，安装后能启到提高网络连接稳定性、带宽利用率、低访问失败率等作用，从而提高服务器网络访问速度。锐速并非实际增大服务器带宽，只是提高网络的稳定性和利用率而已。 安装之前锐速破解版linux一键自动安装包是由@91yun发布的，无限带宽版。锐速只支持在XEN和KVM虚拟技术价格的VPS中安装，不支持在OpenVZ虚拟技术架构的VPS安装，推荐在KVM VPS中安装。目前此一键安装包已支持在CentOS，ubuntu和debian系统中安装，而且能自动匹配服务器内核是否支持安装，如果支持就会全自动下载安装，无需任何操作；如果内核不支持，则必须更换合适的VPS内核才能完成安装。 内核支持 CentOS-6.8：2.6.32-642.el7.x86_64 CentOS-7.2：3.10.0-327.el7.x86_64 CentOS：4.4.0-x86_64-linode63 Ubuntu_14.04：4.2.0-35-generic Debian_8：3.16.0-4-amd64 安装脚本root账户登录，执行12wget -N --no-check-certificate https://github.com/91yun/serverspeeder/raw/master/serverspeeder.shbash serverspeeder.sh 卸载脚本root账户登录，执行1chattr -i /serverspeeder/etc/apx* &amp;&amp; /serverspeeder/bin/serverSpeeder.sh uninstall -f CentOS 7更换内核CentOS 7支持安装锐速的内核：3.10.0-327.el7.x86_64root账户登录，执行以下命令 12rpm -ivh http://soft.91yun.org/ISO/Linux/CentOS/kernel/kernel-3.10.0-229.1.2.el7.x86_64.rpm --forcerpm -qa | grep kernel # 查看内核是否安装成功 相关命令12345678service serverSpeeder start # 启动service serverSpeeder stop # 停止service serverSpeeder reload # 重新加载配置service serverSpeeder restart # 重启service serverSpeeder status # 状态service serverSpeeder stats # 统计service serverSpeeder renewLic # 更新许可文件service serverSpeeder update # 更新 参考资料 如何修改CentOS6、CentOS7内核支持安装锐速的内核 锐速ServerSpeeder无限带宽破解版一键安装包","link":"/server-speeder.html"},{"title":"CentOS 7安装Shadowsocks实现科学上网","text":"手动搭梯子，跨越GFW。 搭建环境 CentOS 7 Python环境 Python包管理工具pip 安装脚本使用Xshell5连接到VPS，登录root账户，执行以下命令123wget --no-check-certificate https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks.shchmod +x shadowsocks.sh./shadowsocks.sh 2&gt;&amp;1 | tee shadowsocks.log 安装完成后，提示如下（安装脚本已设置开启自动启动）12345678910Congratulations, shadowsocks install completed!Your Server IP:your_server_ipYour Server Port:8989Your Password:your_passwordYour Local IP:127.0.0.1Your Local Port:1080Your Encryption Method:aes-256-cfbWelcome to visit:http://teddysun.com/342.htmlEnjoy it! 卸载脚本root账户登录，执行1./shadowsocks.sh uninstall 配置文件配置文件路径/etc/shadowsocks.json 单用户配置12345678910{ &quot;server&quot;:&quot;your_server_ip&quot;, &quot;server_port&quot;:8989, &quot;local_address&quot;:&quot;127.0.0.1&quot;, &quot;local_port&quot;:1080, &quot;password&quot;:&quot;yourpassword&quot;, &quot;timeout&quot;:300, &quot;method&quot;:&quot;aes-256-cfb&quot;, &quot;fast_open&quot;: false} 多用户配置123456789101112131415{ &quot;server&quot;:&quot;your_server_ip&quot;, &quot;local_address&quot;: &quot;127.0.0.1&quot;, &quot;local_port&quot;:1080, &quot;port_password&quot;:{ &quot;8989&quot;:&quot;password0&quot;, &quot;9001&quot;:&quot;password1&quot;, &quot;9002&quot;:&quot;password2&quot;, &quot;9003&quot;:&quot;password3&quot;, &quot;9004&quot;:&quot;password4&quot; }, &quot;timeout&quot;:300, &quot;method&quot;:&quot;aes-256-cfb&quot;, &quot;fast_open&quot;: false} 相关命令1234/etc/init.d/shadowsocks start # 启动/etc/init.d/shadowsocks stop # 停止/etc/init.d/shadowsocks restart # 重启/etc/init.d/shadowsocks status # 状态 客户端连接 windows客户端 Shadowsocks-Win 密码：m7bh 下载后解压，运行，填入配置信息，可查看配置文件/etc/shadowsocks.json 谷歌(360)浏览器 + Proxy SwitchyOmega1.安装好SwitchyOmega后，在选项-左侧情景模式点击新建情景模式2.选择代理服务器，填写名称（例如Vultr），按下图填写配置后保存3.再新建情景模式，选择自动切换模式，填写情景模式名称，导入在线列表规则-添加规则列表；4.规则列表规则选择第二步配置好的SS，规则列表格式选择AutoProxy；5.规则列表网址，填https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt 参考资料 Shadowsocks Python版一键安装脚本","link":"/centos-ss.html"},{"title":"Hexo多机同步方案","text":"Hexo博客的本质是将Markdown格式的文章转化成html页面发布到托管容器中，如何将博客的源代码同步到不同机器，实现多机同布博客显得尤为重要。 具体步骤 在github上创建远程Git仓库，命名为ChangingFond.github.io； 为此仓库创建两个分支，master与hexo； hexo分支用以存放博客源代码，master用以存放生成的静态博客文件（反之亦可）； 克隆ChangingFond.github.io仓库的hexo分支，并将博客源代码文件push； 修改站点配置文件_config.yml中的deploy参数12345deploy: type: git repo: # 将生成的博客静态文件同步到master分支 github: git@github.com:ChangingFond/ChangingFond.github.io.git,master 使用方法 在本地修改博客的源代码（如样式）或发布新博文后 1.依次执行git add . git commit -m “…” git push origin hexo指令将改动推送到GitHub的hexo分支； 2.执行hexo g -d命令将网站发布到github的master分支或VPS上； 当更换机器或者重装电脑（无博客源代码） 1.使用git clone -b hexo git@github.com:ChangingFond/ChangingFond.github.io.git拷贝仓库 2.在本地新拷贝的ChangingFond.github.io.git文件夹下通过git bash执行npm install指令（无需执行hexo init） 若使用hexo init，则站点的配置文件_config.yml里面内容会被清空使用默认值 3.在多台电脑上同时写作，只需要在写作之前进行git pull，写作之后进行git push hexo g -d 参考资料 Hexo使用体验-多机同步发布解决方案 GitHub Pages + Hexo搭建博客","link":"/hexo-multi-snyc.html"},{"title":"获取指定路径下的文件类型及数量","text":"C#实现指定路径，扫描该路径下所有文件，统计文件类型及其对应数量 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455using System;using System.Collections.Generic;using System.IO;namespace FileExtensionScan{ class Program { Dictionary&lt;String, int&gt; pList = new Dictionary&lt;String, int&gt;(); //字典形式{后缀：数量} int fileNum = 0; public void GetFileNum(string srcPath) { try { // 得到源目录的文件列表，该里面是包含文件以及目录路径的一个数组 string[] fileList = System.IO.Directory.GetFileSystemEntries(srcPath); // 遍历所有的文件和目录 foreach (string file in fileList) { // 先当作目录处理如果存在这个目录就重新调用GetFileNum(string srcPath) if (Directory.Exists(file)) GetFileNum(file); else { fileNum++; string ext = Path.GetExtension(file).ToLower(); if (pList.ContainsKey(ext) == false) pList.Add(ext, 1); else pList[ext]++; } } } catch (Exception e) { Console.WriteLine(e.ToString()); } } static void Main(string[] args) { Program p = new Program(); p.GetFileNum(args[0]); //获取目录路径，第一个命令行参数 Console.WriteLine(&quot;扫描文件数目&quot; + p.fileNum); //扫描文件总数 foreach (var dic in p.pList) { Console.WriteLine(&quot;{0} {1}&quot;, dic.Key, dic.Value); } } }}","link":"/file-extension-scan.html"},{"title":"CSS解决表格单元格内容过多的问题","text":"最近在实验室开发前端页面，从PHP后端传递数据渲染视图中的一个表格时，发现表格中某些单元格数据内容过多影响了页面美观，想让多余的内容用省略号代替。 CSS样式123456789table { table-layout: fixed;}td { white-space: nowrap; overflow: hidden; text-overflow: ellipsis;} 代码解释table-layout: fixed 由于table-layout的默认值是auto，即table的宽高将取决于其内容的多寡，如果内容的体积无法估测，那么最终表格的呈现形式也无法保证了，fixed一下就好了。（注意：此样式为关键） white-space: nowrap 为了保证无论单元格（TD）中文本内容有多少，都不会自动换行，此时多余的内容会在水平方向撑破单元格。 overflow: hidden 隐藏超出单元格的部分。 text-overflow: ellipsis 将被隐藏的那部分用省略号代替。","link":"/css-html5-table.html"},{"title":"PHP5.3+配置连接SQL Sever","text":"php5.2.x自带php_mssql.dll的扩展连接SQL Server，但这个扩展只能支持SQL Server 2000以下版本。 php连接方式1mssql_connect('localhost', '用户名', '密码'); php5.3.x不再支持php_mssql.dll扩展库 PHP5.3+配置SQL Sever详细配置方式可见 https://github.com/Microsoft/msphpsql 下载Microsoft Drivers for PHP for SQL Server进入https://www.microsoft.com/en-us/download/details.aspx?id=20098点击download,本人安装的是php环境是5.6.21，选择SQLSRV32.EXE下载 Version 4.0 supports PHP 7.0+ Version 3.2 supports PHP 5.6, 5.5, and 5.4 Version 3.1 supports PHP 5.5 and 5.4 Version 3.0 supports PHP 5.4. 配置Microsoft Drivers for PHP for SQL Server下载的文件是一个自解压的 EXE文件，将其解压，解压后会新增以下文件 其中54、55、56表示php的5.4.x、5.5.x 和5.6.x版本； vc6或vc9的选择要看你使用的web服务器软件，如果使用的是IIS那就选择vc9，如果是Apache 则选择vc6； ts和nts的选择要看你安装的php版本是线程安全版的还是非线程安全版，ts是线程安全，nts是非线程安全。 选择你对应的扩展拷贝到拷到php/ext目录下，在php.ini文件，添加以下代码：12extension=php_pdo_sqlsrv_56_ts.dll（用于pdo）extension=php_sqlsrv_56_ts.dll 验证连接 重启服务器，打开phpinfo();看到Registered PHP Streams一栏出现sqlsrv就证明添加扩展成功 php连接测试123456789101112&lt;?php $serverName = &quot;(local)&quot;; $connectionInfo = array(&quot;UID&quot;=&gt;&quot;sa&quot;,&quot;PWD&quot;=&gt;&quot;admin&quot;,&quot;Database&quot;=&gt;&quot;test&quot;); $conn = sqlsrv_connect($serverName, $connectionInfo); if( $conn ){ echo &quot;Connection established.\\n&quot;; }else{ echo &quot;Connection could not be established.\\n&quot;; die(var_dump(sqlsrv_errors())); } sqlsrv_close($conn);?&gt; yii2连接方式123456$db = new Connection([ 'dsn' =＞ 'sqlsrv:Server=youripaddress;Database=xxx', 'username' =＞ 'yourusername', 'password' =＞ 'yourpassword', 'charset' =＞ 'utf8', ]); 常用函数sqlsrv_connectsqlsrv_closesqlsrv_commitsqlsrv_errorssqlsrv_fetchsqlsrv_fetch_arraysqlsrv_fetch_metadatasqlsrv_num_rowssqlsrv_querysqlsrv_rollbacksqlsrv_rows_affected具体用法可参见php官网 注意事项需安装ODBC Driver 11 or Microsoft ODBC Driver 13 ODBC Driver 11 下载地址 ODBC Driver 13 下载地址 具体安装版本可参见下载页面说明，安装后重启即可。","link":"/php-connect-sqlserver.html"},{"title":"SQL Server导入超大SQL文件的方法","text":"在实验室处理数据时，遇到一张20w记录的表需要恢复，初以为直接在dbms中直接导入sql即可，然而显示内存不够，无法导入。 命令行导入用微软自带的sqlcmd工具，可以导入执行。以SQL Server 2014版本为例： Win+R 键入：cmd 命令，开启命令行工具； 键入： 1cd C:\\Program Files\\Microsoft SQL Server\\100\\Tools\\Binn （具体目录路径跟你安装的SQL位置有关） 键入： 1sqlcmd -S localhost -U username -P 123456 -d dbname -i db.sql 参数说明：-S 服务器地址 -U 用户名 -P 密码 -d 数据库名称 -i 脚本文件路径 建议将数据脚本文件拷到此目录，就只用写文件名，而不用写全路径了。注意参数大小写和空格符号。","link":"/import-big-sql.html"},{"title":"分分钟学会Python3","text":"Python was created by Guido Van Rossum in the early 90s. It is now one of the most popularlanguages in existence. I fell in love with Python for its syntactic clarity. It’s basicallyexecutable pseudocode. Feedback would be highly appreciated! You can reach me at @louiedinh or louiedinh [at] [google’s email service] Note: This article applies to Python 3 specifically. Check out here if you want to learn the old Python 2.7 语言: python3贡献者: - [&quot;Louie Dinh&quot;, &quot;http://pythonpracticeprojects.com&quot;] - [&quot;Steven Basart&quot;, &quot;http://github.com/xksteven&quot;] - [&quot;Andre Polykanine&quot;, &quot;https://github.com/Oire&quot;] - [&quot;Zachary Ferguson&quot;, &quot;http://github.com/zfergus2&quot;] - [&quot;evuez&quot;, &quot;http://github.com/evuez&quot;] filename: learnpython3.py译者: - [&quot;ChangingFond&quot;, &quot;http://blog.fangchengjin.cn&quot;] 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840841842843844845846847848849850851852853854855856857858859860861862# Single line comments start with a number symbol.&quot;&quot;&quot; Multiline strings can be written using three &quot;s, and are often used as comments&quot;&quot;&quot;###################################################### 1. Primitive Datatypes and Operators##################################################### You have numbers3 # =&gt; 3# Math is what you would expect1 + 1 # =&gt; 28 - 1 # =&gt; 710 * 2 # =&gt; 20# Except division which returns floats, real numbers, by default35 / 5 # =&gt; 7.0# Result of integer division truncated down both for positive and negative.5 // 3 # =&gt; 15.0 // 3.0 # =&gt; 1.0 # works on floats too-5 // 3 # =&gt; -2-5.0 // 3.0 # =&gt; -2.0# When you use a float, results are floats3 * 2.0 # =&gt; 6.0# Modulo operation7 % 3 # =&gt; 1# Exponentiation (x**y, x to the yth power)2**4 # =&gt; 16# Enforce precedence with parentheses(1 + 3) * 2 # =&gt; 8# Boolean values are primitives (Note: the capitalization)TrueFalse# negate with notnot True # =&gt; Falsenot False # =&gt; True# Boolean Operators# Note &quot;and&quot; and &quot;or&quot; are case-sensitiveTrue and False # =&gt; FalseFalse or True # =&gt; True# Note using Bool operators with ints0 and 2 # =&gt; 0-5 or 0 # =&gt; -50 == False # =&gt; True2 == True # =&gt; False1 == True # =&gt; True# Equality is ==1 == 1 # =&gt; True2 == 1 # =&gt; False# Inequality is !=1 != 1 # =&gt; False2 != 1 # =&gt; True# More comparisons1 &lt; 10 # =&gt; True1 &gt; 10 # =&gt; False2 &lt;= 2 # =&gt; True2 &gt;= 2 # =&gt; True# Comparisons can be chained!1 &lt; 2 &lt; 3 # =&gt; True2 &lt; 3 &lt; 2 # =&gt; False# (is vs. ==) is checks if two variables refer to the same object, but == checks# if the objects pointed to have the same values.a = [1, 2, 3, 4] # Point a at a new list, [1, 2, 3, 4]b = a # Point b at what a is pointing tob is a # =&gt; True, a and b refer to the same objectb == a # =&gt; True, a's and b's objects are equalb = [1, 2, 3, 4] # Point b at a new list, [1, 2, 3, 4]b is a # =&gt; False, a and b do not refer to the same objectb == a # =&gt; True, a's and b's objects are equal# Strings are created with &quot; or '&quot;This is a string.&quot;'This is also a string.'# Strings can be added too! But try not to do this.&quot;Hello &quot; + &quot;world!&quot; # =&gt; &quot;Hello world!&quot;# Strings can be added without using '+'&quot;Hello &quot; &quot;world!&quot; # =&gt; &quot;Hello world!&quot;# A string can be treated like a list of characters&quot;This is a string&quot;[0] # =&gt; 'T'# You can find the length of a stringlen(&quot;This is a string&quot;) # =&gt; 16# .format can be used to format strings, like this:&quot;{} can be {}&quot;.format(&quot;Strings&quot;, &quot;interpolated&quot;) # =&gt; &quot;Strings can be interpolated&quot;# You can repeat the formatting arguments to save some typing.&quot;{0} be nimble, {0} be quick, {0} jump over the {1}&quot;.format(&quot;Jack&quot;, &quot;candle stick&quot;)# =&gt; &quot;Jack be nimble, Jack be quick, Jack jump over the candle stick&quot;# You can use keywords if you don't want to count.&quot;{name} wants to eat {food}&quot;.format(name=&quot;Bob&quot;, food=&quot;lasagna&quot;) # =&gt; &quot;Bob wants to eat lasagna&quot;# If your Python 3 code also needs to run on Python 2.5 and below, you can also# still use the old style of formatting:&quot;%s can be %s the %s way&quot; % (&quot;Strings&quot;, &quot;interpolated&quot;, &quot;old&quot;) # =&gt; &quot;Strings can be interpolated the old way&quot;# None is an objectNone # =&gt; None# Don't use the equality &quot;==&quot; symbol to compare objects to None# Use &quot;is&quot; instead. This checks for equality of object identity.&quot;etc&quot; is None # =&gt; FalseNone is None # =&gt; True# None, 0, and empty strings/lists/dicts all evaluate to False.# All other values are Truebool(0) # =&gt; Falsebool(&quot;&quot;) # =&gt; Falsebool([]) # =&gt; Falsebool({}) # =&gt; False###################################################### 2. Variables and Collections##################################################### Python has a print functionprint(&quot;I'm Python. Nice to meet you!&quot;) # =&gt; I'm Python. Nice to meet you!# By default the print function also prints out a newline at the end.# Use the optional argument end to change the end character.print(&quot;Hello, World&quot;, end=&quot;!&quot;) # =&gt; Hello, World!# Simple way to get input data from consoleinput_string_var = input(&quot;Enter some data: &quot;) # Returns the data as a string# Note: In earlier versions of Python, input() method was named as raw_input()# No need to declare variables before assigning to them.# Convention is to use lower_case_with_underscoressome_var = 5some_var # =&gt; 5# Accessing a previously unassigned variable is an exception.# See Control Flow to learn more about exception handling.some_unknown_var # Raises a NameError# if can be used as an expression# Equivalent of C's '?:' ternary operator&quot;yahoo!&quot; if 3 &gt; 2 else 2 # =&gt; &quot;yahoo!&quot;# Lists store sequencesli = []# You can start with a prefilled listother_li = [4, 5, 6]# Add stuff to the end of a list with appendli.append(1) # li is now [1]li.append(2) # li is now [1, 2]li.append(4) # li is now [1, 2, 4]li.append(3) # li is now [1, 2, 4, 3]# Remove from the end with popli.pop() # =&gt; 3 and li is now [1, 2, 4]# Let's put it backli.append(3) # li is now [1, 2, 4, 3] again.# Access a list like you would any arrayli[0] # =&gt; 1# Look at the last elementli[-1] # =&gt; 3# Looking out of bounds is an IndexErrorli[4] # Raises an IndexError# You can look at ranges with slice syntax.# (It's a closed/open range for you mathy types.)li[1:3] # =&gt; [2, 4]# Omit the beginningli[2:] # =&gt; [4, 3]# Omit the endli[:3] # =&gt; [1, 2, 4]# Select every second entryli[::2] # =&gt;[1, 4]# Return a reversed copy of the listli[::-1] # =&gt; [3, 4, 2, 1]# Use any combination of these to make advanced slices# li[start:end:step]# Make a one layer deep copy using slicesli2 = li[:] # =&gt; li2 = [1, 2, 4, 3] but (li2 is li) will result in false.# Remove arbitrary elements from a list with &quot;del&quot;del li[2] # li is now [1, 2, 3]# Remove first occurrence of a valueli.remove(2) # li is now [1, 3]li.remove(2) # Raises a ValueError as 2 is not in the list# Insert an element at a specific indexli.insert(1, 2) # li is now [1, 2, 3] again# Get the index of the first item found matching the argumentli.index(2) # =&gt; 1li.index(4) # Raises a ValueError as 4 is not in the list# You can add lists# Note: values for li and for other_li are not modified.li + other_li # =&gt; [1, 2, 3, 4, 5, 6]# Concatenate lists with &quot;extend()&quot;li.extend(other_li) # Now li is [1, 2, 3, 4, 5, 6]# Check for existence in a list with &quot;in&quot;1 in li # =&gt; True# Examine the length with &quot;len()&quot;len(li) # =&gt; 6# Tuples are like lists but are immutable.tup = (1, 2, 3)tup[0] # =&gt; 1tup[0] = 3 # Raises a TypeError# Note that a tuple of length one has to have a comma after the last element but# tuples of other lengths, even zero, do not.type((1)) # =&gt; &lt;class 'int'&gt;type((1,)) # =&gt; &lt;class 'tuple'&gt;type(()) # =&gt; &lt;class 'tuple'&gt;# You can do most of the list operations on tuples toolen(tup) # =&gt; 3tup + (4, 5, 6) # =&gt; (1, 2, 3, 4, 5, 6)tup[:2] # =&gt; (1, 2)2 in tup # =&gt; True# You can unpack tuples (or lists) into variablesa, b, c = (1, 2, 3) # a is now 1, b is now 2 and c is now 3# You can also do extended unpackinga, *b, c = (1, 2, 3, 4) # a is now 1, b is now [2, 3] and c is now 4# Tuples are created by default if you leave out the parenthesesd, e, f = 4, 5, 6# Now look how easy it is to swap two valuese, d = d, e # d is now 5 and e is now 4# Dictionaries store mappingsempty_dict = {}# Here is a prefilled dictionaryfilled_dict = {&quot;one&quot;: 1, &quot;two&quot;: 2, &quot;three&quot;: 3}# Note keys for dictionaries have to be immutable types. This is to ensure that# the key can be converted to a constant hash value for quick look-ups.# Immutable types include ints, floats, strings, tuples.invalid_dict = {[1,2,3]: &quot;123&quot;} # =&gt; Raises a TypeError: unhashable type: 'list'valid_dict = {(1,2,3):[1,2,3]} # Values can be of any type, however.# Look up values with []filled_dict[&quot;one&quot;] # =&gt; 1# Get all keys as an iterable with &quot;keys()&quot;. We need to wrap the call in list()# to turn it into a list. We'll talk about those later. Note - Dictionary key# ordering is not guaranteed. Your results might not match this exactly.list(filled_dict.keys()) # =&gt; [&quot;three&quot;, &quot;two&quot;, &quot;one&quot;]# Get all values as an iterable with &quot;values()&quot;. Once again we need to wrap it# in list() to get it out of the iterable. Note - Same as above regarding key# ordering.list(filled_dict.values()) # =&gt; [3, 2, 1]# Check for existence of keys in a dictionary with &quot;in&quot;&quot;one&quot; in filled_dict # =&gt; True1 in filled_dict # =&gt; False# Looking up a non-existing key is a KeyErrorfilled_dict[&quot;four&quot;] # KeyError# Use &quot;get()&quot; method to avoid the KeyErrorfilled_dict.get(&quot;one&quot;) # =&gt; 1filled_dict.get(&quot;four&quot;) # =&gt; None# The get method supports a default argument when the value is missingfilled_dict.get(&quot;one&quot;, 4) # =&gt; 1filled_dict.get(&quot;four&quot;, 4) # =&gt; 4# &quot;setdefault()&quot; inserts into a dictionary only if the given key isn't presentfilled_dict.setdefault(&quot;five&quot;, 5) # filled_dict[&quot;five&quot;] is set to 5filled_dict.setdefault(&quot;five&quot;, 6) # filled_dict[&quot;five&quot;] is still 5# Adding to a dictionaryfilled_dict.update({&quot;four&quot;:4}) # =&gt; {&quot;one&quot;: 1, &quot;two&quot;: 2, &quot;three&quot;: 3, &quot;four&quot;: 4}#filled_dict[&quot;four&quot;] = 4 #another way to add to dict# Remove keys from a dictionary with deldel filled_dict[&quot;one&quot;] # Removes the key &quot;one&quot; from filled dict# From Python 3.5 you can also use the additional unpacking options{'a': 1, **{'b': 2}} # =&gt; {'a': 1, 'b': 2}{'a': 1, **{'a': 2}} # =&gt; {'a': 2}# Sets store ... well setsempty_set = set()# Initialize a set with a bunch of values. Yeah, it looks a bit like a dict. Sorry.some_set = {1, 1, 2, 2, 3, 4} # some_set is now {1, 2, 3, 4}# Similar to keys of a dictionary, elements of a set have to be immutable.invalid_set = {[1], 1} # =&gt; Raises a TypeError: unhashable type: 'list'valid_set = {(1,), 1}# Can set new variables to a setfilled_set = some_set# Add one more item to the setfilled_set.add(5) # filled_set is now {1, 2, 3, 4, 5}# Do set intersection with &amp;other_set = {3, 4, 5, 6}filled_set &amp; other_set # =&gt; {3, 4, 5}# Do set union with |filled_set | other_set # =&gt; {1, 2, 3, 4, 5, 6}# Do set difference with -{1, 2, 3, 4} - {2, 3, 5} # =&gt; {1, 4}# Do set symmetric difference with ^{1, 2, 3, 4} ^ {2, 3, 5} # =&gt; {1, 4, 5}# Check if set on the left is a superset of set on the right{1, 2} &gt;= {1, 2, 3} # =&gt; False# Check if set on the left is a subset of set on the right{1, 2} &lt;= {1, 2, 3} # =&gt; True# Check for existence in a set with in2 in filled_set # =&gt; True10 in filled_set # =&gt; False###################################################### 3. Control Flow and Iterables##################################################### Let's just make a variablesome_var = 5# Here is an if statement. Indentation is significant in python!# prints &quot;some_var is smaller than 10&quot;if some_var &gt; 10: print(&quot;some_var is totally bigger than 10.&quot;)elif some_var &lt; 10: # This elif clause is optional. print(&quot;some_var is smaller than 10.&quot;)else: # This is optional too. print(&quot;some_var is indeed 10.&quot;)&quot;&quot;&quot;For loops iterate over listsprints: dog is a mammal cat is a mammal mouse is a mammal&quot;&quot;&quot;for animal in [&quot;dog&quot;, &quot;cat&quot;, &quot;mouse&quot;]: # You can use format() to interpolate formatted strings print(&quot;{} is a mammal&quot;.format(animal))&quot;&quot;&quot;&quot;range(number)&quot; returns an iterable of numbersfrom zero to the given numberprints: 0 1 2 3&quot;&quot;&quot;for i in range(4): print(i)&quot;&quot;&quot;&quot;range(lower, upper)&quot; returns an iterable of numbersfrom the lower number to the upper numberprints: 4 5 6 7&quot;&quot;&quot;for i in range(4, 8): print(i)&quot;&quot;&quot;&quot;range(lower, upper, step)&quot; returns an iterable of numbersfrom the lower number to the upper number, while incrementingby step. If step is not indicated, the default value is 1.prints: 4 6&quot;&quot;&quot;for i in range(4, 8, 2): print(i)&quot;&quot;&quot;While loops go until a condition is no longer met.prints: 0 1 2 3&quot;&quot;&quot;x = 0while x &lt; 4: print(x) x += 1 # Shorthand for x = x + 1# Handle exceptions with a try/except blocktry: # Use &quot;raise&quot; to raise an error raise IndexError(&quot;This is an index error&quot;)except IndexError as e: pass # Pass is just a no-op. Usually you would do recovery here.except (TypeError, NameError): pass # Multiple exceptions can be handled together, if required.else: # Optional clause to the try/except block. Must follow all except blocks print(&quot;All good!&quot;) # Runs only if the code in try raises no exceptionsfinally: # Execute under all circumstances print(&quot;We can clean up resources here&quot;)# Instead of try/finally to cleanup resources you can use a with statementwith open(&quot;myfile.txt&quot;) as f: for line in f: print(line)# Python offers a fundamental abstraction called the Iterable.# An iterable is an object that can be treated as a sequence.# The object returned the range function, is an iterable.filled_dict = {&quot;one&quot;: 1, &quot;two&quot;: 2, &quot;three&quot;: 3}our_iterable = filled_dict.keys()print(our_iterable) # =&gt; dict_keys(['one', 'two', 'three']). This is an object that implements our Iterable interface.# We can loop over it.for i in our_iterable: print(i) # Prints one, two, three# However we cannot address elements by index.our_iterable[1] # Raises a TypeError# An iterable is an object that knows how to create an iterator.our_iterator = iter(our_iterable)# Our iterator is an object that can remember the state as we traverse through it.# We get the next object with &quot;next()&quot;.next(our_iterator) # =&gt; &quot;one&quot;# It maintains state as we iterate.next(our_iterator) # =&gt; &quot;two&quot;next(our_iterator) # =&gt; &quot;three&quot;# After the iterator has returned all of its data, it gives you a StopIterator Exceptionnext(our_iterator) # Raises StopIteration# You can grab all the elements of an iterator by calling list() on it.list(filled_dict.keys()) # =&gt; Returns [&quot;one&quot;, &quot;two&quot;, &quot;three&quot;]###################################################### 4. Functions##################################################### Use &quot;def&quot; to create new functionsdef add(x, y): print(&quot;x is {} and y is {}&quot;.format(x, y)) return x + y # Return values with a return statement# Calling functions with parametersadd(5, 6) # =&gt; prints out &quot;x is 5 and y is 6&quot; and returns 11# Another way to call functions is with keyword argumentsadd(y=6, x=5) # Keyword arguments can arrive in any order.# You can define functions that take a variable number of# positional argumentsdef varargs(*args): return argsvarargs(1, 2, 3) # =&gt; (1, 2, 3)# You can define functions that take a variable number of# keyword arguments, as welldef keyword_args(**kwargs): return kwargs# Let's call it to see what happenskeyword_args(big=&quot;foot&quot;, loch=&quot;ness&quot;) # =&gt; {&quot;big&quot;: &quot;foot&quot;, &quot;loch&quot;: &quot;ness&quot;}# You can do both at once, if you likedef all_the_args(*args, **kwargs): print(args) print(kwargs)&quot;&quot;&quot;all_the_args(1, 2, a=3, b=4) prints: (1, 2) {&quot;a&quot;: 3, &quot;b&quot;: 4}&quot;&quot;&quot;# When calling functions, you can do the opposite of args/kwargs!# Use * to expand tuples and use ** to expand kwargs.args = (1, 2, 3, 4)kwargs = {&quot;a&quot;: 3, &quot;b&quot;: 4}all_the_args(*args) # equivalent to foo(1, 2, 3, 4)all_the_args(**kwargs) # equivalent to foo(a=3, b=4)all_the_args(*args, **kwargs) # equivalent to foo(1, 2, 3, 4, a=3, b=4)# Returning multiple values (with tuple assignments)def swap(x, y): return y, x # Return multiple values as a tuple without the parenthesis. # (Note: parenthesis have been excluded but can be included)x = 1y = 2x, y = swap(x, y) # =&gt; x = 2, y = 1# (x, y) = swap(x,y) # Again parenthesis have been excluded but can be included.# Function Scopex = 5def set_x(num): # Local var x not the same as global variable x x = num # =&gt; 43 print (x) # =&gt; 43def set_global_x(num): global x print (x) # =&gt; 5 x = num # global var x is now set to 6 print (x) # =&gt; 6set_x(43)set_global_x(6)# Python has first class functionsdef create_adder(x): def adder(y): return x + y return adderadd_10 = create_adder(10)add_10(3) # =&gt; 13# There are also anonymous functions(lambda x: x &gt; 2)(3) # =&gt; True(lambda x, y: x ** 2 + y ** 2)(2, 1) # =&gt; 5# There are built-in higher order functionslist(map(add_10, [1, 2, 3])) # =&gt; [11, 12, 13]list(map(max, [1, 2, 3], [4, 2, 1])) # =&gt; [4, 2, 3]list(filter(lambda x: x &gt; 5, [3, 4, 5, 6, 7])) # =&gt; [6, 7]# We can use list comprehensions for nice maps and filters# List comprehension stores the output as a list which can itself be a nested list[add_10(i) for i in [1, 2, 3]] # =&gt; [11, 12, 13][x for x in [3, 4, 5, 6, 7] if x &gt; 5] # =&gt; [6, 7]# You can construct set and dict comprehensions as well.{x for x in 'abcddeef' if x not in 'abc'} # =&gt; {'d', 'e', 'f'}{x: x**2 for x in range(5)} # =&gt; {0: 0, 1: 1, 2: 4, 3: 9, 4: 16}###################################################### 5. Modules##################################################### You can import modulesimport mathprint(math.sqrt(16)) # =&gt; 4.0# You can get specific functions from a modulefrom math import ceil, floorprint(ceil(3.7)) # =&gt; 4.0print(floor(3.7)) # =&gt; 3.0# You can import all functions from a module.# Warning: this is not recommendedfrom math import *# You can shorten module namesimport math as mmath.sqrt(16) == m.sqrt(16) # =&gt; True# Python modules are just ordinary python files. You# can write your own, and import them. The name of the# module is the same as the name of the file.# You can find out which functions and attributes# defines a module.import mathdir(math)# If you have a Python script named math.py in the same# folder as your current script, the file math.py will# be loaded instead of the built-in Python module.# This happens because the local folder has priority# over Python's built-in libraries.###################################################### 6. Classes##################################################### We use the &quot;class&quot; operator to get a classclass Human: # A class attribute. It is shared by all instances of this class species = &quot;H. sapiens&quot; # Basic initializer, this is called when this class is instantiated. # Note that the double leading and trailing underscores denote objects # or attributes that are used by python but that live in user-controlled # namespaces. Methods(or objects or attributes) like: __init__, __str__, # __repr__ etc. are called magic methods (or sometimes called dunder methods) # You should not invent such names on your own. def __init__(self, name): # Assign the argument to the instance's name attribute self.name = name # Initialize property self.age = 0 # An instance method. All methods take &quot;self&quot; as the first argument def say(self, msg): print (&quot;{name}: {message}&quot;.format(name=self.name, message=msg)) # Another instance method def sing(self): return 'yo... yo... microphone check... one two... one two...' # A class method is shared among all instances # They are called with the calling class as the first argument @classmethod def get_species(cls): return cls.species # A static method is called without a class or instance reference @staticmethod def grunt(): return &quot;*grunt*&quot; # A property is just like a getter. # It turns the method age() into an read-only attribute # of the same name. @property def age(self): return self._age # This allows the property to be set @age.setter def age(self, age): self._age = age # This allows the property to be deleted @age.deleter def age(self): del self._age# When a Python interpreter reads a source file it executes all its code.# This __name__ check makes sure this code block is only executed when this# module is the main program.if __name__ == '__main__': # Instantiate a class i = Human(name=&quot;Ian&quot;) i.say(&quot;hi&quot;) # &quot;Ian: hi&quot; j = Human(&quot;Joel&quot;) j.say(&quot;hello&quot;) # &quot;Joel: hello&quot; # i and j are instances of type Human, or in other words: they are Human objects # Call our class method i.say(i.get_species()) # &quot;Ian: H. sapiens&quot; # Change the shared attribute Human.species = &quot;H. neanderthalensis&quot; i.say(i.get_species()) # =&gt; &quot;Ian: H. neanderthalensis&quot; j.say(j.get_species()) # =&gt; &quot;Joel: H. neanderthalensis&quot; # Call the static method print(Human.grunt()) # =&gt; &quot;*grunt*&quot; print(i.grunt()) # =&gt; &quot;*grunt*&quot; # Update the property for this instance i.age = 42 # Get the property i.say(i.age) # =&gt; 42 j.say(j.age) # =&gt; 0 # Delete the property del i.age # i.age # =&gt; this would raise an AttributeError###################################################### 6.1 Multiple Inheritance##################################################### Another class definitionclass Bat: species = 'Baty' def __init__(self, can_fly=True): self.fly = can_fly # This class also has a say method def say(self, msg): msg = '... ... ...' return msg # And its own method as well def sonar(self): return '))) ... ((('if __name__ == '__main__': b = Bat() print(b.say('hello')) print(b.fly)# from &quot;filename-without-extension&quot; import &quot;function-or-class&quot;from human import Humanfrom bat import Bat# Batman inherits from both Human and Batclass Batman(Human, Bat): # Batman has its own value for the species class attribute species = 'Superhero' def __init__(self, *args, **kwargs): # Typically to inherit attributes you have to call super: #super(Batman, self).__init__(*args, **kwargs) # However we are dealing with multiple inheritance here, and super() # only works with the next base class in the MRO list. # So instead we explicitly call __init__ for all ancestors. # The use of *args and **kwargs allows for a clean way to pass arguments, # with each parent &quot;peeling a layer of the onion&quot;. Human.__init__(self, 'anonymous', *args, **kwargs) Bat.__init__(self, *args, can_fly=False, **kwargs) # override the value for the name attribute self.name = 'Sad Affleck' def sing(self): return 'nan nan nan nan nan batman!'if __name__ == '__main__': sup = Batman() # Instance type checks if isinstance(sup, Human): print('I am human') if isinstance(sup, Bat): print('I am bat') if type(sup) is Batman: print('I am Batman') # Get the Method Resolution search Order used by both getattr() and super(). # This attribute is dynamic and can be updated print(Batman.__mro__) # =&gt; (&lt;class '__main__.Batman'&gt;, &lt;class 'human.Human'&gt;, &lt;class 'bat.Bat'&gt;, &lt;class 'object'&gt;) # Calls parent method but uses its own class attribute print(sup.get_species()) # =&gt; Superhero # Calls overloaded method print(sup.sing()) # =&gt; nan nan nan nan nan batman! # Calls method from Human, because inheritance order matters sup.say('I agree') # =&gt; Sad Affleck: I agree # Call method that exists only in 2nd ancestor print(sup.sonar()) # =&gt; ))) ... ((( # Inherited class attribute sup.age = 100 print(sup.age) # Inherited attribute from 2nd ancestor whose default value was overridden. print('Can I fly? ' + str(sup.fly))###################################################### 7. Advanced##################################################### Generators help you make lazy code.def double_numbers(iterable): for i in iterable: yield i + i# Generators are memory-efficient because they only load the data needed to# process the next value in the iterable. This allows them to perform# operations on otherwise prohibitively large value ranges.# NOTE: `range` replaces `xrange` in Python 3.for i in double_numbers(range(1, 900000000)): # `range` is a generator. print(i) if i &gt;= 30: break# Just as you can create a list comprehension, you can create generator# comprehensions as well.values = (-x for x in [1,2,3,4,5])for x in values: print(x) # prints -1 -2 -3 -4 -5 to console/terminal# You can also cast a generator comprehension directly to a list.values = (-x for x in [1,2,3,4,5])gen_to_list = list(values)print(gen_to_list) # =&gt; [-1, -2, -3, -4, -5]# Decorators# In this example `beg` wraps `say`. If say_please is True then it# will change the returned message.from functools import wrapsdef beg(target_function): @wraps(target_function) def wrapper(*args, **kwargs): msg, say_please = target_function(*args, **kwargs) if say_please: return &quot;{} {}&quot;.format(msg, &quot;Please! I am poor :(&quot;) return msg return wrapper@begdef say(say_please=False): msg = &quot;Can you buy me a beer?&quot; return msg, say_pleaseprint(say()) # Can you buy me a beer?print(say(say_please=True)) # Can you buy me a beer? Please! I am poor :( Ready For More?Free Online Automate the Boring Stuff with Python Ideas for Python Projects The Official Docs Hitchhiker’s Guide to Python Python Course First Steps With Python A curated list of awesome Python frameworks, libraries and software 30 Python Language Features and Tricks You May Not Know About Official Style Guide for Python Python 3 Computer Science Circles Dive Into Python 3 A Crash Course in Python for Scientists Dead Tree Programming Python Dive Into Python 3 Learn Python 3.0 VISUALLY","link":"/learn-python3-1min.html"},{"title":"bootstrap-datepicker插件汉化","text":"近期在做项目时用到bootstrap-datepicker这个插件，默认英文显示日期，查阅相关资料后改动即可汉化 先将bootstrap-datepicker.js另存为UTF-8编码格式 增加cn语言选项 1234567891011121314151617181920var dates = $.fn.datepicker.dates = { en: { days: [&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;, &quot;Wednesday&quot;, &quot;Thursday&quot;, &quot;Friday&quot;, &quot;Saturday&quot;, &quot;Sunday&quot;], daysShort: [&quot;Sun&quot;, &quot;Mon&quot;, &quot;Tue&quot;, &quot;Wed&quot;, &quot;Thu&quot;, &quot;Fri&quot;, &quot;Sat&quot;, &quot;Sun&quot;], daysMin: [&quot;Su&quot;, &quot;Mo&quot;, &quot;Tu&quot;, &quot;We&quot;, &quot;Th&quot;, &quot;Fr&quot;, &quot;Sa&quot;, &quot;Su&quot;], months: [&quot;January&quot;, &quot;February&quot;, &quot;March&quot;, &quot;April&quot;, &quot;May&quot;, &quot;June&quot;, &quot;July&quot;, &quot;August&quot;, &quot;September&quot;, &quot;October&quot;, &quot;November&quot;, &quot;December&quot;], monthsShort: [&quot;Jan&quot;, &quot;Feb&quot;, &quot;Mar&quot;, &quot;Apr&quot;, &quot;May&quot;, &quot;Jun&quot;, &quot;Jul&quot;, &quot;Aug&quot;, &quot;Sep&quot;, &quot;Oct&quot;, &quot;Nov&quot;, &quot;Dec&quot;], today: &quot;Today&quot;, clear: &quot;Clear&quot; }, cn: { days: [&quot;周日&quot;, &quot;周一&quot;, &quot;周二&quot;, &quot;周三&quot;, &quot;周四&quot;, &quot;周五&quot;, &quot;周六&quot;, &quot;周日&quot;], daysShort: [&quot;日&quot;, &quot;一&quot;, &quot;二&quot;, &quot;三&quot;, &quot;四&quot;, &quot;五&quot;, &quot;六&quot;, &quot;七&quot;], daysMin: [&quot;日&quot;, &quot;一&quot;, &quot;二&quot;, &quot;三&quot;, &quot;四&quot;, &quot;五&quot;, &quot;六&quot;, &quot;七&quot;], months: [&quot;一月&quot;, &quot;二月&quot;, &quot;三月&quot;, &quot;四月&quot;, &quot;五月&quot;, &quot;六月&quot;, &quot;七月&quot;, &quot;八月&quot;, &quot;九月&quot;, &quot;十月&quot;, &quot;十一月&quot;, &quot;十二月&quot;], monthsShort: [&quot;一月&quot;, &quot;二月&quot;, &quot;三月&quot;, &quot;四月&quot;, &quot;五月&quot;, &quot;六月&quot;, &quot;七月&quot;, &quot;八月&quot;, &quot;九月&quot;, &quot;十月&quot;, &quot;十一月&quot;, &quot;十二月&quot;], today: &quot;今天&quot;, clear: &quot;清除&quot; }}; 修改默认语言参数language为cn 123456789101112131415161718192021var defaults = $.fn.datepicker.defaults = { autoclose: false, beforeShowDay: $.noop, calendarWeeks: false, clearBtn: false, daysOfWeekDisabled: [], endDate: Infinity, forceParse: true, format: 'mm/dd/yyyy', keyboardNavigation: true, language: 'cn', minViewMode: 0, orientation: &quot;auto&quot;, rtl: false, startDate: -Infinity, startView: 0, todayBtn: false, todayHighlight: false, weekStart: 0 }; 即可完成对bootstrap-datepicker插件的汉化。","link":"/bootstrap-datepicker.html"},{"title":"Windows下搭建Django开发环境","text":"Django是用 Python 语言写的开源 Web 开发框架，它鼓励快速开发，并遵循 MVC 设计和 BSD 版权。Django 根据比利时的爵士音乐家 Django Reinhardt 命名. 安装Python环境在安装Django框架之前，确保电脑已经安装配置好Python环境检测Python环境可在命令行直接键入python,若出现以下代码则Python环境已成功配置12Python 3.6.0a3 (v3.6.0a3:f3edf13dc339, Jul 11 2016, 21:40:24) [MSC v.1900 64 bit (AMD64)] on win32Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information. 下载Django框架 Django官网下载 通过Git拉取1git clone https://github.com/django/django.git Note: Django源代码文件与Python文件夹放在同一根目录下，如D:\\Django，此文件夹下还有D:\\Python36。 安装Django12cd D:\\Django # Django下载位置python setup.py install # Django被安装到D:\\Python\\lib\\site-packages 验证Django打开命令行123pythonimport djangodjango.get_version()如果出现版本号，即Django已经安装成功 创建第一个Django项目打开命令行，键入1django-admin startproject 项目路径 # 如 E:\\cs\\DjangoTest 如果想在任意文件夹下执行上述命令而不输入全路径，需要将D:\\Python\\lib\\site-packages\\django\\bin添加到环境变量 执行上述命令之后，会发现在安装路径下出现以下文件123456789 DjangoTest ├── manage.py └── mysite ├── __init__.py ├── settings.py ├── urls.py └── wsgi.py1 directory, 5 files 运行Django服务器进入项目文件夹执行12python manage.py runserver 8000&gt; 8000是默认端口号在浏览器打开127.0.0.1:8000，如果出现以下内容1234It worked!Congratulations on your first Django-powered page.Of course, you haven't actually done any work yet. Next, start your first app by running python manage.py startapp [app_label].You're seeing this message because you have DEBUG = True in your Django settings file and you haven't configured any URLs. Get to work!至此，windows下Django环境搭建成功！","link":"/start-django.html"},{"title":"Hello Markdown","text":"We believe that writing is about content, about what you want to say – not about fancy formatting.我们坚信写作写的是内容，所思所想，而不是花样格式。— Ulysses for Mac Markdown介绍Markdown 是一种轻量级标记语言，它允许人们使用易读易写的纯文本格式编写文档，然后转换成格式丰富的HTML页面。 —— [ 维基百科 ] Markdown参考文档点击以下链接可以查看Markdown语法规则文档 创始人 John Gruber 的 Markdown 语法说明 Markdown中文版语法说明 Markdown，你只需要掌握这几个 Markdown编辑器 Mac OX Windows Web Mou Atom 简书 Ulysses for Mac MarkdownPad csdn Markdown语法标题123456# 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题###### 六级标题 在#号后加一个空格，这是最标准的Markdown语法 引用如果你需要引用一小段别处的句子，就要用引用的格式1&gt; 这是一个引用就会出现以下效果 这是一个引用 使用&gt;表示引用，&gt;&gt;表示引用里面再套一层引用，依次类推。 链接12[点击进入博客](http://blog.fangchengjin.cn/)[点击进入博客(鼠标悬浮带title)](http://blog.fangchengjin.cn/ &quot;ChangingFond&quot;) 就会出现以下效果 点击进入博客点击进入博客(鼠标悬浮带title) 注意：引用先定义 [ref_name]:url，然后在需要写入url的地方，这样使用[锚文本][ref_name]，通常的ref_name一般用数字表示，这样显得专业 图片1![Markdown](http://changingfond.oss-cn-hangzhou.aliyuncs.com/16-7-18/36478356.jpg &quot;Optional title&quot;) 就会出现以下效果 粗体与斜体1234**这是粗体**__这是粗体__*这是斜体*_这是斜体_ 就会出现以下效果 这是粗体这是粗体这是斜体这是斜体 注意：前后的 * 或 _ 与要加粗或倾斜的字体之间不能有空格。 有序列表有序列表直接在文字前加1. 2. 3. 符号要和文字之间加上一个字符的空格1231. 第一行2. 第二行3. 第三行就会出现以下效果 第一行 第二行 第三行 无序列表只需要在文字前加上 * (星号) 或者 + (加号) 或者 - (减号) 即可变为无序列表，符号要和文字之间加上一个字符的空格123* 第一行* 第二行* 第三行就会出现以下效果 第一行 第二行 第三行 表格12345| Tables | Are | Cool || ------------- |:-------------:| -----:|| col 3 is | right-aligned | $1600 || col 2 is | centered | $12 || zebra stripes | are neat | $1 | 就会出现以下效果 Tables Are Cool col 3 is right-aligned $1600 col 2 is centered $12 zebra stripes are neat $1 代码框在文章里引用代码框，只需要用三个反引号包裹代码块```var canvas = document.getElementById(“canvas”);var context = canvas.getContext(“2d”);```就会出现以下效果12var canvas = document.getElementById(&quot;canvas&quot;);var context = canvas.getContext(&quot;2d&quot;); 分割线你可以在一行中用三个以上的星号、减号、底线来建立一个分隔线，行内不能有其他东西。你也可以在星号或是减号中间插入空格。下面每种写法都可以建立分隔线：12345* * *********- - ---------------------------------------- 特殊字符 可以在文本中直接使用html标签，但是要注意在使用的时候，前后加上空行 依赖 Markdown 来换行，在换行处先按入两个以上的空格然后回车 单一段落(&lt;p&gt;) 用一个空白行分割 用\\来转义，表示文本中的 Markdown 符号Markdown 支持以下这些符号前面加上反斜杠来帮助插入普通的符号：123456789101112\\ 反斜线` 反引号* 星号_ 底线{} 花括号[] 方括号() 括弧# 井号+ 加号- 减号. 英文句号! 感叹号","link":"/markdown-tutorial.html"},{"title":"小试Ubuntu Server","text":"今天偶尔逛某里云发现有个云翼计划， 针对大学生可9.9一个月购买一台ECS，虽然本人已经在某讯搭建有ECS，但鉴于其是Windows Server，特想试试Linux Server的一些花样，话不多说，先买为敬。一个月使用时间，足够我折腾一番。 配置 CPU:1核 内存:1024MB 带宽:1Mbps(峰值) 操作系统:Ubuntu 14.04 64位 一个字，渣，也是，便宜没好货。 创建实例成功后，在本地远程连接到服务器一探究竟，显示无法联机。百度后才知道是服务器端没有开启远程连接，无奈之下，只有在阿里控制台先进入服务器 远程连接1sudo apt-get install xrdp 在本地输入cmd + mstsc输入账号密码时终于远程连接服务器。 命令行实在是不会用，就想安装个图形界面 KUbuntu安装开机后输入图形界面的命令 startx，提示安装xinit 1sudo apt-get install xinit 安装完后终端由黑色变成了白底黑字，出现X型的鼠标指针 安装桌面环境。本人安装的是KUbuntu。安装命令如下： 1sudo apt-get install kubuntu-desktop 重启后我们看到了kubuntu界面了,这下我傻眼了，这个界面跟我之前用到的ubuntu看上去差别太大 略微体验了一下，但是kde毕竟太(ka)过(cheng)于(gou)炫， 卸载kde的桌面环境的安装包大概有600-700M，还是比较大的，都差不多赶上了一个ubuntu系统大小的一半了，为了节省空间更是决定卸载掉。 1sudo apt-get --purge remove libqt3-mt libqtcore4 关于开机画面的解决方案 1sudo apt-get autoremove plymouth-theme-kubuntu-logo 重启之后，回归黑框框，听说黑框框很装逼，但门道多着呢，继续探索！ 附录1:Linux下关机重启命令重启命令：12341. reboot2. shutdown -r now 立刻重启(root用户使用)3. shutdown -r 10 过10分钟自动重启(root用户使用)4. shutdown -r 20:35 在时间为20:35时候重启(root用户使用) 如果是通过shutdown命令设置重启的话，可以用shutdown -c命令取消重启 关机命令：12341. halt 立刻关机2. poweroff 立刻关机3. shutdown -h now 立刻关机(root用户使用)4. shutdown -h 10 10分钟后自动关机 如果是通过shutdown命令设置关机的话，可以用shutdown -c命令取消重启 附录2:Linux下各大桌面环境/窗口管理器对比 桌面环境/窗口管理器 RAM used CPU used 类型 KDE 4.6 363 MB 4 % 桌面环境 Unity 271 MB 14% 桌面环境(shell) GNOME 3 193 MB 10% 桌面环境 GNOME 2.x 191 MB 1 % 桌面环境 XFCE 4.8 144 MB 10 % 桌面环境 LXDE 85 MB 10 % 桌面环境 IceWM 85 MB 2 % 窗口管理器 Enlightenment (E17 Standard) 72 MB 1 % 窗口管理器 Fluxbox 69 MB 1 % 窗口管理器 OpenBox 60 MB 1 % 窗口管理器 JWM 58 MB 1 % 窗口管理器","link":"/ubuntu-server.html"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/hello-world.html"}],"tags":[{"name":"apache","slug":"apache","link":"/tags/apache/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"vps","slug":"vps","link":"/tags/vps/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"Frontend","slug":"Frontend","link":"/tags/Frontend/"},{"name":"JavaScript","slug":"JavaScript","link":"/tags/JavaScript/"},{"name":"css","slug":"css","link":"/tags/css/"},{"name":"Elasticsearch","slug":"Elasticsearch","link":"/tags/Elasticsearch/"},{"name":"C#","slug":"C","link":"/tags/C/"},{"name":"Git","slug":"Git","link":"/tags/Git/"},{"name":"Guava","slug":"Guava","link":"/tags/Guava/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"SQL","slug":"SQL","link":"/tags/SQL/"},{"name":"SQL Server","slug":"SQL-Server","link":"/tags/SQL-Server/"},{"name":"Markdown","slug":"Markdown","link":"/tags/Markdown/"},{"name":"php","slug":"php","link":"/tags/php/"},{"name":"Deep Learning","slug":"Deep-Learning","link":"/tags/Deep-Learning/"},{"name":"Person Re-ID","slug":"Person-Re-ID","link":"/tags/Person-Re-ID/"},{"name":"ResNet","slug":"ResNet","link":"/tags/ResNet/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"Cuda","slug":"Cuda","link":"/tags/Cuda/"},{"name":"Windows","slug":"Windows","link":"/tags/Windows/"},{"name":"论文","slug":"论文","link":"/tags/%E8%AE%BA%E6%96%87/"},{"name":"Mockito","slug":"Mockito","link":"/tags/Mockito/"}],"categories":[{"name":"技术人生","slug":"技术人生","link":"/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"},{"name":"编程笔记","slug":"编程笔记","link":"/categories/%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"name":"源码阅读","slug":"源码阅读","link":"/categories/%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"},{"name":"Guava","slug":"源码阅读/Guava","link":"/categories/%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/Guava/"},{"name":"行人重识别","slug":"行人重识别","link":"/categories/%E8%A1%8C%E4%BA%BA%E9%87%8D%E8%AF%86%E5%88%AB/"},{"name":"奇技淫巧","slug":"奇技淫巧","link":"/categories/%E5%A5%87%E6%8A%80%E6%B7%AB%E5%B7%A7/"}]}